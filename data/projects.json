[
  {
    "projectNo": "CCDS25-0001",
    "title": "VIS4AI: Visual analytics for explainable Large Vision Language Models",
    "summary": "Existing large vision language models often work like a blackbox. There are a really large number of parameters in the large vision language models. This project aims to develop an interactive visual analytics approach to explain which set of parameters are responsible for specific functions or concepts and how the large vision language models work.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0002",
    "title": "VIS4AI: Visual analytics for explainable Large Language Models",
    "summary": "For Large Language Models(LLMs), besides ChatGPT whose source-code is not publicly released, there are also some open-sourced LLMs like miniGPT-4, llava, mPlug-OWL, Otter and InstructLib. There are a really large number of parameters in the LLMs, and their detailed parameters are actually accessible. So one question to ask ourselves is: can we explain which set of parameters are responsible for specific functions or concepts?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Web-based Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0003",
    "title": "Audio-based highlighting for visualization presentation",
    "summary": "We have implemented a hard-coded system to achieve audio-based highlighting for visualization presentation, which is not actually generalizable: \nhttps://dl.acm.org/doi/abs/10.1145/3441852.3476539 . Can we make use of the latest progress of AI and achieve a generic solution that can achieve real-time audio-based highlighting of visualization presentations?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Image Analysis &amp; Processing",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0004",
    "title": "Emotion-driven stylish visualization generation",
    "summary": "Given a plain standard chart, how can we automatically generate some fancy decorations to convey the underlying emotions we want to convey? There have been a series of research on the emotion in animated transitions, but it seems that there are still not too many research on the emotion of static visualizations. There are at least two things we can do: 1) We can adjust the overall color usage, e.g., warm color for �happy� and �joyful� emotion and �blue� for sad emotions; 2) We can add extra decorations to a plain chart. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0005",
    "title": "Controllable Image Editing in PPT",
    "summary": "When we insert images into the PPT, PPT can automatically generate some interesting ideas for image design, which looks cool. But the issue is that the generated image layouts and designs are not perfect, it is even impossible for users to do some minor changes, for example, adjust the image size or change the order of two images. It will be interesting to provide controllable interactions and allow users to achieve such kind of image editing tasks conveniently, for example, natural language based editing.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Software and Applications",
      "Machine Learning",
      "Human Computer Interaction",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0006",
    "title": "AI4VIS: AI-powered Interactive Creation of Visualizations �Infographics",
    "summary": "This project aims to develop an AI-powered approach to allow users to interactively create and adjust the visual designs and encodings of different visualizations. The tentative application scenarios are infographics.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Web-based Applications",
      "Human Computer Interaction",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0007",
    "title": "AI4VIS: AI-powered Interactive Creation of Visualizations � Standard Charts",
    "summary": "This project aims to develop an AI-powered approach to allow users to interactively create and adjust the visual designs and encodings of different visualizations. The tentative application scenarios are the standard charts.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Web-based Applications",
      "Human Computer Interaction",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0008",
    "title": "AI4VIS: Leveraging Large Vision Language Model to Evaluate Visualizations",
    "summary": "The evaluation of data visualization often involves human participants, which is time-consuming. This project aims to explore whether it is possible for us to leverage large vision language models to evaluate visualizations. For example, it can be used to check if the visualization violates some visualization design guidelines, report the issues and further provide improvement suggestions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Web-based Applications",
      "Human Computer Interaction",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0009",
    "title": "3.\tInsightMap: A Brief Overview of Data Facts",
    "summary": "Exploratory data analysis allows users to interactively discover the underlying data facts of a given dataset. However, such a process is often a trial-and-error process and time-consuming. Existing data mining techniques, e.g., QuickInsight, have made it easy to extract data facts from a dataset. This project aims to develop an intuitive visualization approach to visual all the possible data facts of a given dataset in a straightforward manner.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Web-based Applications",
      "Human Computer Interaction",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0010",
    "title": "Visual Analytics for Reliable Software Fuzz Testing",
    "summary": "Fuzz testing or fuzzing is an automated software testing method that injects invalid, malformed, or unexpected inputs into a system to reveal software defects and vulnerabilities. However, it is often time-consuming to finish the test and users are unable to inspect the intermediate results during the test. When the results come out, there is also no guidance for users to identify which part should be improved. This project aims to develop a novel interactive visual analytics approach to keep human in the loop and achieve efficient and reliable software fuzz testing.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0011",
    "title": "Visual Analysis of 2D Material Data",
    "summary": "C2DB (https://cmr.fysik.dtu.dk/c2db/c2db.html) is a well-known dataset of two-dimensional (2D) materials. It contains over 200 structural, thermodynamic, elastic, electronic, magnetic, and optical properties for over 15 thousand compounds. Material scientists often need to analyze this dataset and identify high potential compounds, e.g., compounds with desirable semi-conductivity. However, it is very challenging to explore such a material dataset due to both large dataset size and the large number of missing compound property values. This project aims to develop a novel visual analytics approach to help material scientist interactively explore such a 2D material dataset and easily discover new materials with desirable properties like semi-conductivity. The proposed visualization methods will facilitate effective human-AI collaboration in desirable new material discovery process.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Yong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Data Mining",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0012",
    "title": "Application of Generative AI in Travel Planning",
    "summary": "Generative AI (GAI) is expected to improve transportation services by suggesting users the best modes of transportation to travel among places. This project will develop a system of mobile personalized transportation service that a user can specific travel requirements such as origins, multiple destinations, time, and other requirements (e.g., bus or train preferences), and the system will generate the best travel plans for the users. Generative AI technologies such as large language models (LLMs) and Stable Diffusion can be used to support the system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0013",
    "title": "Application of Generative AI in Education",
    "summary": "Generative AI (GAI) is expected to revolutionize the personalized education and learning by generating course contents, exercise, and quiz. This project will develop a system architecture of mobile healthcare by using GAI technologies such as large language models (LLMs) and Stable Diffusion to support learning planning and personalized education. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0014",
    "title": "Application of Generative AI in Healthcare",
    "summary": "Generative AI (GAI) is expected to revolutionize the personalized healthcare by generating rare disease data, modeling high-fidelity digital twin, building versatile testbeds, and providing 24/7 customized medical services. This project will develop a system architecture of mobile healthcare by using GAI technologies such as large language models (LLMs) and Stable Diffusion to support healthcare planning and personalized medication. Also, a virtual physical therapy will be considered.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0015",
    "title": "Mobile AI-Generated Content (AIGC) Services",
    "summary": "Artificial Intelligence Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. However, without a comprehensive understanding of existing models, applications, and challenges, it is impossible to fully realize the potential of AIGC in transforming people�s lifestyles and workflows. This project aims to address this gap by focusing on the deployment of AIGC applications, e.g., ChatGPT, at mobile edge networks, i.e., mobile AIGC networks, that provide personalized and customized AIGC services in realtime while maintaining user privacy. The project will deploy AIGC models in wireless networks and evaluate the performance of the AIGC services to various users with different demands and requirements.\n\nSpecific details:\n(a) Design component\n\nDesign AIGC models and deployment algorithm in wireless networks \n\n(b) Implementation component\n\nWrite programs to generate AIGC to meet users' demand\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Mobile Applications",
      "Wireless and Mobile Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0016",
    "title": "Metaverse for virtual education 1",
    "summary": "Dubbed as the next-generation Internet, the metaverse is a virtual world that allows users to interact with each other or objects in real-time using their avatars. The metaverse is envisioned to support novel ecosystems of service provision in an immersive environment brought about by an intersection of the virtual and physical worlds. The native AI systems in metaverse will personalized user experience over time and shape the experience in a scalable, seamless, and synchronous way.\n\nIn this project, the student is expected to develop a metaverse prototype for applications in virtual education. The student is highly encouraged to use Unity, and an additional bonus is a VR component. The prototype should provide users with different functions such as the scheduling and reservation. In addition, the prototype should collect usage data efficiently for the personalization and performance improvement.\n\nSpecific details:\n(a) Design component\n\nThe student is to work on developing a Metaverse prototype for virtual education\n\n(b) Implementation component\n\nThe prototype is expected to be delivered for some simple testing and demonstration.\n\n(a) Research component\n\n\n(b) Development component\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Mixed Reality",
      "Artificial Intelligence",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0017",
    "title": "Application of Generative AI in Education",
    "summary": "Generative AI (GAI) is expected to revolutionize the personalized education and learning by generating course contents, exercise, and quiz. This project will develop a system architecture of mobile healthcare by using GAI technologies such as large language models (LLMs) and Stable Diffusion to support learning planning and personalized education. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0018",
    "title": "Application of Generative AI in Healthcare",
    "summary": "Generative AI (GAI) is expected to revolutionize the personalized healthcare by generating rare disease data, modeling high-fidelity digital twin, building versatile testbeds, and providing 24/7 customized medical services. This project will develop a system architecture of mobile healthcare by using GAI technologies such as large language models (LLMs) and Stable Diffusion to support healthcare planning and personalized medication. Also, a virtual physical therapy will be considered.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0019",
    "title": "Mobile AI-Generated Content (AIGC) Services",
    "summary": "Artificial Intelligence Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. However, without a comprehensive understanding of existing models, applications, and challenges, it is impossible to fully realize the potential of AIGC in transforming people�s lifestyles and workflows. This project aims to address this gap by focusing on the deployment of AIGC applications, e.g., ChatGPT, at mobile edge networks, i.e., mobile AIGC networks, that provide personalized and customized AIGC services in realtime while maintaining user privacy. The project will deploy AIGC models in wireless networks and evaluate the performance of the AIGC services to various users with different demands and requirements.\n\nSpecific details:\n(a) Design component\n\nDesign AIGC models and deployment algorithm in wireless networks \n\n(b) Implementation component\n\nWrite programs to generate AIGC to meet users' demand\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Mobile Applications",
      "Wireless and Mobile Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0020",
    "title": "Mobile AI-Generated Content (AIGC) Services",
    "summary": "Artificial Intelligence Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. However, without a comprehensive understanding of existing models, applications, and challenges, it is impossible to fully realize the potential of AIGC in transforming people�s lifestyles and workflows. This project aims to address this gap by focusing on the deployment of AIGC applications, e.g., ChatGPT, at mobile edge networks, i.e., mobile AIGC networks, that provide personalized and customized AIGC services in realtime while maintaining user privacy. The project will deploy AIGC models in wireless networks and evaluate the performance of the AIGC services to various users with different demands and requirements.\n\nSpecific details:\n(a) Design component\n\nDesign AIGC models and deployment algorithm in wireless networks \n\n(b) Implementation component\n\nWrite programs to generate AIGC to meet users' demand\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Mobile Applications",
      "Wireless and Mobile Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0021",
    "title": "On-the-job training in the Metaverse workspace",
    "summary": "Dubbed as the next-generation Internet, the metaverse is a virtual world that allows users to interact with each other or objects in real-time using their avatars. \n\nIn this project, the student is expected to build a metaverse prototype modelled after a laboratory/office space in NTU. The prototype will allow users to access the workspace virtually through VR head mounted devices, and train to interact with/work on virtual tools realistically with haptic suits/gloves. This enables users to carry out on-the-job training in a practical, yet riskless, virtual environment, before they work on real world job projects. The student is expected to use Unity and its Physics engine to model 3D objects in the virtual domain. In the physical domain, the student is expected to work with Arduino/Raspberry Pi components.\n\nSpecific details:\n(a) Design component\n\nThe student is to work on developing a Metaverse prototype for on-the-job training.\n \n(b) Implementation component\n\nThe prototype is expected to be delivered for some simple testing and demonstration.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Virtual Reality",
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0022",
    "title": "Metaverse for virtual game",
    "summary": "Dubbed as the next-generation Internet, the metaverse is a virtual world that allows users to interact with each other or objects in real-time using their avatars. The metaverse is envisioned to support novel ecosystems of service provision in an immersive environment brought about by an intersection of the virtual and physical worlds. The native AI systems in metaverse will personalized user experience over time and shape the experience in a scalable, seamless, and synchronous way.\n\nIn this project, the student is expected to develop a metaverse prototype for applications in virtual game. The student is highly encouraged to use Unity, and an additional bonus is a VR component. The prototype should provide users with different functions such as the game scenes and team tasks. In addition, the prototype should collect usage data efficiently for the personalization and performance improvement. \n\nSpecific details:\n(a) Design component\n\nThe student is to work on developing a Metaverse prototype for virtual game\n \n(b) Implementation component\n\nThe prototype is expected to be delivered for some simple testing and demonstration.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Virtual Reality",
      "Serious Games"
    ]
  },
  {
    "projectNo": "CCDS25-0023",
    "title": "Metaverse for virtual game",
    "summary": "Dubbed as the next-generation Internet, the metaverse is a virtual world that allows users to interact with each other or objects in real-time using their avatars. The metaverse is envisioned to support novel ecosystems of service provision in an immersive environment brought about by an intersection of the virtual and physical worlds. The native AI systems in metaverse will personalized user experience over time and shape the experience in a scalable, seamless, and synchronous way.\n\nIn this project, the student is expected to develop a metaverse prototype for applications in virtual game. The student is highly encouraged to use Unity, and an additional bonus is a VR component. The prototype should provide users with different functions such as the game scenes and team tasks. In addition, the prototype should collect usage data efficiently for the personalization and performance improvement. \n\nSpecific details:\n(a) Design component\n\nThe student is to work on developing a Metaverse prototype for virtual game\n \n(b) Implementation component\n\nThe prototype is expected to be delivered for some simple testing and demonstration.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Dusit Niyato",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Virtual Reality",
      "Serious Games"
    ]
  },
  {
    "projectNo": "CCDS25-0024",
    "title": "Interactive Shape Modelling in Unity 3D system",
    "summary": "In this project the student will continue working on the project where the interactive software ShapeExplorer (https://personal.ntu.edu.sg/assourin/BookSpringer) is being developed using Unity 3D system (http://unity3d.com). The software is used for generating curves and polygon meshes defined by parametric and implicit functions. This software is used in SC3060 (Computer Graphics and Visualization) and CE7404 (Virtual Reality) courseworks. \n     The project requires further improvements of the software. Specifically, the focus is on interactive shape modelling where implicitly defined solid objects will be used for interactive constructive solid geometry. Versions using common interactive devices and the hand tracking Leap Motion device will be developed.\n     Good prior knowledge of UNITY programming is essential for this project. Also, the prerequisites are SC3060 \"Computer Graphics &amp; Visualization\" and/or self-studying of the book https://personal.ntu.edu.sg/assourin/BookSpringer (free download from NTU library).\n    \nThis is an individual project but it will be conducted in close interaction with a PhD student. \n    \nThe actual content of the project will de defined after discussion with the student and based on his/her abilities and interest.\n\nSpecific details:\n(a) Design component\nTo design algorithms for visualising objects in UNITY 3D environments based on parametric and implicit definitions.\n\n(b) Implementation component\nTo implement algorithms for visualising objects in UNITY 3D environments based on parametric and implicit definitions.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0025",
    "title": "Music from the air - digital terpsiton",
    "summary": "This project requires that the student MUST BE FAMILIAR with the theory of music (scales, cords, harmony, etc) and can play some musical instrument.      \n   One hundred years ago the theremin was invented. This is an electronic musical instrument controlled without physical contact by hands of the performer.  The theremin consists of two metal antennas that sense the relative position of the thereminist's hands and control pitch of the notes with one hand, and volume with the other. Later the inventor, Leo Theremin, proposed another musical instrument -- terpsitone -- named after the Greek Goddess of dance Terpsihore. The idea was that sound can be generated by sensing the body of dancer. It was proposed to be made on the same tracking principles as the theremin except that it was designed as a platform on which the dancer had to move/dance. This instrument however never was really made except a few test copies due to the complexity of tracking and using. \n     \n\nReference:\nhttps://www.youtube.com/watch?v=gH0Y5M46Gqc&amp;list=PLbKLI6FekIW4D-hV9pOyc0kS3ZTIIhttI&amp;index=39\n\nSpecific details:\n(a) Design component\n\n(b) Implementation component\n\n(a) Research component\nTo explore whether Kinect can be realistically used for making music while tracking the body of the player\n\n(b) Development component\nTo make a pilot version of the application",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0026",
    "title": "Music from the air - digital theremin",
    "summary": "Theremin is an electronic musical instrument controlled without physical contact by hands of the performer.  It was invented in the 1919. Theremin consists of two metal antennas that sense the relative position of the thereminist's hands and control pitch of the notes with one hand, and volume with the other. The  instrument can be tuned to each individual player including the range of the notes and volumes to be produced. \n    This project requires that the student MUST BE FAMILIAR with the theory of music (scales, cords, harmony, etc) and can play some musical instrument. The student will be making a digital theremin with optical tracking devices (Leap Motion controller) where position of dominant hand will be tracked to define the pitch of the sound, while position of the other hand will control the volume. Unity 3D system will be used for programming.  \n\n   This is an individual project but it will be conducted in close interaction with a PhD student\n   \nReferences:\nhttps://en.wikipedia.org/wiki/Theremin\nhttps://www.youtube.com/watch?v=Nfh6UuJuU-U\n\nSpecific details:\n(a) Design component\nTo design waveforms and filters for audio signals\n\n(b) Implementation component\nTo implement the designed elements using C# and audio library\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0027",
    "title": "Virtual assembling using hand tracking with Leap Motion controller",
    "summary": "In this project the student will design and develop virtual assembling in Unity 3D system using hand tracking by Leap Motion controller.\n\n   First, the student will learn how Leap Motion controller can track hands and will understand how well it can be used for simulating virtual assembling operations where objects have to be picked up, positioned and placed by one or two hands.\nNext, the student will learn how Leap Motion controller can be used together with Unity3D system.\n   Next, the student will need to design the user interaction based on the study performed. The interaction should reliably simulate real-life assembling operations which are performed by hands on top of table. The interaction has to be performed using the help of Unity 3D physics engine which computes collision detection of the virtual fingers with the objects. However, the student will need to design and implement measures compensating for luck of physical feedback forces which can be felt by the user.\n   Finally, a user study has to be done to verify whether virtual interaction is as good as real-life interaction when performing assembling operations.\n\nThe project can be performed on home PC/notebook.\n\nRequirements: programming using C/C++. \nRefer to http://unity3d.com\n\nSpecific details:\nTo design and implement hand gestures and the virtual scene for the user testing.",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0028",
    "title": "predicting eye movements with AI models",
    "summary": "Humans do not perceive the entire scenes at once. Instead, they move their eyes and pay attention to certain parts of the visual scenes. How do we come up with AI models capable of predicting human eye movements? Students get to program computational models of eye movement predictions. Alternatively, students also get to learn how to use advanced eye tracking devices in the lab, design eye tracking expeirments with programming languages, collecting human data, and analyzing these eye movement data.\n\nSpecific details:\n(a) Design component\nComputational models of eye movement prediction\n\n(b) Implementation component\nEyetracking experiments\ndata analysis from the experimental results\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Biomedical Systems",
      "Human Computer Interaction",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0029",
    "title": "Developing efficient human-like memory systems",
    "summary": "Where and when did you go to the primary school? What did you see this morning when you went to the school? What did you have lunch yesterday? We humans have amazing memory systems. In contrast, AI systems still suffer from storing large amount of data efficiently. Students will be involved in research projects studying human memory systems. This includes developing 3D environments in simulation engines, such as Blender, for VR headsets. Alternatively, students can design web-based applications for collecting human memorization data. Students with strong programming language skills will also get to code computational models that mimic the ways humans memorize episodic events.\n\nSpecific details:\n(a) Design component\ncomputational modeling of memory systems\nweb-based applications testing human memorization ability in videos\n3D simulation environments to test human memorability during navigation tasks for Virtual reality glasses\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Graphics",
      "Human Computer Interaction",
      "Virtual Reality",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0030",
    "title": "Learning Mental States for C. elegans with Recurrent Neural Networks (RNNs)",
    "summary": "Modern recording techniques enable large-scale measurements of neural activity along with the exhibited behaviors in a variety of model organisms. The dynamics of neural activity shed light on how organisms process sensory information and generate motor behavior. Here, we study these dynamics using optical recordings of neural activity in the nematode C. elegans. To understand these data, we aim to develop state space models that decompose neural time-series into homoscedastic representations that model behaviors exhibited in such states. Students will gain hands-on experiences with research projects in developing such AI models. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nAI models\nanalayze behaviors of AI models and biological species (C elegans)\n\n(b) Development component",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computational Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0031",
    "title": "Building Multi-Modal Intelligence: Dissecting Model with Monosemantic Features and a Unified Evaluation Approach",
    "summary": "This project aims to refine model evaluation processes by optimizing evaluation pipelines for contemporary large multi-modality models. Additionally, it seeks to leverage insights gained from the evaluation to enhance model performance and achieve a comprehensive understanding of the models through the application of sparse autoencoders.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThis project aims to:\n\n-\tDevelop a unified evaluation pipeline tailored to the requirements of modern large multi-modality models.\n\n-\tBuild improved vision models with enhanced long-context visual processing and reasoning capabilities.\n\n-\tGain a deeper understanding of large multi-modal models using sparse autoencoders to identify the causes of hallucinations and explore potential mitigation strategies.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "URECA-FYP",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0032",
    "title": "Volumetric Multimodal Video Synthesis",
    "summary": "The goal of this project is to develop a novel approach for volumetric multimodal video synthesis that leverages holistic supervision to improve the quality and fidelity of the synthesized videos. The framework incorporates a holistic supervision strategy that leverages both local and global information to improve the accuracy and consistency of the synthesized video. We aim to use deep learning techniques, such as generative adversarial networks (GANs) and 3D convolutional networks, to achieve state-of-the-art performance in terms of visual quality, temporal coherence, and consistency across modalities. Our proposed approach has potential applications in a variety of domains, including virtual reality, gaming, and robotics, where high-quality and realistic 3D video data is essential for immersive user experiences and effective decision-making.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Multimodal data integration: Develop methods for integrating multimodal information, using modalities like image, audio, depth maps, and surface normal.\n\n2) Volumetric video synthesis: Develop deep learning techniques, such as GANs and 3D convolutional networks, to achieve state-of-the-art performance in terms of visual quality, temporal coherence, and consistency across modalities.\n\n(b) Development component\n\n1) Create a demo using Hugging Face to showcase the performance and functionality of the proposed system for volumetric multimodal video synthesis with holistic supervision.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0033",
    "title": "Be A Director: Conditional Video Generation",
    "summary": "Recent years have witnessed great progress in creating vivid portraits from monocular videos. However, how to seamlessly adapt the created video avatars to other scenarios with different backgrounds and lighting conditions remains unsolved. In this project, we aim to relight portrait videos by reflectance decomposition. By manipulating the decomposed components, we can control the lighting condition of portraits. Users can choose the background image and correspondingly relight portraits even without professional knowledge of image processing.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Survey portrait relighting methods and compare their differences.\n2) Train or use off-the-shelf relighting models for portrait videos.\n3) Explore to improve the relighting quality or user interaction.\n\n(b) Development component\n\n1) Design a UI to allow users to flexibly choose the background image and correspondingly relight portraits.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0034",
    "title": "Scene Crafter: 3D Scene Generation for Game Assets",
    "summary": "Generative Adversarial Network (GAN) has been attracting more and more attention in recent years because of its powerful ability in generating natural images. However, the power of generative models has not been unleashed for 3D scene generation, which has wide applications in game industry to create game maps or related assets. In this project, we aim to generate 3D scenes with geometry details, diverse styles, and immersive appearance. By manipulating the latent space of GAN, we can even control the model to generate 3D scenes on your own will, for example a fantasy land, where you can interactively roam and tour.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Learn technical details of GAN and volume rendering (i.e., Neural Radiance Field).\n2) Explore possible ways to train generative models for 3D scenes or adapt off-the-shelf large generative models.\n3) Analyse and demonstrate generation results.\n\n(b) Development component\n\n1) Design an interactive UI for users to freely move in the generated scenes.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0035",
    "title": "Customized Image Synthesis using Diffusion Models",
    "summary": "Diffusion models have become increasingly popular because of its powerful ability in generating natural images of high fidelity and diversity. Nowadays, text-to-image diffusion models have been widely used to convert a natural language description (e.g., �an orange cat�) to photorealistic images (e.g. a photo of an orange cat). We can utilize the powerful pre-trained text-to-image diffusion models for various amazing downstream applications. For instance, a pre-trained text-to-image diffusion model can be leveraged to extract the appearance of a specific cat from multiple given images of this cat, and generate images of this cat under various scenarios. In this FYP, the student will explore algorithms for customized image synthesis using pre-trained text-to-image diffusion models. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Conduct a comprehensive literature review on image generation, diffusion models, and text-to-image models\n2) Implement pre-trained text-to-image diffusion models\n3) Implement customized image synthesis using pre-trained text-to-image diffusion models\n4) Improve existing techniques for more robust customized image synthesis\n5) Explore other aspects of customized image synthesis (appearance, backgrounds, styles, etc)\n\n(b) Development component\n\n1) Design a UI to allow user upload photos for customized synthesis",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0036",
    "title": "Customized Storyboard Creation for Consistent Visual Narratives",
    "summary": "In the past few years, there has been great research done in customized image generation methods where a user inputs both sample image(s) and a prompt to generate images that feature the object from the sample image in various new settings and scenarios. This project aims to see how these methods can be extended to consistent storyboard generation, where a single prompt with sample image(s) can result in a storyboard where the object / characters are depicted in a consistent fashion across scenes in the story. For instance, given a sample image of a character and a prompt such as �the character explores a futuristic city,� the goal would be to generate a storyboard where the character is consistently depicted across multiple scenes, interacting with different elements of the city while maintaining a coherent appearance and style. This project will explore various methods for customized image generation and evaluate their effectiveness in generating such storyboards.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Generate static virtual try-on images using pretrained diffusion models.\n2) Design baseline methods for generating virtual try-on videos, like generate a sequence of images conditioning on human poses.\n\n(b) Development component\n\n1) Design a demo for the virtual try-on application.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0037",
    "title": "3D Human Generation for Virtual Assets",
    "summary": "3D Human digitization plays an important role in a series of real-world scenarios, including AR/VR products, autonomous driving, and robotics. The high-fidelity 3D human Generation or Reconstruction still remains as a challenging problem to tackle. In this project, we aim to generate high-fidelity animatable 3D humans by leveraging the powerful ability of implicit neural representation learning (e.g., neural radiance fields) and generative modelling. By conditioning on one human image, we can generate the high-fidelity 3D humans satisfying the input condition and animate the 3D humans freely with a motion sequence.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Learn technical details of diffusion models and volume rendering (i.e., Neural Radiance Field).\n2) Learn to estimate the SMPL parameters of 3D humans in data preparation stage.\n3) Explore possible ways to train generative models for 3D humans or adapt off-the-shelf large generative models.\n4) Analyse and demonstrate generation results.\n\n(b) Development component\n\n1) Design an interactive UI for users to freely animate the generated 3D humans.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0038",
    "title": "Coherent Visual Story Generation using Diffusion Models",
    "summary": "The emergence of Diffusion Models has opened up a lot of possibilities for generative tasks such as text-to-image generation. However, current methods still struggle to generate coherent sequential image outputs based on a series of text descriptions. This is mainly due to the gap between vision and natural language: human-generated narrations often fail to describe all the visual details accurately, such as object appearance and background, resulting in randomness in the generated sequences. In this FYP, the student will explore how to capture visual concepts from images/videos and integrate them into text descriptions to generate stable and coherent image sequences.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Explore pre-trained text-to-image diffusion models, analyse their performance on sequential text-to-image generation.\n2) Implement existing inversion (customized generation) methods on diffusion models and investigate their effectiveness.\n3) Develop improved inversion methods for sequential text-to-image generation.\n4) Explore the integration of inversion methods and text-to-image generation models for generating coherent visual stories.\n\n(b) Development component\n\n1) Design and develop a user-friendly UI for uploading reference images/videos and sequential text descriptions.\n2) Implement coherent visual story generation on the UI for user interaction and feedback.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0039",
    "title": "Advancing Text-Conditioned Image Editing",
    "summary": "Text-conditioned image editing using only a single image and a single edit prompt remains a challenging task; Existing methods struggle to produce realistic, semantically-aligned, non-rigid edits while preserving the original image's integrity. In this project, we will explore new novel strategies to improve existing state-of-the-art methods.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Utilize or train large-scale vision models to enhance visual in-context learning capabilities.\n2) Investigate optimal solutions for selecting effective prompts for visual in-context learning.\n\n(b) Development component\n\n1) Develop a Hugging Face demonstration showcasing visual in-context learning.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0040",
    "title": "Highly Controllable Motion Generation Model",
    "summary": "This project aims to develop a highly controllable motion generation technology that can be utilized in various applications, such as animation, virtual reality, robotics, and gaming. By leveraging state-of-the-art deep learning techniques and motion capture data, the project will create a versatile system that allows users to generate complex and diverse human motion sequences by providing simple input commands. The system will be designed to be user-friendly and efficient, enabling even non-experts to generate realistic and high-quality motion sequences with ease.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Investigate existing motion generation techniques, such as VAEs, GANs, and motion diffusion models.\n2) Develop a deep learning-based model for motion generation, incorporating controllability and adaptability to user input.\n\n(b) Development component\n\n1) Implement the motion generation model in a user-friendly application.\n2) Create a graphical user interface (GUI) that enables users to provide input and visualize generated motion sequences.",
    "supervisor": "A/P Liu Ziwei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0041",
    "title": "Multi-agent visual search-1",
    "summary": "Visual search is a fundamental cognitive process that enables agents to locate relevant targets in complex environments. While single-agent visual search has been extensively studied, how multiple agents coordinate their search strategies remains an open question. This research investigates multi-agent visual search (MAS), focusing on shared attention, adaptive decision-making, and communication among agents. By combining human behavioral experiments with AI models, we aim to understand how agents leverage each other�s gaze and search history to improve efficiency. We will develop computational models that simulate cooperative and competitive search dynamics, exploring how information sharing influences search performance. This work has applications in robotics, surveillance, and human-AI collaboration, where efficient multi-agent search is critical.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\ndesign human studies and collect human data\n(b) Development component\ndevelop multi agent reinforcement learning agents",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0042",
    "title": "Multi-agent visual search-2",
    "summary": "Visual search is a fundamental cognitive process that enables agents to locate relevant targets in complex environments. While single-agent visual search has been extensively studied, how multiple agents coordinate their search strategies remains an open question. This research investigates multi-agent visual search (MAS), focusing on shared attention, adaptive decision-making, and communication among agents. By combining human behavioral experiments with AI models, we aim to understand how agents leverage each other�s gaze and search history to improve efficiency. We will develop computational models that simulate cooperative and competitive search dynamics, exploring how information sharing influences search performance. This work has applications in robotics, surveillance, and human-AI collaboration, where efficient multi-agent search is critical.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\ndesign human studies and collect human data\n(b) Development component\ndevelop multi agent reinforcement learning agents",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0043",
    "title": "Multi-agent visual search-3",
    "summary": "Visual search is a fundamental cognitive process that enables agents to locate relevant targets in complex environments. While single-agent visual search has been extensively studied, how multiple agents coordinate their search strategies remains an open question. This research investigates multi-agent visual search (MAS), focusing on shared attention, adaptive decision-making, and communication among agents. By combining human behavioral experiments with AI models, we aim to understand how agents leverage each other�s gaze and search history to improve efficiency. We will develop computational models that simulate cooperative and competitive search dynamics, exploring how information sharing influences search performance. This work has applications in robotics, surveillance, and human-AI collaboration, where efficient multi-agent search is critical.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\ndesign human studies and collect human data\n(b) Development component\ndevelop multi agent reinforcement learning agents",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0044",
    "title": "adaptive world models for AI",
    "summary": "Intelligent agents must continuously learn and adapt to dynamic environments. Adaptive world models aim to build representations of the world that evolve over time, allowing agents to generalize beyond their training experience. This research explores how AI models can develop flexible, predictive internal representations that update as new information becomes available. We will investigate techniques such as meta-learning, continual learning, and reinforcement learning to create models that can anticipate changes, recover from uncertainty, and optimize decision-making. By comparing AI models with human cognitive strategies, we aim to develop more robust and generalizable adaptive world models. This research has applications in robotics, autonomous systems, and AI-driven decision-making.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\ndevelop world models that are adaptive\n\n(b) Development component",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0045",
    "title": "policy making and governance for AI",
    "summary": "As artificial intelligence (AI) becomes increasingly integrated into society, effective policy making and governance frameworks are essential to ensure its ethical, legal, and social implications are addressed. This research examines how policies can be designed to promote fairness, transparency, accountability, and safety in AI systems. We will analyze existing AI regulations, propose governance models, and explore the role of international cooperation in AI oversight. By bridging technical AI development with policy and law, this work aims to guide policymakers in creating adaptive regulatory frameworks that balance innovation with public interest. The research has broad applications in AI ethics, data privacy, algorithmic bias mitigation, and responsible AI deployment across industries.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature review and design surveys, plans, or AI models for governance and policy making\n\n(b) Development component",
    "supervisor": "Ast/P Zhang Mengmi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0056",
    "title": "Integrating Agentic AI and Chain-of-Thought Reasoning in Web-Based Platforms to Enhance Undergraduate Data Structures Education",
    "summary": "Recent advancements in artificial intelligence have introduced methodologies such as Agentic AI frameworks and Chain-of-Thought (CoT) reasoning, significantly enhancing complex problem-solving in large language models (LLMs). Agentic AI systems autonomously plan, reason, and adapt to achieve goals, mirroring human cognitive processes, while CoT prompting enables LLMs to generate step-by-step explanations, improving logical reasoning. Wei et al. (2022) demonstrated that CoT prompting enhances LLM reasoning, leading to improved performance in arithmetic and commonsense tasks.\n\nIn education, these advancements have the potential to transform traditional teaching by providing adaptive, AI-driven student support. However, a significant gap exists in applying these frameworks within undergraduate data structures courses. Existing studies focus on general LLM capabilities without tailoring them to the specific challenges of data structures learning. This research addresses this gap by developing a web-based learning platform integrating Agentic AI and CoT reasoning to enhance students' comprehension and problem-solving skills in data structures.\nResearch Objective and Method:\n\n A mixed-methods approach will be used:\n    Quantitative: Conduct pre- and post-course assessments to measure improvements in students' understanding of data structures.\n    Qualitative: Conduct surveys and focus groups to gain insights into students� experiences with AI-driven learning tools.\n\nThis methodology aligns with prior studies that have used mixed-methods approaches to evaluate AI�s impact on learning.\n\nResearch Questions:\n    How does integrating Agentic AI in a web-based platform impact student engagement and motivation in data structures?\n    To what extent does Chain-of-Thought reasoning improve problem-solving skills in data structures?\n    How do students perceive the usability and effectiveness of AI-driven learning tools in data structures coursework?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis study examines Agentic AI, Chain-of-Thought (CoT) reasoning, and Self-Regulated Learning (SRL) theory in programming education (Dilling &amp; Herrmann, 2024; Joshi, 2025). AI-driven modules will be developed to provide structured feedback for data structures learning. Undergraduate students will be recruited, and data will be collected via pre/post-tests, surveys, and focus groups. Statistical and thematic analyses will measure learning improvements and engagement.\n\n\n(b) Development component\nA web-based learning platform will be developed, integrating Agentic AI and CoT reasoning for real-time adaptive support. Interactive coding exercises will provide AI-generated hints and feedback. Pilot testing will refine usability and effectiveness before full implementation in data structures courses. A continuous optimization strategy will be applied using feedback loops to enhance AI-driven scaffolding and improve student learning outcomes.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Software and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0057",
    "title": "AI-Powered Multi-Agent System for Automated Test Script Generation from SRS Documents",
    "summary": "Recent AI-driven test automation advancements enable automated test script generation from Software Requirements Specification (SRS) documents. Kumari (2025) introduced a Multi-Agent System (MAS) using LLMs for test case generation, demonstrating adaptive validation and AI-driven execution. However, her framework lacked real-time agent collaboration, limiting scalability and accuracy in complex projects.\n\nOther studies have limitations. Bhatia et al. (2024) explored LLM-based test case generation but relied on a single-agent model, achieving an 87% validity rate. Roy and Tiwari (2020) proposed a Smart Test Automation Framework, focusing on feature extraction but lacking real-time validation. Spieker and Gotlieb (2019) introduced Adaptive Metamorphic Testing using contextual bandits for fault detection. NVIDIA (2023) developed an AI agent-based automation framework, but it focused on unit testing rather than end-to-end automation.\n\nThis research extends prior work by implementing a hierarchical MAS framework with Requirement Analysis, Test Case Generation, Test Script Writing, Validation, and Execution Agents. It integrates adaptive learning, cross-agent validation, and context-aware optimization, improving accuracy, efficiency, and scalability.\n\nResearch Objective\n    Develop a MAS framework for test script generation from SRS documents.\n    Improve automation accuracy using real-time validation and adaptive learning.\n    Compare MAS performance with single-agent AI models in efficiency, accuracy, and defect detection.\n\nResearch Questions\n\n    How does a multi-agent AI system improve accuracy and efficiency in test script generation compared to single-agent models?\n    What challenges exist in AI-driven adaptive learning, and how does real-time validation improve usability?\n    How does AI compare to manual test case writing in defect detection and execution time?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nMAS Development � Implement specialized agents:\nSRS Analysis Agent � Extracts functional requirements (NVIDIA, 2023).\nTest Case Generation Agent � Converts requirements into structured test cases (Bhatia et al., 2024).\nScript Writing Agent � Generates automation scripts (Kumari, 2025).\nValidation Agent � Ensures test cases align with SRS (Roy &amp; Tiwari, 2020).\nExecution &amp; Reporting Agent � Runs scripts, logs results, and optimizes efficiency (Spieker &amp; Gotlieb, 2019).\n\n(b) Development component\nAgent Design � Define roles, workflows, and knowledge-sharing (Kumari, 2025).\nTest Automation Pipeline � Develop the SRS-to-Test Case conversion system (Bhatia et al., 2024).\nValidation Layer � Implement cross-agent test case verification (Roy &amp; Tiwari, 2020).\nUser Interface &amp; API � Provide developer configurations and results visualization (NVIDIA, 2023).\nPerformance Optimization � Improve efficiency with adaptive learning (Spieker &amp; Gotlieb, 2019).",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Software and Applications",
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0058",
    "title": "Real-Time Mobile Interventions for Tourist Safety: Influencing On-Site Decision-Making to Reduce Incidents",
    "summary": "Recent studies have explored the impact of mobile applications on tourist behavior and safety. Dias and Afonso (2021) investigated how mobile apps alter tourist experiences, emphasizing increased connectivity and security. Dinkoksung et al. (2023) developed a mobile solution to enhance tourist safety in warm and humid destinations, integrating warning systems and health recommendations. Additionally, research by Ketter (2023) analyzed behavioral interventions to manage social media-induced tourism impacts, highlighting strategies to influence tourist behavior.\n\nThis study aims to develop and evaluate a mobile application that delivers real-time safety alerts to influence tourists' on-site decisions and reduce incidents. Using a mixed-methods approach, it will begin with a literature review to identify effective features from existing mobile safety applications. The application development phase will integrate real-time alerts, geofencing, and health recommendations, following methodologies from Dinkoksung et al. (2023). Pilot testing will be conducted in selected tourist destinations to assess usability and effectiveness. Finally, data analysis will evaluate the app�s impact on tourist behavior and incident reduction through surveys and incident reports.\n\nResearch Questions\n    How do real-time safety alerts via mobile applications influence tourists' immediate decisions at high-risk locations?​\n\n    What is the effectiveness of mobile applications in reducing incidents among tourists in warm and humid destinations?​\n    MDPI\n\n    How do tourists perceive the usability and reliability of safety-focused mobile applications during their travels?\n\nDia et al (2021). Impact of Mobile Applications in Changing the Tourist Experience. European Journal of Tourism, Hospitality and Recreation, 11(1), 113-120.\n\nDinkoksung et.al. (2023). A Mobile Solution for Enhancing Tourist Safety in Warm and Humid Destinations. Applied Sciences, 13(15), 9027.\n\nSpecific details:\n(a) Design component\n\nDesign web and mobiile application\n(b) Implementation component\n\nDevelop web and mobile applications\n\n(a) Research component\nLiterature Review: Examine studies on mobile apps and tourist behavior.​\n\nSurvey Design: Develop questionnaires to assess tourist perceptions.​\nMDPI\n\nApplication Development: Create the safety app with real-time alerts.​\nMDPI\n\nPilot Testing: Implement the app in selected destinations.​\n\nData Collection: Gather usage data and survey responses.​\n\nAnalysis: Evaluate the app's impact on behavior and safety.​\n \n\n(b) Development component\n\nRequirement Analysis: Identify essential safety features.​\n\nDesign Phase: Create user-friendly interfaces.​\nMDPI\n\nDevelopment: Implement features like geofencing and alerts.​\n\nTesting: Conduct usability and functionality tests.​\n\nDeployment: Launch the app in pilot areas.​\n\nFeedback Collection: Gather user feedback for improvements.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Smartphone Systems and Applications",
      "Web-based Applications",
      "Mobile Applications",
      "Software and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0059",
    "title": "Protecting Neural Networks from Adversarial Attacks",
    "summary": "While a number of solutions for fast decisioning and inferencing on neural networks have been proposed in recent times, training a network remains a difficult task, often consuming days. The problem is likely to worsen due to data privacy, which mandates either the training to be done on an encrypted data-set, or to be done in a distributed manner with �whitening layer� added before integrating the multiple trained networks. The goal of this project is to set up a framework using OpenTPU and benchmarking the training time for various datasets. Subsequently, the training process needs to be optimised through batch-processing, hardware implementation, dynamic network tuning or a combination of the above.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0060",
    "title": "Protecting Neural Networks from Adversarial Attacks",
    "summary": "While a number of solutions for fast decisioning and inferencing on neural networks have been proposed in recent times, training a network remains a difficult task, often consuming days. The problem is likely to worsen due to data privacy, which mandates either the training to be done on an encrypted data-set, or to be done in a distributed manner with �whitening layer� added before integrating the multiple trained networks. The goal of this project is to set up a framework using OpenTPU and benchmarking the training time for various datasets. Subsequently, the training process needs to be optimised through batch-processing, hardware implementation, dynamic network tuning or a combination of the above.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0061",
    "title": "Efficient Quantum Circuit Design",
    "summary": "Due to the advent of Quantum computing, there is a tremendous growth in the space of algorithm design, technology development, design automation and circuit constructions. There are excellent open-source tools for simulating Quantum circuit, which allows one to implement basic Quantum algorithm, simulate those and perform benchmarking in terms of parameters like depth, size and quantum resources in general. During this project, the student will be assigned to study simple building blocks of a quantum circuit (e.g., multiplier) and obtain their performance numbers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Digital Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0062",
    "title": "Protecting Neural Networks from Adversarial Attacks",
    "summary": "While a number of solutions for fast decisioning and inferencing on neural networks have been proposed in recent times, training a network remains a difficult task, often consuming days. The problem is likely to worsen due to data privacy, which mandates either the training to be done on an encrypted data-set, or to be done in a distributed manner with �whitening layer� added before integrating the multiple trained networks. The goal of this project is to set up a framework using OpenTPU and benchmarking the training time for various datasets. Subsequently, the training process needs to be optimised through batch-processing, hardware implementation, dynamic network tuning or a combination of the above.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0063",
    "title": "Efficient Quantum Circuit Design",
    "summary": "Due to the advent of Quantum computing, there is a tremendous growth in the space of algorithm design, technology development, design automation and circuit constructions. There are excellent open-source tools for simulating Quantum circuit, which allows one to implement basic Quantum algorithm, simulate those and perform benchmarking in terms of parameters like depth, size and quantum resources in general. During this project, the student will be assigned to study simple building blocks of a quantum circuit (e.g., multiplier) and obtain their performance numbers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Digital Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0064",
    "title": "Efficient Quantum Circuit Design",
    "summary": "Due to the advent of Quantum computing, there is a tremendous growth in the space of algorithm design, technology development, design automation and circuit constructions. There are excellent open-source tools for simulating Quantum circuit, which allows one to implement basic Quantum algorithm, simulate those and perform benchmarking in terms of parameters like depth, size and quantum resources in general. During this project, the student will be assigned to study simple building blocks of a quantum circuit (e.g., multiplier) and obtain their performance numbers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Digital Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0065",
    "title": "Automatic Agent-based Code Generation",
    "summary": "In this project, the goal is to utilize online AI agents for code generation, debugging, script generation from visual and language prompts. Primarily hardware code generation will be targeted.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Hardware Acceleration"
    ]
  },
  {
    "projectNo": "CCDS25-0066",
    "title": "Leveraging Large Language Models to Transform Real Estate Practices: Automating Complex Tasks and Ensuring Ethical Compliance in Singapore",
    "summary": "he integration of Large Language Models (LLMs) into Singapore's real estate sector offers significant potential to automate complex tasks, such as contract analysis and client interactions, thereby enhancing operational efficiency. However, deploying LLMs necessitates strict adherence to ethical standards and local regulations to mitigate risks associated with data privacy, bias, and accountability. For instance, Madani et al. (2024) developed a compliant real estate chatbot to prevent discriminatory practices like steering and redlining. This research aims to explore the application of LLMs in automating real estate processes within Singapore, focusing on operational benefits and ethical considerations.​\n\n\nResearch Method:\nLiterature Review:\n        Examine existing studies on AI applications in real estate, emphasizing automation and ethical compliance.​\n\nCase Studies:\n        Analyze implementations of LLM-based systems in real estate firms, assessing their impact on efficiency and compliance.​\n\nSurveys and Interviews:\n        Gather insights from industry professionals regarding the adoption of LLMs, perceived benefits, and ethical concerns.​\n\nEthical Framework Analysis:\n        Evaluate current AI governance frameworks in Singapore and their applicability to LLM deployment in real estate.​\n\nResearch Questions:\n\n    How can LLMs be effectively utilized to automate complex tasks in Singapore's real estate sector?​\n\n    What are the ethical implications of deploying LLMs in real estate practices, and how can compliance be ensured?​\n\n    What frameworks and guidelines are necessary to govern the use of LLMs in Singapore's real estate industry?​\n\nRelated Work\n   Madani, N., Bagalkotkar, A., Anand, S., Arnson, G., Srihari, R. K., &amp; Joseph, K. (2024). A Recipe For Building a Compliant Real Estate Chatbot.\n\n    Zillow Tech Hub. (2024). Navigating Fair Housing Guardrails in LLMs. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis study employs a mixed-methods approach, combining qualitative and quantitative analyses. Data will be collected through surveys and interviews with real estate professionals, alongside case studies of firms implementing LLMs. Ethical implications will be examined within the context of Singapore's AI governance frameworks.​\n\n(b) Development component\nThe research will involve developing a prototype LLM-based system tailored for Singapore's real estate industry. This system will automate tasks such as contract analysis and client communication, incorporating ethical guidelines to ensure compliance with local regulations.​",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Web-based Applications",
      "Natural Language Processing/ Text Mining",
      "Software and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0067",
    "title": "Adversarial attack Defenses for Neural Networks",
    "summary": "Adversarial attacks is a major threat towards practical deployment of neural networks. There are various countermeasures proposed to thwart such attacks with varying overheads and efficacy. The goal of this project is to study various adversarial attacks and develop their defenses.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0068",
    "title": "Protecting Neural Networks from Adversarial Attacks",
    "summary": "While a number of solutions for fast decisioning and inferencing on neural networks have been proposed in recent times, training a network remains a difficult task, often consuming days. The problem is likely to worsen due to data privacy, which mandates either the training to be done on an encrypted data-set, or to be done in a distributed manner with �whitening layer� added before integrating the multiple trained networks. The goal of this project is to set up a framework using OpenTPU and benchmarking the training time for various datasets. Subsequently, the training process needs to be optimised through batch-processing, hardware implementation, dynamic network tuning or a combination of the above.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0069",
    "title": "Efficient Quantum Circuit Design",
    "summary": "Due to the advent of Quantum computing, there is a tremendous growth in the space of algorithm design, technology development, design automation and circuit constructions. There are excellent open-source tools for simulating Quantum circuit, which allows one to implement basic Quantum algorithm, simulate those and perform benchmarking in terms of parameters like depth, size and quantum resources in general. During this project, the student will be assigned to study simple building blocks of a quantum circuit (e.g., multiplier) and obtain their performance numbers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Digital Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0070",
    "title": "Adversarial attack Defenses for Neural Networks",
    "summary": "Adversarial attacks is a major threat towards practical deployment of neural networks. There are various countermeasures proposed to thwart such attacks with varying overheads and efficacy. The goal of this project is to study various adversarial attacks and develop their defenses.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0071",
    "title": "Efficient Multi-Objective Peer-to-Peer Federated Learning",
    "summary": "Neural networks have become tremendously successful in recent times due to large computing power and availability of tagged datasets for various applications. Training these networks is computationally demanding and often requires proprietary datasets. Therefore, it is of major interest for unauthorised users to obtain the pre-trained models and sell it to third party for a premium. Watermarking is an effective way to prevent such usage. Although watermarking is an well known technique for IP ownership in several domains, establishing these techniques for neural networks will require careful study of adversarial models as well as practical usage of a model for the entire life cycle of it, including compression and transfer learning. The goal of this project is to study an existing watermarking technique proposed recently in [1,2], in terms of resilience, especially when the network size is small, and/or exhaustive weight perturbations are attempted.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0072",
    "title": "Efficient Quantum Circuit Design",
    "summary": "Due to the advent of Quantum computing, there is a tremendous growth in the space of algorithm design, technology development, design automation and circuit constructions. There are excellent open-source tools for simulating Quantum circuit, which allows one to implement basic Quantum algorithm, simulate those and perform benchmarking in terms of parameters like depth, size and quantum resources in general. During this project, the student will be assigned to study simple building blocks of a quantum circuit (e.g., multiplier) and obtain their performance numbers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Digital Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0073",
    "title": "Efficient Quantum Circuit Design",
    "summary": "Due to the advent of Quantum computing, there is a tremendous growth in the space of algorithm design, technology development, design automation and circuit constructions. There are excellent open-source tools for simulating Quantum circuit, which allows one to implement basic Quantum algorithm, simulate those and perform benchmarking in terms of parameters like depth, size and quantum resources in general. During this project, the student will be assigned to study simple building blocks of a quantum circuit (e.g., multiplier) and obtain their performance numbers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Digital Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0074",
    "title": "Peer-to-Peer Federated Learning",
    "summary": "Neural networks have become tremendously successful in recent times due to large computing power and availability of tagged datasets for various applications. Training these networks is computationally demanding and often requires proprietary datasets. One approach to resolve this issue is to perform local training and share the models with a layer of differential privacy in peer-to-peer networks. The goal of this project is to study the actual design of P2P FL networks, including the engineering aspects of Android application development.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Anupam Chattopadhyay",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0075",
    "title": "IntelliPrompt: An AI-Driven Personalized Learning Assistant for Prompt Engineering Skill Acquisition",
    "summary": "Recent research highlights the effectiveness of AI-driven personalized learning systems in adapting educational content. Tapalova &amp; Zhiyenbayeva (2022) explored AI in education, emphasizing machine learning and NLP for personalized instruction. Li (2024) examined AI-driven adaptive learning for second-language acquisition, demonstrating AI�s ability to optimize learning paths for individual needs.\n\nBuilding on these approaches, this research proposes IntelliPrompt, an AI-driven Personalized Learning Assistant for structured and adaptive Prompt Engineering skill acquisition. The system integrates personalized AI-driven learning pathways, interactive simulations, and real-time feedback to ensure learners develop and refine prompt engineering skills effectively.\nResearch Method\n\nData Collection &amp; Learning Analytics\n        Track learning interactions to analyze skill progression.\n        Apply NLP analytics to identify user challenges in prompt crafting.\nDevelop adaptive learning paths based on real-time performance.\n        Implement ML-based personalization models for content delivery.\n\nUse reinforcement learning to refine prompt engineering techniques.\n        Introduce scenario-based interactive modules for hands-on learning.\nConduct pre- and post-learning assessments to measure skill improvement.\n        Compare AI-guided learning vs. traditional self-learning effectiveness.\n\nTapalova &amp; Zhiyenbayeva�s AI-Personalized Learning Model: Tailoring AI-driven educational pathways.\n    Li�s AI-Driven Adaptive Learning Strategy: Enhancing structured, feedback-driven skill acquisition.\n\nResearch Questions\n    How effective is IntelliPrompt in enhancing personalized Prompt Engineering skill acquisition?\n    How does AI-driven adaptive learning compare to traditional self-learning in skill retention?\n    What impact does real-time AI-driven feedback have on learners� ability to refine prompts?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nhis research employs AI-driven personalization to create adaptive Prompt Engineering learning paths. It integrates Tapalova &amp; Zhiyenbayeva�s machine-learning-based education model with Li�s adaptive learning strategy to structure interactive, scenario-based training modules. Pre- and post-learning evaluations, interaction tracking, and comparative analysis will assess effectiveness.\n\n(b) Development component\nThe system will integrate AI-driven learning agents to guide users through prompt engineering fundamentals, optimization, and debugging. Reinforcement learning models will tailor feedback dynamically. Scenario-based simulations will allow users to experiment with different prompts and receive interactive feedback. AI-generated performance tracking metrics will refine content delivery based on user progress.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Machine Learning",
      "Software and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0076",
    "title": "Performing Follow-The-Regularized-Leader under Differential Privacy",
    "summary": "Privacy-preserving federated learning has garnered significant attention from both academia and industry. A leading algorithm in this area is Follow-The-Regularized-Leader (FTRL) under differential privacy (DP), commonly known as DP-FTRL. However, the current DP-FTRL approach often lacks practical utility. This project aims to enhance its effectiveness by applying instance-optimal techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Cyber Security",
      "Artificial Intelligence",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0077",
    "title": "Performing Stochastic Gradient Descent Algorithm under Differential Privacy",
    "summary": "Privacy-preserving federated learning has garnered significant attention from both academia and industry. A leading algorithm in this area is Stochastic Gradient Descent (SGD) under differential privacy (DP), commonly known as DPSGD. However, the current DPSGD approach often lacks practical utility. This project aims to enhance its effectiveness by applying instance-optimal DP techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Security",
      "Artificial Intelligence",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0078",
    "title": "Faith and Fate: The Role of Noise in Web Agents",
    "summary": "The rapid proliferation of Large Language Model (LLM)-based web agents, particularly those operating solely on the User Interface (UI) level, has significantly enhanced user interaction with the web, offering unparalleled accessibility and automation. However, this transformative technology introduces novel security challenges, especially since the majority of current research focuses on the increasingly prevalent UI-only paradigm. This paper investigates the dual role of ``noise'' � web elements imperceptible or irrelevant to humans but interpretable by UI-only agents � in both protecting and exploiting these agents. We explore two primary scenarios: ``Faith,'' where noise is strategically employed to prevent unauthorized agent actions like automated data scraping, and ``Fate,'' where noise is leveraged to mislead agents into performing malicious actions, such as clicking hidden advertisements or downloading malware. We delve into shallow attack techniques that exploit these vulnerabilities, demonstrating how subtle webpage modifications can manipulate the behavior of UI-only agents. Simultaneously, we propose deeper defense mechanisms that leverage an understanding of agent perception to mitigate these risks, focusing on both action generation and action grounding processes. We further analyze a case study of stealthy traffic redirection, where agents are subtly guided towards malicious content while the user remains unaware. This work aims to establish guiding principles for designing secure web agent interactions, emphasizing the need to balance usability with robust security measures in the face of evolving web threats, particularly within the context of UI-only agents. Our findings underscore the critical need for a paradigm shift in web security to address the unique challenges posed by the increasing prevalence of LLM-based, UI-only web agents, ensuring their responsible development and deployment.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0079",
    "title": "Benchmarking User Vulnerability to LLM-Driven Attacks: A User Study on Perceptions, Susceptibility, and Mitigation Strategies",
    "summary": "abstract: The rise of large language models (LLMs) has significantly impacted various sectors, from research to programming, enhancing productivity and facilitating complex tasks. However, this reliance on LLMs also exposes users to a range of potential threats, including phishing, misinformation, and social engineering attacks. This study investigates the vulnerability of users to LLM-driven attacks, exploring how different factors such as technical proficiency, trust in AI, and task complexity influence their susceptibility. We present an interactive framework designed to simulate and evaluate a variety of LLM-driven attacks, focusing on phishing, misleading content, and malicious code injection. Through a controlled user study involving diverse participants, we benchmark their responses to these attacks, assessing the effectiveness of different mitigation strategies. The study also examines the role of real-time feedback mechanisms, user education, and interface design in enhancing user resistance to deceptive LLM outputs. Our findings shed light on how user behaviors, demographics, and environmental factors impact the likelihood of falling victim to LLM-driven threats, providing valuable insights for the development of more robust security measures and user awareness programs. This research contributes to the growing body of work on AI safety and user protection in the context of emerging AI technologies.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0080",
    "title": "Secure and Private Data Valuation for Large Models",
    "summary": "In the era of large language models (LLMs), high-quality data has become a valuable commodity, with companies increasingly collecting, curating, and synthesizing datasets for sale. However, a major challenge in the data marketplace is that buyers cannot assess the true effectiveness of the data before making a purchase, leading to trust issues and inefficiencies. To address this, we need a novel framework for private data valuation that enables fair pricing and verification without exposing sensitive information or undermining the profits of both buyers and sellers. Our research explores cutting-edge techniques such as zero-knowledge proofs, differential privacy, and secure multi-party computation to design a secure and transparent data valuation mechanism.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0081",
    "title": "Multimodal foundation model diagnosis and improvement",
    "summary": "This project will focus on identifying limitations and constraints of existing multimodal large language models (MLLMs) and improving MLLMs by addressing the identified constraints and limitations.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0082",
    "title": "Multimodal image and video generation",
    "summary": "This project will focus on multimodal image or video generation given multimodal inputs such as descriptive text and initial and end images. The student is expected to reimplement existing methods and attempt to resolve identified problems if possible.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0083",
    "title": "Data-efficient 3D generation",
    "summary": "This project will explore data-efficient 3D generation techniques. The student is expected to reimplement state-of-the-art data-efficient 3D generation techniques and attempt to improve the generation quality.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0084",
    "title": "3D generation with Gaussian splatting",
    "summary": "This project will study 3D image generation with Gaussian splatting. The student is expected to reimplement state-of-the-art techniques and attempt to address existing problems in large-scene modeling, \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0085",
    "title": "Large vision language models",
    "summary": "This project will focus on large vision language models. The student will work on vision-language data and develop relevant techniques on hallucination from inter-object relations, etc.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0086",
    "title": "Multimodal large language models",
    "summary": "This project will focus on multimodal large language models and its applications in various real-world problems. The student is expected to work on multimodal data and related tasks such as reinforcement learning with human feedback (RLHF).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0087",
    "title": "3D Generation with NeRF",
    "summary": "This project will develop advanced 3D generation techniques that exploits neural radiance fields (NeRF) that have superior multi-view consistency as compared with GANs or traditional computer vision techniques. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0088",
    "title": "3D point cloud analytics",
    "summary": "This project will develop deep neural networks that is capable of performing object detection and segmentation by using 3D point cloud. The technique is very useful to autonomous driving.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0089",
    "title": "Multimodal reasoning",
    "summary": "This project will study how to reason the explicit and implicit human intensions given natural language instructions and natural images as inputs. The student is expected to examine and benchmark existing multimodal reasoning techniques and/or design possible solutions to various problems with existing multimodal reasoning algorithms.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0090",
    "title": "Multimodal 3D perception",
    "summary": "This project will develop multimodal 3D perception networks that enable 3D perception according to natural language instructions. Students are expected examine and benchmark existing 3D scene segmentation and/or 3D object detection techniques given natural language instructions about 3D objects/scenes. They may also design new solutions to various problems in multimodal 3D perception.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0091",
    "title": "Multimodal robot path/route planning",
    "summary": "This project will study multimodal robot path/route planning based on implicit/explicit human natural language instructions.  It will investigate how to optimally decompose  human instructions into multiple executable steps and how to optimally plan inter-step routes for achieving the natural language instructions by robots.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lu Shijian",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0092",
    "title": "Verified Compiler Bootstrap in Lean",
    "summary": "CakeML (https://cakeml.org/) is a formally verified compiler, i.e., it comes\nwith a proof that the compiler will never miscompile input programs. This\nstrong correctness guarantee adds a layer of trust in developing\nsafety-critical applications.  Notably, Myreen (CPP,2021) showed how to build a\nminimalistic verified bootstrap compiler; a variant of this approach has been\napplied to CakeML using the HOL4 proof assistant\n(https://www.cse.chalmers.se/~myreen/cpp2021-bootstrap-myreen.pdf).\n\nIn this project, the student will try to port these ideas over to the Lean\nproof assistant and explore the challenges in building a similar bootstrapping\npathway in this new setting. This project is most suitable for students who\nhave strong background in functional programming / theorem proving / formal\nmethods.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n- The student will be learning Lean and also exploring the differences between HOL4 (a simply typed proof assistant) and Lean (a dependently typed proof assistant), in terms of their support for compiler bootstrapping.\n\n(b) Development component\n\n- The student will build a bootstrapping compiler, as described in the linked paper.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Programming Languages &amp; Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0093",
    "title": "Verifying a Verification Condition Generator",
    "summary": "A verification condition generator (VCG) takes an input program (e.g., C, C++,\nRust) along with a correctness assertion and/or annotations; it outputs certain\nlogical formulas which, if proven by an external tool, guarantees the\ncorrectness of the input.\n\nAn interesting question is whether the VCG itself is generating correct\nconditions for the input program. This project aims to answer this by formally\nverifying an efficient VCG tool using theorem proving and CakeML\n(https://cakeml.org/). This project is most suitable for students who have\nbackground in at least one of these topics: functional programming / theorem\nproving / formal methods.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThe student will need to learn basic VC generation techniques and theorem proving.\n\n(b) Development component\n\nThe student will be applying the above research and learning towards building a verified VC generator.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0095",
    "title": "Implementing and Verifying a Compiler Pass for CakeML",
    "summary": "This project is about developing a simple compiler optimization in the CakeML\nproject. This optimization will need to be proven correct and integrated into\nthe CakeML compiler. This project is suitable for students who wish to learn\ncompiler verification and have strong background in functional programming\nand/or compiler development.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThe student will learn how to use a theorem prover (HOL4) and also how to carry out formal reasoning about compiler correctness.\n\n(b) Development component\n\nThe student will be developing a verified compiler pass.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0096",
    "title": "Formalized Mathematics (Towards Mechanizing 1000 Theorems)",
    "summary": "Theorem proving is about writing mathematical results/proofs in a formal,\ncomputer-checkable language; formal proofs have gained significant popularity\nin mathematics and in AI, e.g., it was used recently by Google Deepmind as the\nbacking language for AlphaProof.\n\nIn this project, the student will learn to use a proof assistant, such as\nIsabelle/HOL or Lean, to mechanize one of the proofs in this list\n(https://1000-plus.github.io/all). The choice of result to be formalized will\nbe discussed with the supervisor.  This project is suitable for students who\nwish to pick up theorem proving and have strong background in mathematics.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThe student will be learning how to use a proof assistant.\n\n(b) Development component\n\nThe student will be developing one formal proof from the aforementioned list in the proof assistant.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0097",
    "title": "Exploring Trifferent Codes with Combinatorial Solvers",
    "summary": "The trifferent code problem asks, for each given n, the largest possible size\n|C| of a set C of length n strings over {0,1,2} such that every 3 distinct\nelements in C have a position where they all differ. For example, for n = 2,\nthe maximum size of C is 4 (try it yourself!).\n\nThis project is about applying combinatorial solvers to verify various bounds\non |C|. This project is best suited to a theory-oriented student, who can\nexpect to learn about symbolic AI topics such as SAT/SMT encodings and how to\nuse various state-of-the-art combinatorial solvers.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n- The student will be reading on SAT encoding techniques, learning about state-of-the-art solvers, and applying them towards the aforementioned problem.\n\n(b) Development component\n\n- The student will be coding simple scripts to carry out the encodings and to interface with the solvers.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Theory &amp; Algorithms",
      "Logic and Formal Methods"
    ]
  },
  {
    "projectNo": "CCDS25-0098",
    "title": "Formalization of tabulation hashing in a proof assistant",
    "summary": "This project involves concepts from two related areas of theoretical computer\nscience.  Firstly, tabulation hashing is an important example of a 3-wise\nindependent hash family, i.e., it can be used as a central ingredient for\nproving the correctness of randomized algorithms that rely on this independence\nproperty.  Secondly, theorem proving is about writing mathematical\nresults/proofs in a formal, computer-checkable language; formal proofs have\ngained significant popularity in mathematics and in AI, e.g., it was used\nrecently by Google Deepmind as the backing language for AlphaProof. In this\nFYP, the student will learn to use a proof assistant and apply it towards\nwriting a formal proof of the 3-wise independence of tabulation hashing.\n\nIn this project, the student will learn to use a proof assistant, such as\nIsabelle/HOL or Lean, to prove the aforementioned 3-wise independence property.\nThis project is suitable for students with strong background/interest in\nfunctional programming, formal methods, or theoretical aspects of computer\nscience. \n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n- The FYP will involve applying theorem provers towards a new application (tabulation hashing). This will likely involve building new libraries, especially for working with probabilistic statements.\n\n(b) Development component\n\n- The student is expected to follow and complete a mechanization of the 3-wise independence property for basic tabulation hashing. Extensions beyond classical tabulation hashing can be left as a stretch goal.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0099",
    "title": "A Robustness Evaluation Framework for Code Watermarking",
    "summary": "LLM-based code generation models like CodeGen, Code Llama, and StarCoder have shown significant potential in automating software development. To protect the intellectual property of generated code, various watermarking techniques have been introduced to verify code ownership. However, existing methods for evaluating watermark robustness are insufficient. Current research primarily tests proposed watermarking methods against simple attacks like re-watermarking, de-watermarking, and random removal, which fail to provide a comprehensive assessment of robustness. A key task is to design effective code watermark attacks that exploit the unique properties of watermarks (e.g., grammar, semantic) and integrate these attacks into a unified framework to thoroughly evaluate the robustness of code watermarks. Addressing this challenge is critical for enabling practical IP protection of code watermarks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "System Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0100",
    "title": "Discovering the Vulnerabilities in LLM Reasoning",
    "summary": "Chain-of-Thought (CoT) has become a key strategy for improving large language models (LLMs) in complex reasoning tasks, including recent advancements like GPT-o1 and Deepseek-R1. Despite its effectiveness, little research has explored vulnerabilities in reasoning, which may lead to serious consequences. Reasoning-based LLMs are particularly susceptible to complex jailbreak attacks that can mislead the model into generating harmful or biased content. Moreover, the increased length of CoT sequences introduces significant computational overhead. A key task is to design targeted attacks that exploit vulnerabilities in the CoT reasoning process, such as logical inconsistencies and misleading intermediate steps, and develop effective defense mechanisms to strengthen reasoning integrity. Addressing this challenge is essential for ensuring the reliability and security of LLM-based reasoning systems.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Security",
      "System Security"
    ]
  },
  {
    "projectNo": "CCDS25-0101",
    "title": "Online Life-Long Learning App with Personalized Recommendation (I)",
    "summary": "Singapore government is promoting life-long learning that every person should continue their learning at any time, anywhere and their own pace. This can be achieved by an online learning app that integrates learning materials from various sources. In addition, the App should be equipped with the functionality of automatically pushing learning materials to each learner, depending on their preferences, levels, degree or certificate that they are currently pursuing. To encourage them to learn, this App should also have a credit system to record how much each learner has achieved and awards the learner a degree or certificate when the requirement is fulfilled. \n\nSpecific details:\n(a) Design component\n\nDesign the credit mechanism for the App, as well as the recommendation functionality. \n\n(b) Implementation component\n\nImplement the App with those functionalities. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Smartphone Systems and Applications",
      "Artificial Intelligence",
      "e-Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0102",
    "title": "Online Life-Long Learning App with Personalized Recommendation (II)",
    "summary": "Singapore government is promoting life-long learning that every person should continue their learning at any time, anywhere and their own pace. This can be achieved by an online learning app that integrates learning materials from various sources. In addition, the App should be equipped with the functionality of automatically pushing learning materials to each learner, depending on their preferences, levels, degree or certificate that they are currently pursuing. To encourage them to learn, this App should also have a credit system to record how much each learner has achieved and awards the learner a degree or certificate when the requirement is fulfilled. \n\nSpecific details:\n(a) Design component\n\nDesign the credit mechanism for the App, as well as the recommendation functionality. \n\n(b) Implementation component\n\nImplement the App with those functionalities. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Smartphone Systems and Applications",
      "Artificial Intelligence",
      "e-Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0103",
    "title": "Online Life-Long Learning App with Personalized Recommendation (III)",
    "summary": "Singapore government is promoting life-long learning that every person should continue their learning at any time, anywhere and their own pace. This can be achieved by an online learning app that integrates learning materials from various sources. In addition, the App should be equipped with the functionality of automatically pushing learning materials to each learner, depending on their preferences, levels, degree or certificate that they are currently pursuing. To encourage them to learn, this App should also have a credit system to record how much each learner has achieved and awards the learner a degree or certificate when the requirement is fulfilled. \n\nSpecific details:\n(a) Design component\n\nDesign the credit mechanism for the App, as well as the recommendation functionality. \n\n(b) Implementation component\n\nImplement the App with those functionalities. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Smartphone Systems and Applications",
      "Artificial Intelligence",
      "e-Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0104",
    "title": "Online Secure Payment for Membership System (III)",
    "summary": "For a membership based online system, members need to pay for their membership fees in an annual basis. Thus, having a secure payment mechanism is crucial for the success of these systems. In this project, you will be implementing several state-of-the-art secure online payment methods that are commonly used. Members will have privilege to access certain resources. They will also be able to purchase various items in this membership system. \n\nSpecific details:\n(a) Design component\n\nYou will design various access levels for members and non-members. Certain resources are only accessible by members. \n\n(b) Implementation component\n\nYou will be implementing the membership system with several state-of-the-art secure online payment methods that are commonly used.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "e-Commerce",
      "Cyber Security",
      "Data Security",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0105",
    "title": "Online Secure Payment for Membership System (II)",
    "summary": "For a membership based online system, members need to pay for their membership fees in an annual basis. Thus, having a secure payment mechanism is crucial for the success of these systems. In this project, you will be implementing several state-of-the-art secure online payment methods that are commonly used. Members will have privilege to access certain resources. They will also be able to purchase various items in this membership system. \n\nSpecific details:\n(a) Design component\n\nYou will design various access levels for members and non-members. Certain resources are only accessible by members. \n\n(b) Implementation component\n\nYou will be implementing the membership system with several state-of-the-art secure online payment methods that are commonly used.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "e-Commerce",
      "Cyber Security",
      "Data Security",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0106",
    "title": "Online Secure Payment for Membership System (I)",
    "summary": "For a membership based online system, members need to pay for their membership fees in an annual basis. Thus, having a secure payment mechanism is crucial for the success of these systems. In this project, you will be implementing several state-of-the-art secure online payment methods that are commonly used. Members will have privilege to access certain resources. They will also be able to purchase various items in this membership system. \n\nSpecific details:\n(a) Design component\n\nYou will design various access levels for members and non-members. Certain resources are only accessible by members. \n\n(b) Implementation component\n\nYou will be implementing the membership system with several state-of-the-art secure online payment methods that are commonly used.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "e-Commerce",
      "Cyber Security",
      "Data Security",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0107",
    "title": "Development of an AI-Powered Exchange Platform (II)",
    "summary": "In this project, the student needs to participate in the development of an AI-powered exchange platform. This platform is used for investors to conduct investments and manage their portfolio.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nnew learning-to-rank algorithms for ranking users for Whom-to-Follow\n\nnew methods to infer users' preference from their implicit feedback\n\n(b) Development component\n\nDevelop the above methods and test on real data",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "e-Commerce",
      "Data Analytics",
      "Data Mining",
      "Web-based Applications",
      "Social Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0108",
    "title": "Development of an AI-Powered Exchange Platform (I)",
    "summary": "In this project, the student needs to participate in the development of an AI-powered exchange platform. This platform is used for investors to conduct investments and manage their portfolio.  \n\nSpecific details:",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0109",
    "title": "App for Communication and Material Sharing (II)",
    "summary": "In this project, the student needs to design and develop an app to manage member information of a group and provide communication and material sharing services to users. The database is also created. \n\nSpecific details:",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0110",
    "title": "App for Communication and Material Sharing (I)",
    "summary": "In this project, the student needs to design and develop an app to manage member information of a group and provide communication and material sharing services to users. The database is also created. \n\nSpecific details:",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0111",
    "title": "Real estate app development and recommendation (I)",
    "summary": "In this project, the student needs to design and develop an app to manage real estate information and provide recommendation of houses to users. The database is also created. \n\nSpecific details:",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0112",
    "title": "Real estate app development and recommendation (II)",
    "summary": "In this project, the student needs to design and develop an app to manage real estate information and provide recommendation of houses to users. The database is also created. \n\nSpecific details:",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0113",
    "title": "App for Communication and Material Sharing (III)",
    "summary": "In this project, the student needs to design and develop an app to manage member information of a group and provide communication and material sharing services to users. The database is also created. \n\nSpecific details:",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0114",
    "title": "Real estate app development and recommendation (III)",
    "summary": "In this project, the student needs to design and develop an app to manage real estate information and provide recommendation of houses to users. The database is also created. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nnew learning-to-rank algorithms for ranking users for Whom-to-Follow\n\nnew methods to infer users' preference from their implicit feedback\n\n(b) Development component\n\nDevelop the above methods and test on real data",
    "supervisor": "Prof Zhang Jie",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "e-Commerce",
      "Data Analytics",
      "Data Mining",
      "Web-based Applications",
      "Social Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0115",
    "title": "Full Stack Development & Deployment of ASR-GUI Text-to-Speech Application",
    "summary": "The aim of this project is to develop a chat-bot using open source chat-bot stack\nto perform Q&amp;A of\ntargetted domain, a digital assistant such as Call Jamie for an organization to perform tasks to deal with complaint, appointment changes, etc.\n\nThe student will be working with existing team in MML Lab to perform this work.\n\nYou will learn about chat-bot and NLP technologies, as well as information extraction.\n\nSpecific details:\nApplication of speech-&gt;text and NLP with dialogue management.",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Natural Language Processing/ Text Mining",
      "Multimedia Systems",
      "Data Analytics",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0116",
    "title": "SG Decoding Full-stack development for ASR",
    "summary": "form filling application with speech as input.\nthis is a software development project\nThe student will work with the team of engineers, and examine different hotword implemetation of ASR to solve rare-words appearance.\n\nSpecific details:",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Video/Audio/Speech Processing",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0117",
    "title": "Docker Swarm and Kubernetes : deploying speech recognition workers for scalability",
    "summary": "Currently we have a speech recognition engine for online speech recognition like google-speech sdk - we wish to improve its scaling such that it can support dynamic increase in load (more phone calls) requesting for its service.\n\nSpecific details:\nArchitecting existing SDK supporting speech recognition api of our speech engine based on kaldi to use docker swarm and kubernetes to support growth in usage.",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0118",
    "title": "Scaling for SGDecoding web application",
    "summary": "Currently we have a speech recognition engine for online speech recognition like google-speech sdk - we wish to improve its scaling such that it can support dynamic increase in load (more phone calls) requesting for its service.\n\nSpecific details:\nArchitecting existing SDK supporting speech recognition api of our speech engine based on kaldi to use docker swarm and kubernetes to support growth in usage.",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0119",
    "title": "Setting up of infrastructure for Speechlab Applications with Terraform and Terragrunt",
    "summary": "Currently we have a speech recognition engine for online speech recognition like google-speech sdk - we wish to improve its scaling such that it can support dynamic increase in load (more phone calls) requesting for its service.\n\nSpecific details:\nArchitecting existing SDK supporting speech recognition api of our speech engine based on kaldi to use docker swarm and kubernetes to support growth in usage.",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0120",
    "title": "Audio event classification using DNN approaches",
    "summary": "The aim of this project is to examine existing state of the art image captioning tools:\nhttps://paperswithcode.com/task/image-captioning\nand if possible improve and\nintegrate it to our existing video search system via image caption.\n\nThe student must be very keen in machine learning and natural language processing.\n\nSpecific details:",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Data Analytics",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0121",
    "title": "Emotion analysis from speech",
    "summary": "DNN algorithm for speech emotion classification.\nModern DNN techniques have been shown to be very good for image analysis. In this work, the work is to examine the same type of algorithm and use it to analyse speech features for emotion analysis\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nLit survey of recent works in speech emotion recognition.\n\n\n(b) Development component\nUsing existing code-base and extension of it for implementation.",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0122",
    "title": "LLM for dialogue summarization and diarization",
    "summary": "LLM has shown to be able to analyse and process text very well. In this project, student will examine existing open sourced LLM for the above 2 tasks To compare its performance under different  conditions such as (memory footprint/model size) conditions.  \n\nAdditionally, the student will also explore and fine/tune the AISG SEALION model  for under-resourced languages.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nFine Tune LLM for diarization and summarization task.\n\n(b) Development component\n\n\nCompare and contrast various LLM�s performance on under-resourced languages.",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0123",
    "title": "Full Stack Development and Deployment of Web-based Speech recognition System",
    "summary": "LLM has shown to be able to analyse and process text very well. In this project, student will examine existing open sourced LLM for the above 2 tasks To compare its performance under different  conditions such as (memory footprint/model size) conditions.  \n\nAdditionally, the student will also explore and fine/tune the AISG SEALION model  for under-resourced languages.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nFine Tune LLM for diarization and summarization task.\n\n(b) Development component\n\n\nCompare and contrast various LLM�s performance on under-resourced languages.",
    "supervisor": "Prof Chng Eng Siong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0124",
    "title": "A critical study on datasets for Recommender System",
    "summary": "This is a research project. The student is expected to conduct experiments on some  well known datasets (e.g., Yelp, Amazon) by running multiple baseline recsys models. \n\nSpecific details:\n(a) Design component\nThe evaluation protocol \n\n(b) Implementation component\nThe various baseline recsys models from KNN to MF, then deep learning models like NeuMF, LightGCN\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sun Aixin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0125",
    "title": "Development of a RecSys evaluation platform (Part  2)",
    "summary": "This project requires the student to be familiar with the evaluation of recommender models and the available toolkits, particularly on their data partitioning and evaluation settings. Then to design and implement a new evaluation platform.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sun Aixin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0126",
    "title": "Deep Learning Methods with Less Supervision",
    "summary": "Deep learning has achieved tremendous success for visual recognition in recent years. Deep network based methods are shown to outperform humans on the large-scale image classification dataset ImageNet. However, most deep learning methods focus on fully supervised learning tasks which usually require intensive hand labelling effort for creating training data. Especially for dense prediction tasks like semantic segmentation, it requires a large amount of accurate per-pixel annotations to construct training data for learning deep models, and thus needs expensive or even unaffordable human labelling effort and limits its real-world applications.  To reduce the labelling effort, this project aims to develop effective weakly supervised learning and few-shot learning methods which require much less supervision information for visual recognition problems including semantic segmentation and object detection. The interested candidates should have their own GPU computation resources.\n\nSpecific details:\n(a) Design component\nDeep Convolutional Neural Networks\n\n(b) Implementation component\nDeep Convolutional Neural Networks\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lin Guosheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0127",
    "title": "Controllable Image Generation and Editing",
    "summary": "The spotlight on visual content generation has intensified in recent years, with its immense potential spanning across applications such as data augmentation, design, filmmaking, animation, gaming, AR/VR, and social media. This project sets out to pioneer the development of innovative algorithms for controllable image generation and editing, based on diffusion, GANs, and other cutting-edge generation frameworks. We will explore different types of control signals, such as text descriptions, reference images, box layouts, and style images, to control the image generation process.  The candidates are required to have their GPU resources for deep network training (e.g.,  GTX 3080 or above).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lin Guosheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0128",
    "title": "Controllable Image Generation and Editing",
    "summary": "The spotlight on visual content generation has intensified in recent years, with its immense potential spanning across applications such as data augmentation, design, filmmaking, animation, gaming, AR/VR, and social media. This project sets out to pioneer the development of innovative algorithms for controllable image generation and editing, based on diffusion, GANs, and other cutting-edge generation frameworks. We will explore different types of control signals, such as text descriptions, reference images, box layouts, and style images, to control the image generation process.  The candidates are required to have their GPU resources for deep network training (e.g.,  GTX 3080 or above).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lin Guosheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0129",
    "title": "Controllable Image Generation and Editing",
    "summary": "The spotlight on visual content generation has intensified in recent years, with its immense potential spanning across applications such as data augmentation, design, filmmaking, animation, gaming, AR/VR, and social media. This project sets out to pioneer the development of innovative algorithms for controllable image generation and editing, based on diffusion, GANs, and other cutting-edge generation frameworks. We will explore different types of control signals, such as text descriptions, reference images, box layouts, and style images, to control the image generation process.  The candidates are required to have their GPU resources for deep network training (e.g.,  GTX 3080 or above).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lin Guosheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0130",
    "title": "Controllable Image Generation and Editing",
    "summary": "The spotlight on visual content generation has intensified in recent years, with its immense potential spanning across applications such as data augmentation, design, filmmaking, animation, gaming, AR/VR, and social media. This project sets out to pioneer the development of innovative algorithms for controllable image generation and editing, based on diffusion, GANs, and other cutting-edge generation frameworks. We will explore different types of control signals, such as text descriptions, reference images, box layouts, and style images, to control the image generation process.  The candidates are required to have their GPU resources for deep network training (e.g.,  GTX 3080 or above).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lin Guosheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0131",
    "title": "Deep Learning Methods with Less Supervision",
    "summary": "Deep learning has achieved tremendous success for visual recognition in recent years. Deep network based methods are shown to outperform humans on the large-scale image classification dataset ImageNet. However, most deep learning methods focus on fully supervised learning tasks which usually require intensive hand labelling effort for creating training data. Especially for dense prediction tasks like semantic segmentation, it requires a large amount of accurate per-pixel annotations to construct training data for learning deep models, and thus needs expensive or even unaffordable human labelling effort and limits its real-world applications.  To reduce the labelling effort, this project aims to develop effective weakly supervised learning and few-shot learning methods which require much less supervision information for visual recognition problems including semantic segmentation and object detection. The interested candidates should have their own GPU computation resources.\n\nSpecific details:\n(a) Design component\nDeep Convolutional Neural Networks\n\n(b) Implementation component\nDeep Convolutional Neural Networks\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lin Guosheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0132",
    "title": "Controllable Image Generation and Editing",
    "summary": "The spotlight on visual content generation has intensified in recent years, with its immense potential spanning across applications such as data augmentation, design, filmmaking, animation, gaming, AR/VR, and social media. This project sets out to pioneer the development of innovative algorithms for controllable image generation and editing, based on diffusion, GANs, and other cutting-edge generation frameworks. We will explore different types of control signals, such as text descriptions, reference images, box layouts, and style images, to control the image generation process.  The candidates are required to have their GPU resources for deep network training (e.g.,  GTX 3080 or above).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lin Guosheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0133",
    "title": "RISC-V processor FPGA implementation",
    "summary": "This project involves the design and implementation of a RISC-V processor on a FPGA board for educational purposes. The project is more suitable for CE student.\n\nSpecific details:\n(a) Design component\nCustomization of RISC-V IP\n\n(b) Implementation component\nImplementing the RISC-V based processor on an FPGA \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Vun Chan Hua, Nicholas",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Architecture",
      "Field Programmable Gate Arrays (FPGA)",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0135",
    "title": "Data visualization with Python Programming in Excel",
    "summary": "This project is to use python programming within excel to implement query function and data visualization. The use case is for timetable planning system.  \n\nSpecific details:\n(a) Design component\n\nTo consider UI requirements in the system design\n\n(b) Implementation component\n\nTo integrate Python programming with Excel data\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Vun Chan Hua, Nicholas",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0136",
    "title": "Virtual assembling using hand tracking with the desktop haptic device 3DSystems Touch",
    "summary": "In this project the student will design and develop virtual assembling in Unity 3D system using the desktop haptic device 3DSystems Touch \n\n   First, the student will learn how the desktop happy device works to  track the position of hand and return back the haptic force. Next, the student will learn how the device can be used together with Unity3D system.\n   Next, the student will need to design the user interaction based on the study performed. The interaction should reliably simulate real-life assembling operations which are performed by the virtual tools controlled by the haptic device. The interaction has to be performed using the help of Unity 3D physics engine which computes collision detection of the virtual fingers with the objects. \n   Finally, a user study has to be done to verify whether virtual interaction is as good as real-life interaction when performing assembling operations.\n\nThe project can be performed on home PC/notebook.\n\nRequirements: programming using C/C++. \nRefer to http://unity3d.com\nhttps://www.3dsystems.com/haptics-devices/openhaptics\n\nSpecific details:\nTo design and implement the haptic interaction and the virtual scene for the user testing.",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0137",
    "title": "Virtual sculpting using hand tracking with Leap Motion controller",
    "summary": "In this project the student will design and develop virtual sculpting in Unity 3D system using hand tracking by Leap Motion controller.\n\n   First, the student will learn how Leap Motion controller can track hands and will understand how well it can be used for simulating virtual sculpting operations where the solid object has to be picked up, positioned and deformed by one or two hands.\nNext, the student will learn how Leap Motion controller can be used together with Unity3D system.\n   Next, the student will need to design the user interaction based on the study performed. The interaction should reliably simulate real-life sculpting operations which are performed by hands on top of table. The interaction has to be performed using the help of Unity 3D physics engine which computes collision detection of the virtual fingers with the objects. However, the student will need to design and implement measures compensating for luck of physical feedback forces which can be felt by the user.\n   Finally, a user study has to be done to verify whether virtual sculpting is as good as real-life sculpting.\n\nThe project can be performed on home PC/notebook.\n\nRequirements: programming using C/C++. \nRefer to http://unity3d.com\n\nSpecific details:\nTo design and implement hand gestures and the virtual scene for the user testing.",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0139",
    "title": "Virtual carving using the desktop haptic device 3DSystems Touch",
    "summary": "In this project the student will design and develop virtual carving  in Unity 3D system using the desktop haptic device 3DSystems Touch.\n\n   First, the student will learn how the desktop haptic device 3DSystems Touch can track hands and will understand how well it can be used for simulating virtual carving operations where the solid object has to be picked up, positioned and deformed by a virtual tool.\n   Next, the student will learn how the desktop haptic device 3DSystems Touch can be used together with Unity3D system.\n   Next, the student will need to design the user interaction based on the study performed. The interaction should reliably simulate real-life carving operations which are performed by hands on top of table. The interaction has to be performed using the help of Unity 3D physics engine which computes collision detection of the virtual tool with the objects. \n   Finally, a user study has to be done to verify whether virtual carving is as good as real-life carving.\n\nThe project can be performed on home PC/notebook.\n\nRequirements: programming using C/C++. \nRefer to http://unity3d.com\nhttps://www.3dsystems.com/haptics-devices/openhaptics\n\nSpecific details:\nTo design and implement virtual carving operations and the virtual scene for the user testing.",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0140",
    "title": "Virtual painting using hand tracking with Leap Motion controller",
    "summary": "In this project the student will design and develop virtual painting in Unity 3D system using hand tracking by Leap Motion controller.\n\n   First, the student will learn how Leap Motion controller can track hands and will understand how well it can be used for simulating virtual painting operations where the solid object has to be picked up, positioned and painted (airbrush and paintbrush) by one or two hands.\n   Next, the student will learn how Leap Motion controller can be used together with Unity3D system.\n   Next, the student will need to design the user interaction based on the study performed. The interaction should reliably simulate real-life painting operations which are performed by hands on top of table. The interaction has to be performed using the help of Unity 3D physics engine which computes collision detection of the virtual fingers with the objects. However, the student will need to design and implement measures compensating for luck of physical feedback forces which can be felt by the user.\n   Finally, a user study has to be done to verify whether virtual painting is as good as real-life painting.\n\nThe project can be performed on home PC/notebook.\n\nRequirements: programming using C/C++. \nRefer to http://unity3d.com\n\nSpecific details:\nTo design and implement hand gestures and the virtual scene for the user testing.",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0141",
    "title": "Prediction of Box Office Revenue of Movies",
    "summary": "The movie box office is determined by a myriad of factors, such as the influence of star actors or actresses,  the time of release, position in a multi-movie franchise, quality of the screenplay, and so on. \n\nIn this project, we will explore the use of deep neural networks to predict box office from data available prior to the movie release. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nInvestigating and experimenting with neural networks to figure out the best way to make the predictions. \n\n(b) Development component\n\nCrawling movie data from websites",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Data Mining",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0142",
    "title": "Language Dataset Construction in Thai, Tagalog, or Lao (Laotian)",
    "summary": "The student must have working knowledge of any of the three languages to take on this project.\n\nThe student will build a web crawler to collect language data from public websites featuring high-quality text. \n\nSpecific details:\n(a) Design component\n\nIdentify websites with high-quality data.\nDesign a web crawler.\n\n(b) Implementation component\n\nImplement and deploy the web crawler.\n[Optional] Train a small neural language model as a validation step. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Computer Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0143",
    "title": "Recognizing Text on Maps",
    "summary": "Maps are a special form of data presentation that combines imagery and text. As such, performing optical character recognition on maps poses its unique challenges. \n\nIn this project, the student is expected to:\n\n- Annotate a sufficient number of text on a collection of maps\n- Develop a neural network that recognizes text from maps. \n- Evaluate the performance of the developed approach.\n- [Optional] Investigate ways to improve the neural network.\n\nThis project requires a significant level of learning on neural networks and computer vision. Students with strong motivation and intellectual curiosity are encouraged to apply. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n- Investigate ways to improve the neural network.\n\n(b) Development component\n\n- Annotate a sufficient number of text on a collection of maps\n- Develop a neural network that recognizes text from maps. \n- Evaluate the performance of the developed approach.",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0144",
    "title": "Annotating Layouts of Scientific Papers (Part 1)",
    "summary": "In this project, you will be asked to label the different components of scientific papers written in different languages, including various Asian languages and European languages.\n\n[Optional] A capable student can finetune an existing neural network to identify the components from the page images. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nFinetuning an existing neural network\n\n(b) Development component\n\nAnnotating the components from the page images.",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0145",
    "title": "Annotating Layouts of Scientific Papers (Part 2)",
    "summary": "In this project, you will be asked to label the different visual components of scientific papers written in different languages, including various Asian languages and European languages. Examples of these components include: title, abstract, author list, header, footer, etc. \n\n[Optional] A capable student can finetune an existing neural network to identify the components from the page images. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nFinetuning an existing neural network\n\n(b) Development component\n\nAnnotating the components from the page images.",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0146",
    "title": "Classifying Meme and Non-meme Images (Part 1）",
    "summary": "In this project, you will be asked to build neural networks that classify images from the internet as either memes or non-memes. For the meme images, you will also need to identify the language of the meme. \n\nA meme is defined as an image that was posted for entertainment or shocking purposes, and with the hope that it may go viral or receive many likes on social networks. \n\nWe have a small set of images but the student may have to collect more images or annotate some by themselves. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nBuilding and training the neural network\n\n(b) Development component\n\nAnotation and collection of data.",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0147",
    "title": "Classifying Meme and Non-meme Images (Part 2）",
    "summary": "In this project, you will be asked to build neural networks that classify images from the internet as either memes or non-memes. For the meme images, you will also need to identify the language of the meme. \n\nA meme is defined as an image that was posted for entertainment or shocking purposes, and with the hope that it may go viral or receive many likes on social networks. \n\nWe have a small set of images but the student may have to collect more images or annotate some by themselves. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nBuilding and training the neural network\n\n(b) Development component\n\nAnotation and collection of data.",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0148",
    "title": "Extracting Event Knowledge from Pretrained Language Models Such as ChatGPT",
    "summary": "In the past few years, a major driver for performance improvements of neural networks, especially those that process natural language,  is the rapid increase in their size. Large networks trained on gigantic text datasets, such as ChatGPT, have demonstrated excellent performance on a large number of tasks. \n\nIntuitively, these neural networks possess enormous amount of knowledge in their parameters, but it is difficult to extract the knowledge in a human-understandable form and to quantify exactly what kind of event knowledge exists in such networks.\n\nIn this project, the student will attempt to design different types of textual queries, known as \"prompts\", which can extract event knowledge from pretrained language models. For example, one may ask the neural network \"what would Alice  typically do after she wakes up in the morning\", in order to gather an event sequence or an event graph. \n\nThe student will examine and categorize the extracted knowledge, and evaluate the knowledge by comparing them to external knowledge graphs. \n\nThe student should possess some working knowledge of neural networks, or be ready to learn substantial amount of new knowledge. Attention to detail is necessary. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n- Investigate new types of model prompts that can extract event knowledge from pretrained language models.\n\n- Create methods that compare the extracted event knowledge against external event knowledge graphs or QA datasets. \n\n(b) Development component",
    "supervisor": "A/P Li Boyang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0149",
    "title": "Non-Conflict Reviewers Selection System - A Graph-based Technique",
    "summary": "This project focuses on an intriguing problem that has remained unsolved in any research community. Given a paper submitted to a conference/journal venue, how can you determine who are the \"best\" reviewers for it? By \"best\", we do not only mean a reviewer who is an expert in the area related to the paper, but also who is impartial and do not have any direct or indirect social connection (\"guanxi\") with the authors of the paper. In this project, the candidate shall develop and implement a system that mines publicly-available DBLP data related to co-authorship network to predict \"best\" reviewers for a paper. The project requires solid understanding in data mining and strong programming skills in Java. \n\nSpecific details:",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0150",
    "title": "Efficient and Scalable Processing of Visual Property Graph Queries",
    "summary": "The project is on design and implementation of a data-driven system. The specific system to be designed and implemented is open for discussion. The candidate can propose his/her own project based on his/her interest. Only constraints are (a) it has to be based on database or data analytics technology (non-Machine Learning), (b) it has to be interesting and (c) it must be substantial enough to cover the duration of FYP. You are strongly advised to discuss with me before selecting the project.\n\nSpecific details:\n(a) Design component\n\nDesign of the proposed system\n\n(b) Implementation component\n\nImplementation using Java or Python\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Data Analytics",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0151",
    "title": "Network Embedding for Drug Target Discovery in Cancer Signaling Network: A Machine Learning-based Approach",
    "summary": "The goal of target combination prediction in signaling networks is to predict target (nodes) combinations that can effectively modulate a set of disease nodes in order to achieve a specifi\fc therapeutic goal (e.g., reducing the activity of ERKPP protein by 50%). An in silico solution to this problem can aid in early rejection of unsuitable targets and guide the design of further in vitro and in vivo drug combination experiments, thereby reducing the cost and time for drug development. An effective solution needs to analyze the topology of the neighborhood of diseases nodes along with their disease-specifi\fc roles in order to capture crosstalks between pathways and their impact on targets. In this project, the candidate has to explore how network embedding  can facilitate this. To this end, he/she will built on top of a state-of-the-art attributed network embedding technique that has been recently proposed by our group. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nExploring how network embedding can enable drug target discovery.\n\n(b) Development component\n\nImplementation of the proposed technique in Python.",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning",
      "Computational Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0152",
    "title": "Choose-your-own-project",
    "summary": "The project is on design and implementation of a data-driven system. The specific system to be designed and implemented is open for discussion. The candidate can propose his/her own project based on his/her interest. Only constraints are (a) it has to be based on database or data analytics technology (non-Machine Learning), (b) it has to be interesting and (c) it must be substantial enough to cover the duration of FYP. You are strongly advised to discuss with me before selecting the project.\n\nSpecific details:\n(a) Design component\n\nDesign of the proposed system\n\n(b) Implementation component\n\nImplementation using Java or Python\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Data Analytics",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0153",
    "title": "Design and Implementation of a Visual Query Interface for Property Graphs",
    "summary": "Attractive visual query interfaces (VQIs) have great potential to democratize the usage of property graph databases as they facilitate user-friendly query formulation without demanding the need to learn a property graph query language e.g., Cypher. In this project, the student shall explore the construction of various features of Cypher in a VQI. What features can we support in a user-friendly manner? What features we cannot support and why? The project is based on an existing VQI for property graph queries called SIERRA that we have recently built. \n\nThe student should have good creativity and programming background.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nExplore designing various features of Cypher in a VQI.\n\n(b) Development component\n\nImplementation of these features.",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0154",
    "title": "How Easy? An In-depth Study of How Users Draw Graph Queries on Large Property Graphs",
    "summary": "Analyzing graph data sets often involves finding regions in the data that match a given pattern. Specification of these patterns as a query is palatable for visual querying techniques as the data itself can be presented graphically using node-link diagram. That is, it is easier to visually describe query patterns than to express them textually or programmatically. This has led to increasing research in visual querying frameworks for graph data.\n\nVisual graph query interfaces (VQI) enable an end user to draw node-link diagrams freely, which are then matched against the underlying graph data to identify regions of interest. In this project, we undertake a comprehensive study of how users draw the graph pattern and cognitive load associated with sketching complex patterns. What challenges they face when the data is very large? Is it really easy to draw a query that returns non-empty results?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nUnderstand cognitive load associated withdrawing  various meaningful graph patterns.\n\nAnalyse drawing behaviour of users.\n\n(b) Development component\n\nDevelopment of framework to survey and analyze drawing behaviour of users.",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Data Analytics",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0155",
    "title": "Design and Implementation of a Visual Interface for Exploring Homonymous Author Names",
    "summary": "Disambiguating author names in bibliographic databases is a challenging problem. A recent benchmarking study revealed that the semi-automatic approach adopted by DBLP is the state-of-the-art. However, homonymous author name disambiguation remains an unyielding problem in DBLP. We have built a novel system called\nNERD to take a concrete step towards addressing this problem. We formalize this problem in DBLP as the namesake discovery problem (NDP) and present a light-weight and fast solution to address it. Specifically, it exploits an external data source (i.e., OpenAlex) and deploys a non-machine learning-based solution to identify namesakes hidden in a DBLP page associated with an author name. \n\nIn this project, the student shall build a user-friendly visual interface that enables a user to analyze and explore the results generated by NERD. \n\nSpecific details:\n(a) Design component\n\nVisual interface for NERD\n\n(b) Implementation component\n\nImplement the visual interface\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0156",
    "title": "Code an intelligent 3D data capturing camera (1)",
    "summary": "Nowadays, getting 3D data is increasingly important as they are needed in various applications such as face recognition, self-driving and metaverse. Developing such a robust and accurate 3D camera is urgently demanded.  AI will play an important role for a smart 3D camera.  We wish to code such a camera through a structured light technique or other similar techniques. \nImagine that when we take a picture, it is 3D! The project should be exciting and fun, and there is a lot of space for your creativity. \nThis project will be divided into different components, where each student will be working on one of them. Your interest and strength will be considered in determining which you are going to do exactly.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0157",
    "title": "Code an intelligent 3D data capturing camera (2)",
    "summary": "Nowadays, getting 3D data is increasingly important as they are needed in various applications such as face recognition, self-driving and metaverse. Developing such a robust and accurate 3D camera is urgently demanded.  AI will play an important role for a smart 3D camera.  We wish to code such a camera through a structured light technique or other similar techniques. \nImagine that when we take a picture, it is 3D! The project should be exciting and fun, and there is a lot of space for your creativity. \nThis project will be divided into different components, where each student will be working on one of them. Your interest and strength will be considered in determining which you are going to do exactly.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0158",
    "title": "Code an intelligent 3D data capturing camera (3)",
    "summary": "Nowadays, getting 3D data is increasingly important as they are needed in various applications such as face recognition, self-driving and metaverse. Developing such a robust and accurate 3D camera is urgently demanded.  AI will play an important role for a smart 3D camera.  We wish to code such a camera through a structured light technique or other similar techniques. \nImagine that when we take a picture, it is 3D! The project should be exciting and fun, and there is a lot of space for your creativity. \nThis project will be divided into different components, where each student will be working on one of them. Your interest and strength will be considered in determining which you are going to do exactly.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0159",
    "title": "Code an intelligent 3D data capturing camera (4)",
    "summary": "Nowadays, getting 3D data is increasingly important as they are needed in various applications such as face recognition, self-driving and metaverse. Developing such a robust and accurate 3D camera is urgently demanded.  AI will play an important role for a smart 3D camera.  We wish to code such a camera through a structured light technique or other similar techniques. \nImagine that when we take a picture, it is 3D! The project should be exciting and fun, and there is a lot of space for your creativity. \nThis project will be divided into different components, where each student will be working on one of them. Your interest and strength will be considered in determining which you are going to do exactly.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0160",
    "title": "Code an intelligent 3D data capturing camera (5)",
    "summary": "Nowadays, getting 3D data is increasingly important as they are needed in various applications such as face recognition, self-driving and metaverse. Developing such a robust and accurate 3D camera is urgently demanded.  AI will play an important role for a smart 3D camera.  We wish to code such a camera through a structured light technique or other similar techniques. \nImagine that when we take a picture, it is 3D! The project should be exciting and fun, and there is a lot of space for your creativity. \nThis project will be divided into different components, where each student will be working on one of them. Your interest and strength will be considered in determining which you are going to do exactly.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0161",
    "title": "Code an intelligent 3D data capturing camera (6)",
    "summary": "Nowadays, getting 3D data is increasingly important as they are needed in various applications such as face recognition, self-driving and metaverse. Developing such a robust and accurate 3D camera is urgently demanded.  AI will play an important role for a smart 3D camera.  We wish to code such a camera through a structured light technique or other similar techniques. \nImagine that when we take a picture, it is 3D! The project should be exciting and fun, and there is a lot of space for your creativity. \nThis project will be divided into different components, where each student will be working on one of them. Your interest and strength will be considered in determining which you are going to do exactly.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0162",
    "title": "Deep learning for defect detection (1)",
    "summary": "Our powerful devices such as handphones and computers reply on high- quality chips without defects during manufacturing. Hence it is necessary to find the chip defects before they  are integrated. Visually inspection by visible light or x-ray is commonly used.  Deep learning is a powerful tool to make the detection intelligent.\n\nWe wish to establish a platform for intelligent defect detection with multiple components such as quality checking, super-resolution and other image processing tasks. Students will develop software for one of the components. \n\nThe project will not only let you more deeply understand deep learning, but also benefit our local companies demanding such techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0163",
    "title": "Deep learning for defect detection (2)",
    "summary": "Our powerful devices such as handphones and computers reply on high- quality chips without defects during manufacturing. Hence it is necessary to find the chip defects before they  are integrated. Visually inspection by visible light or x-ray is commonly used.  Deep learning is a powerful tool to make the detection intelligent.\n\nWe wish to establish a platform for intelligent defect detection with multiple components such as quality checking, super-resolution and other image processing tasks. Students will develop software for one of the components. \n\nThe project will not only let you more deeply understand deep learning, but also benefit our local companies demanding such techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0164",
    "title": "Deep learning for defect detection (3)",
    "summary": "Our powerful devices such as handphones and computers reply on high- quality chips without defects during manufacturing. Hence it is necessary to find the chip defects before they  are integrated. Visually inspection by visible light or x-ray is commonly used.  Deep learning is a powerful tool to make the detection intelligent.\n\nWe wish to establish a platform for intelligent defect detection with multiple components such as quality checking, super-resolution and other image processing tasks. Students will develop software for one of the components. \n\nThe project will not only let you more deeply understand deep learning, but also benefit our local companies demanding such techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0165",
    "title": "Deep learning for defect detection (4)",
    "summary": "Our powerful devices such as handphones and computers reply on high- quality chips without defects during manufacturing. Hence it is necessary to find the chip defects before they  are integrated. Visually inspection by visible light or x-ray is commonly used.  Deep learning is a powerful tool to make the detection intelligent.\n\nWe wish to establish a platform for intelligent defect detection with multiple components such as quality checking, super-resolution and other image processing tasks. Students will develop software for one of the components. \n\nThe project will not only let you more deeply understand deep learning, but also benefit our local companies demanding such techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0166",
    "title": "Deep learning for defect detection (5)",
    "summary": "Our powerful devices such as handphones and computers reply on high- quality chips without defects during manufacturing. Hence it is necessary to find the chip defects before they  are integrated. Visually inspection by visible light or x-ray is commonly used.  Deep learning is a powerful tool to make the detection intelligent.\n\nWe wish to establish a platform for intelligent defect detection with multiple components such as quality checking, super-resolution and other image processing tasks. Students will develop software for one of the components. \n\nThe project will not only let you more deeply understand deep learning, but also benefit our local companies demanding such techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0167",
    "title": "Deep learning for defect detection (6)",
    "summary": "Our powerful devices such as handphones and computers reply on high- quality chips without defects during manufacturing. Hence it is necessary to find the chip defects before they  are integrated. Visually inspection by visible light or x-ray is commonly used.  Deep learning is a powerful tool to make the detection intelligent.\n\nWe wish to establish a platform for intelligent defect detection with multiple components such as quality checking, super-resolution and other image processing tasks. Students will develop software for one of the components. \n\nThe project will not only let you more deeply understand deep learning, but also benefit our local companies demanding such techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Qian Kemao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0168",
    "title": "Choose-your-own-project",
    "summary": "The project is on design and implementation of a data-driven system. The specific system to be designed and implemented is open for discussion. The candidate can propose his/her own project based on his/her interest. Only constraints are (a) it has to be based on database or data analytics technology (non-Machine Learning), (b) it has to be interesting and (c) it must be substantial enough to cover the duration of FYP. You are strongly advised to discuss with me before selecting the project.\n\nSpecific details:\n(a) Design component\n\nDesign of the proposed system\n\n(b) Implementation component\n\nImplementation using Java or Python\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Data Analytics",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0169",
    "title": "Effective Visualization of Human Cancer Signaling Network",
    "summary": "Cancer signaling network provides a comprehensive map of molecular mechanisms implicated in cancer. This network has more than 6000 nodes where nodes and edges are enriched with attributes.  This makes it challenging to visualize the relevant content of the network. In this project, the student will design and implement advanced interactive visualization techniques to enable a user to effectively visualize various details of the network.\n\nSpecific details:\n(a) Design component\n\nVisualization schemes for cancer signaling network.\n\n(b) Implementation component\n\nImplement the visualization schemes.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Visual Computing",
      "Human Computer Interaction",
      "Bioinformatics"
    ]
  },
  {
    "projectNo": "CCDS25-0170",
    "title": "Computing Aesthetics of a Visual Query Interface",
    "summary": "People prefer attractive interfaces and the eﬀect of aesthetics in GUI appreciation is signiﬁcant. Existing approaches to make a GUI stand out is to work out all of the details of visual design manually. In this research we explore how to automatically compute the \"aesthetics score\" of a visual query interface used in data-driven systems. We focus on graph query interface, however, the approach can be generalized to other types of query interfaces.\n\nThe project involves research in data management and HCI and culminates with the implementation of the proposed technique on an existing visual querying framework. It is based on a preliminary prototype called VOYAGER that has been developed by a past student. \n\nA rigorous investigation of this problem may result in conference or journal paper. \n\nSpecific details:\n\n\nNovel technique to automatically compute aesthetics of a visual query interface",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Human Computer Interaction",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0171",
    "title": "How Accurate is NERD? Analyzing a Homonymous Author Name Disambiguation Framework",
    "summary": "Disambiguating author names in bibliographic databases is a challenging problem. A recent benchmarking study revealed that the semi-automatic approach adopted by DBLP is the state-of-the-art. However, homonymous author name disambiguation remains an unyielding problem in DBLP.  Recently, we have developed a novel system called NERD to take a concrete step towards addressing this problem. We formalize this problem in DBLP as the namesake discovery problem (NDP) and present a light-weight and fast solution to address it.\nSpecifically, it exploits an external data source (i.e., OpenAlex) and deploys a non-machine learning-based solution to identify namesakes hidden in a DBLP page associated with an author name. \n\nThe goal of this project is to undertake exhaustive, rigorous, and systematic analysis of the results quality of NERD. To this end, real-world DBLP pages shall be used to analyze NERD�s ability to identify many namesakes accurately.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nAnalyze performance of NERD.\n\n(b) Development component\n\nImplement various performance metrics using Python.",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0172",
    "title": "A User-friendly Framework for Human-in-the-loop Data-driven Formation of Program Committees for Conferences",
    "summary": "The formation of a quality program committee (PC) for\na conference venue is critical for a high-quality scientific program. Traditionally, PC chairs take a �manual� approach to form a PC. In practice, however, such an approach, might not create a diverse PC w.r.t. certain dimensions. Furthermore, it has been reported that the traditional manual approach may lead to dense coauthorship\nnetworks among PC members. All these aspects can easily make it challenging in practice to ensure fair and quality assignments of reviewers to submissions.\nIn this project, we build a user-friendly system for a  data-driven PC-chair-in-the-loop PC formation framework for conferences to mitigate some of the challenges brought by traditional PC formation methods.\n\nThe project builds on an existing implementation in Python. \n\nSpecific details:\n(a) Design component\n\nHuman-in-the-loop framework.\n\n(b) Implementation component\n\nImplementation using Python. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Sourav Saha Bhowmick",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0173",
    "title": "Reinforcement Learning for Stock Trading 1",
    "summary": "This project aims to implement reinforcement learning for stock trading. \n\nExperiance in reinforcement learning algorithm design is needed for the project. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component",
    "supervisor": "Prof Bo An",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0174",
    "title": "Deep Reinforcement Learning for Complex Environment 1",
    "summary": "Reinforcement learning (RL) is a general learning, predicting, and decision making paradigm. RL provides solution methods for sequential decision making problems as well as those can be transformed into sequential ones. RL connects deeply with optimization, statistics, game theory, causal inference, sequential experimentation, etc., overlaps largely with approximate dynamic programming and optimal control, and applies broadly in science, engineering and arts. This project will explore application of deep RL for solving real world problems. \n\nThe student must have done some deep RL work. Please read my webpage for deep RL papers before emailing me.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Bo An",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0175",
    "title": "Reinforcement Learning for Stock Trading 2",
    "summary": "This project aims to implement reinforcement learning for stock trading. \n\nExperiance in reinforcement learning algorithm design is needed for the project. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component",
    "supervisor": "Prof Bo An",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0176",
    "title": "Deep Reinforcement Learning for Real World Problems 1",
    "summary": "The student must have done some deep RL work. Please read my webpage for deep RL papers before emailing me.\n\nReinforcement learning (RL) is a general learning, predicting, and decision making paradigm. RL provides solution methods for sequential decision making problems as well as those can be transformed into sequential ones. RL connects deeply with optimization, statistics, game theory, causal inference, sequential experimentation, etc., overlaps largely with approximate dynamic programming and optimal control, and applies broadly in science, engineering and arts. This project will explore application of deep RL for solving real world problems. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Bo An",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0177",
    "title": "Personalized Economic Decision-Making in Multi-Agent Simulations Using LLM-based Agents",
    "summary": "Economic decision-making is inherently diverse, influenced by individual personalities and cognitive biases. Traditional economic models often assume homogeneous agents who make decisions based on fixed rationality principles, which limits their ability to capture the diverse of economic decision-making. Recently, large language models (LLMs) shows its ability in simulating different personalities. Therefore, LLM-based agents can exhibit individualized decision-making patterns, adapt their economic strategies, and dynamically respond to market conditions. By integrating personality-driven reasoning and contextual adaptability, LLM-powered agents can simulate diverse consumer behaviours, investment strategies, and negotiation dynamics, leading to more realistic and insightful economic simulations.\n\nThe objective of this project is to explore personalized economic decision-making using LLM-based agents. Specifically, we will design agents with distinct economic personas, allowing them to trade, negotiate, and respond to market fluctuations in a multi-agent simulation environment. By analysing how different decision-making strategies influence market, we aim to uncover insights into the role of heterogeneity in economic systems. By simulating personalized economic decision-making behaviours, this project will contribute to more realistic and human-like economic simulations.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Bo An",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0178",
    "title": "Pandemic Spread Prediction with Deep Learning",
    "summary": "Accurate prediction of pandemic spread is essential for effective public health. Traditional epidemiological models, such as the SEIR model, rely on predefined assumptions that often limit their adaptability to real-world dynamics, making long-term forecasting challenging. Recent advancements in deep learning offer a data-driven approach to pandemic prediction, enabling models to learn patterns directly from historical data. Unlike traditional models, deep learning-based approaches can dynamically adjust to changing conditions and improve prediction accuracy over time. By integrating deep learning with real-world pandemic data, we can develop more robust forecasting models that enhance situational awareness and support timely interventions.\n\nThe objective of this project is to develop a deep learning-based pandemic prediction model that improves forecasting accuracy by leveraging historical data. Specifically, we will train deep learning models, such as LSTM and Transformer-based architectures, to capture temporal dependencies in infection trends. By comparing the performance of deep learning models with traditional epidemiological models, we aim to evaluate their effectiveness in capturing real-world pandemic spread. This project will provide a more adaptive and data-driven approach to pandemic forecasting, contributing to more informed public health strategies and improved preparedness for future outbreaks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Bo An",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0179",
    "title": "Simulating Negotiation and Trade Behaviour Using LLM-Powered Agents",
    "summary": "Negotiation and trade are fundamental components of economic systems, influencing market dynamics, pricing strategies, and resource allocation. Traditional agent-based models (ABMs) for economic simulations rely on predefined rules and fixed strategies, limiting their ability to capture the complexity and adaptability of real-world negotiations. These models struggle to simulate the flexibility, strategic reasoning, and language-based interactions that characterize human negotiation behaviour. Recent advancements in large language models (LLMs) provide an opportunity to enhance trade simulations by enabling agents to negotiate, persuade, and adapt dynamically. Unlike conventional ABM agents, LLM-powered agents can engage in context-aware, multi-turn negotiations, adjusting their offers and responses based on economic incentives, prior interactions, and negotiation history.\n\nThe objective of this project is to develop a multi-agent negotiation and trade simulation framework using LLM-powered agents. Specifically, we will design agents that can engage in price bargaining, respond strategically to counteroffers, and optimize their trade outcomes in a simulated market environment. By analysing negotiation patterns, market fluctuations, and deal success rates, we aim to understand how AI-driven agents can mimic human negotiation behaviour. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Bo An",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0180",
    "title": "No Title 5",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0181",
    "title": "No Title 4",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0182",
    "title": "No Title 3",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0183",
    "title": "No Title 4",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0184",
    "title": "No Title 5",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0185",
    "title": "No Title 10",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0186",
    "title": "No Title 10",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0187",
    "title": "No Title 5",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0188",
    "title": "No Title 4",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0189",
    "title": "No Title 5",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0190",
    "title": "No Title 4",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must or the project will be useful for charity organizations. \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0191",
    "title": "No Title 2",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0192",
    "title": "No Title 1",
    "summary": "This project is for a student, who wants to establish his/her company after graduation. He/she has total freedom to do whatever he/she wants to do. In other words, he/she needs to set the project title and scope. Some requirements are listed below \n\n1.\tThis project must be IT related. \n2.\tA sound business plan is must \n3.\tA prototype must be developed.  \n\nStudents selecting the related projects can form a team. However, note that it is not guaranteed that you and your team members will be given the �no title� projects.   \n\nVery low grades, including D and below, will be given if the requirements 1-3 are not fulfilled. If the final prototype is only a website without using other advanced technology, e.g. AI, data mining, image processing, security or advanced database methods, D grade will be given.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kong Wai Kin Adams",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0193",
    "title": "Voice-Activated LLM-Powered Conversational Health Companion for Smartwatches",
    "summary": "The integration of Large Language Models (LLMs) with smartwatch data aims to create conversational health companions that provide personalized health insights. Recent studies have explored this integration to enhance user engagement and health monitoring. For instance, the development of PhysioLLM demonstrates how LLMs can process physiological data from wearables to offer tailored health advice. Another study introduced a Personal Health Insights Agent (PHIA) that utilizes LLMs to analyze wearable data, providing users with actionable health information. However, both approaches rely primarily on text-based interaction, lacking voice-based engagement, which could improve usability, accessibility, and real-time feedback. Our research aims to bridge this gap by incorporating voice activation and voice-based interaction in LLM-powered health companions.\n\nResearch Objective:\nThis research collects physiological data (e.g., heart rate, sleep patterns, stress levels) from smartwatches using APIs and captures voice interactions for analysis. It integrates LLMs with automatic speech recognition (ASR) and wake-word activation to process voice commands for personalized health feedback. A conversational voice interface is developed, and comparative user studies assess engagement, usability, and adherence in voice vs. text-based interactions.\n\nHow effectively can LLMs process and integrate both physiological data from smartwatches and voice inputs to generate real-time, personalized health insights?\n\nWhat is the impact of voice-based interaction on user engagement, usability, and adherence compared to text-based interactions in LLM-powered smartwatch health companions?\n\nHow can privacy and security risks associated with voice-activated LLM health companions on smartwatches be mitigated while maintaining real-time functionality?\n\nFang, C. M., et al. \"PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models.\" (2024).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nVoice &amp; Data Integration: Combining smartwatch biometric data with LLM-driven voice-based personalized insights.\nConversational Interface: Designing wake-word activated, voice-first user-friendly interactions.\nPersonalization Algorithms: Tailoring health insights using voice commands and contextual smartwatch data.\nUser Evaluation: Conducting comparative studies : voice-based and text-based LLM health assistants.\n\nMerrill, et al. \"Transforming Wearable Data into Health Insights using Large Language Model Agents.\" (2024)\n \n\n\n(b) Development component\nSpeech Recognition &amp; Wake-Word Activation: Implementing custom voice triggers for hands-free activation.\nLLM &amp; Smartwatch API Integration: Enabling real-time voice-driven health monitoring.\nPrivacy &amp; Security : Ensuring on-device processing for voice data to protect privacy.\nReal-Time Voice Feedback: Creating a conversational AI assistant that adapts based on voice input and physiological trends.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining",
      "Smartphone Systems and Applications",
      "Ubiquitous/ Pervasive Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0194",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0195",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0196",
    "title": "360-Degree Video Streaming in the Metaverse: Tailored Reinforcement Learning Strategies",
    "summary": "In the dynamic and rapidly evolving landscape of the Metaverse, the pivotal challenge of delivering\noptimal Quality of Service (QoS) for 360-degree video streaming stands at the forefront of virtual reality\ntechnology. This challenge becomes increasingly complex when addressing the diverse needs of both\nVirtual Reality (VR) and non-VR users. Deep Reinforcement Learning (DRL), particularly Proximal Policy\nOptimization (PPO) and Separate Input Differentiated Output (SIDO), presents a promising approach to\ntackle this challenge. Our exploration delves into the integration of these advanced techniques,\nrevealing SIDO's superior performance with a striking enhancement over conventional PPO\nmethods. This significant improvement is rooted in SIDO's adept handling of the varied QoS demands,\nensuring high frame rates and low latency for VR users, while maintaining resource efficiency for non-VR\nusers. Our findings not only underscore the efficacy of customized DRL strategies in managing the\nintricacies of virtual environments but also open new avenues for future innovation. This research paves\nthe way for further exploration into algorithmic refinement, adaptation to diverse scenarios within the\nMetaverse, real-world application testing, and incorporating user feedback for QoS personalization. As\nwe venture into this uncharted digital realm, our work establishes a foundation for more immersive,\nefficient, and user-focused virtual experiences, signifying a significant leap in the domain of 360-degree\nvideo streaming technology.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0197",
    "title": "Web3 Edge Computing: A Study on the Integration of Decentralized Computing and Edge Computing in the Web3 Ecosystem",
    "summary": "Introduction:\nWeb3 has the potential to change the way we interact with the internet. With its decentralized architecture, Web3 provides a new level of security and control for users. One of the key components of Web3 is edge computing, which allows for data processing and computation to occur closer to the user. Edge computing offers a number of benefits, including improved performance, reduced latency, and enhanced security. However, the integration of edge computing and decentralized computing in Web3 presents its own set of challenges. In this proposal, we will explore the potential of Web3 edge computing and identify areas for further research to optimize its integration in the Web3 ecosystem.\n\nResearch Questions:\n\nWhat is the current state of Web3 edge computing, and how does it differ from traditional edge computing?\nWhat are the potential benefits and challenges of integrating decentralized computing and edge computing in Web3?\nHow can Web3 developers design applications that leverage edge computing to improve performance and security?\nHow can Web3 edge computing be used to enable new use cases, such as IoT and autonomous vehicles?\nMethodology:\nThis study will utilize a mixed-methods approach, including both quantitative and qualitative data collection methods. We will conduct a systematic review of existing literature on Web3 edge computing, including academic articles, whitepapers, and technical reports. Additionally, we will conduct interviews with Web3 developers and industry experts to gain insights into the challenges and opportunities for integrating edge computing in the decentralized web. We will also analyze Web3 applications to identify areas for improvement in terms of leveraging edge computing for improved performance and security.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0198",
    "title": "Federated deep learning algorithm study",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm using federated learning. In this project, we will review all existing federated learning algorithms. Then, we will explore new federated learning algorithm to improve the performance of the federated learning. \n\nSpecific details:\n(a) Design component\nWe will design new algorithm\n\n(b) Implementation component\nWe will implement new algorithm in the federated learning system\n\n(a) Research component\nwe will survey all existing federated learning algorithms\n\n(b) Development component\nwe will try to develop new algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0199",
    "title": "Federated Deep Learning Algorithm Design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning. In this project, we will summarize existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm used for federated learning.\n\nSpecific details:\n(a) Design component\nalgorithm\n\n(b) Implementation component\nalgorithm\n\n(a) Research component\nsurvey federated learning algorithms\n\n(b) Development component\n\nDesign new federated learning algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0200",
    "title": "Federated learning study",
    "summary": "Federated Learning is a hot topic in the recent years due to the increased emphasis for data privacy. Therefore, with less accessibility to restricted private data, federated learning is designed to bring the deep learning models to the private data for anonymous training. However, with increasingly complex model architecture, large latency during model transfer can be induced and model training can take up a lot of time. Therefore, to solve this, we would like to suggest adaptations to the conventional federated learning process. In this project, students will research on different adaptation techniques to the conventional federated learning. This can include deep reinforcement learning for model pruning to reduce the complex model's size.\n\nSpecific details:\n(a) Design component\nfederated learning framework\n\n(b) Implementation component\nfederated learning framework\n\n(a) Research component\ndifferential privacy technique\n\n(b) Development component\nDevelop existing differential privacy technique in the federated learning",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Blockchain"
    ]
  },
  {
    "projectNo": "CCDS25-0201",
    "title": "Federated deep learning system survey and design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. However, to solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing systems in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new system using federated learning.\n\nSpecific details:\n(a) Design component\nFederated deep learning system design\n\n(b) Implementation component\nFederated deep learning system implementation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0202",
    "title": "Federated deep learning system survey and design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. However, to solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing systems in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new system using federated learning.\n\nSpecific details:\n(a) Design component\nFederated deep learning system design\n\n(b) Implementation component\nFederated deep learning system implementation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0203",
    "title": "Federated learning study",
    "summary": "Federated Learning is a hot topic in the recent years due to the increased emphasis for data privacy. Therefore, with less accessibility to restricted private data, federated learning is designed to bring the deep learning models to the private data for anonymous training. However, with increasingly complex model architecture, large latency during model transfer can be induced and model training can take up a lot of time. Therefore, to solve this, we would like to suggest adaptations to the conventional federated learning process. In this project, students will research on different adaptation techniques to the conventional federated learning. This can include deep reinforcement learning for model pruning to reduce the complex model's size.\n\nSpecific details:\n(a) Design component\nfederated learning framework\n\n(b) Implementation component\nfederated learning framework\n\n(a) Research component\ndifferential privacy technique\n\n(b) Development component\nDevelop existing differential privacy technique in the federated learning",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Blockchain"
    ]
  },
  {
    "projectNo": "CCDS25-0204",
    "title": "Federated Deep Learning Algorithm Design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning. In this project, we will summarize existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm used for federated learning.\n\nSpecific details:\n(a) Design component\nalgorithm\n\n(b) Implementation component\nalgorithm\n\n(a) Research component\nsurvey federated learning algorithms\n\n(b) Development component\n\nDesign new federated learning algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0205",
    "title": "LLM hallucination study",
    "summary": "The \"LLM Hallucination Study\" aims to investigate the phenomenon of hallucination in large language models (LLMs), where these models generate information or responses that are inaccurate, fabricated, or not based on real-world data. This project will investigate hallucination in LLMs. The outcomes of this research are expected to contribute to the development of more reliable and trustworthy AI systems, enhancing their utility and safety in critical applications across various sectors.\n\nSpecific details:\n(a) Design component\nWe will design new algorithms\n\n(b) Implementation component\nWe will implement new algorithms\n\n(a) Research component\nwe will survey existing algorithms\n\n(b) Development component\nwe will try to develop new algorithms",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0206",
    "title": "Federated deep learning algorithm study",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm using federated learning. In this project, we will review all existing federated learning algorithms. Then, we will explore new federated learning algorithm to improve the performance of the federated learning. \n\nSpecific details:\n(a) Design component\nWe will design new algorithm\n\n(b) Implementation component\nWe will implement new algorithm in the federated learning system\n\n(a) Research component\nwe will survey all existing federated learning algorithms\n\n(b) Development component\nwe will try to develop new algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0207",
    "title": "Web3 Edge Computing: A Study on the Integration of Decentralized Computing and Edge Computing in the Web3 Ecosystem",
    "summary": "Introduction:\nWeb3 has the potential to change the way we interact with the internet. With its decentralized architecture, Web3 provides a new level of security and control for users. One of the key components of Web3 is edge computing, which allows for data processing and computation to occur closer to the user. Edge computing offers a number of benefits, including improved performance, reduced latency, and enhanced security. However, the integration of edge computing and decentralized computing in Web3 presents its own set of challenges. In this proposal, we will explore the potential of Web3 edge computing and identify areas for further research to optimize its integration in the Web3 ecosystem.\n\nResearch Questions:\n\nWhat is the current state of Web3 edge computing, and how does it differ from traditional edge computing?\nWhat are the potential benefits and challenges of integrating decentralized computing and edge computing in Web3?\nHow can Web3 developers design applications that leverage edge computing to improve performance and security?\nHow can Web3 edge computing be used to enable new use cases, such as IoT and autonomous vehicles?\nMethodology:\nThis study will utilize a mixed-methods approach, including both quantitative and qualitative data collection methods. We will conduct a systematic review of existing literature on Web3 edge computing, including academic articles, whitepapers, and technical reports. Additionally, we will conduct interviews with Web3 developers and industry experts to gain insights into the challenges and opportunities for integrating edge computing in the decentralized web. We will also analyze Web3 applications to identify areas for improvement in terms of leveraging edge computing for improved performance and security.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0208",
    "title": "360-Degree Video Streaming in the Metaverse: Tailored Reinforcement Learning Strategies",
    "summary": "In the dynamic and rapidly evolving landscape of the Metaverse, the pivotal challenge of delivering\noptimal Quality of Service (QoS) for 360-degree video streaming stands at the forefront of virtual reality\ntechnology. This challenge becomes increasingly complex when addressing the diverse needs of both\nVirtual Reality (VR) and non-VR users. Deep Reinforcement Learning (DRL), particularly Proximal Policy\nOptimization (PPO) and Separate Input Differentiated Output (SIDO), presents a promising approach to\ntackle this challenge. Our exploration delves into the integration of these advanced techniques,\nrevealing SIDO's superior performance with a striking enhancement over conventional PPO\nmethods. This significant improvement is rooted in SIDO's adept handling of the varied QoS demands,\nensuring high frame rates and low latency for VR users, while maintaining resource efficiency for non-VR\nusers. Our findings not only underscore the efficacy of customized DRL strategies in managing the\nintricacies of virtual environments but also open new avenues for future innovation. This research paves\nthe way for further exploration into algorithmic refinement, adaptation to diverse scenarios within the\nMetaverse, real-world application testing, and incorporating user feedback for QoS personalization. As\nwe venture into this uncharted digital realm, our work establishes a foundation for more immersive,\nefficient, and user-focused virtual experiences, signifying a significant leap in the domain of 360-degree\nvideo streaming technology.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0209",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0210",
    "title": "Reducing Hallucinations in Large Language Models through Retrieval-Augmented Generation (RAG)",
    "summary": "1. Background and Motivation\nHallucinations in LLMs occur when the models produce outputs that are plausible but factually incorrect or fabricated. This issue is particularly concerning in high-stakes domains such as healthcare, law, finance, and education, where misinformation can lead to severe consequences. Current LLMs generate text based on patterns learned from large datasets during training, but they do not inherently verify the accuracy of the information they produce.\n\nRAG addresses this limitation by incorporating a retrieval mechanism that fetches relevant information from an external knowledge base or document repository, which the model can then use to inform its responses. By grounding the generation process in real-time, accurate data, RAG has the potential to significantly reduce hallucinations and improve the trustworthiness of LLM outputs.\n\n2. Research Objectives\nThe primary objectives of this research are:\n\nDevelop and integrate a RAG framework that enhances the factual accuracy of LLM outputs by retrieving relevant information from external sources during text generation.\n\nEvaluate the effectiveness of the RAG framework in reducing hallucinations across various tasks, such as question answering, summarization, and dialogue systems.\n\nExplore the balance between retrieval and generation, optimizing the integration of retrieved content without compromising the fluency and coherence of the LLM's output.\n\nConduct domain-specific evaluations to assess the impact of RAG in high-stakes fields, such as healthcare, legal technology (Legal Tech), and finance, where accuracy is critical.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0211",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0212",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0213",
    "title": "Federated learning study",
    "summary": "Federated Learning is a hot topic in the recent years due to the increased emphasis for data privacy. Therefore, with less accessibility to restricted private data, federated learning is designed to bring the deep learning models to the private data for anonymous training. However, with increasingly complex model architecture, large latency during model transfer can be induced and model training can take up a lot of time. Therefore, to solve this, we would like to suggest adaptations to the conventional federated learning process. In this project, students will research on different adaptation techniques to the conventional federated learning. This can include deep reinforcement learning for model pruning to reduce the complex model's size.\n\nSpecific details:\n(a) Design component\nfederated learning framework\n\n(b) Implementation component\nfederated learning framework\n\n(a) Research component\ndifferential privacy technique\n\n(b) Development component\nDevelop existing differential privacy technique in the federated learning",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Blockchain"
    ]
  },
  {
    "projectNo": "CCDS25-0214",
    "title": "Federated deep learning system survey and design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. However, to solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing systems in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new system using federated learning.\n\nSpecific details:\n(a) Design component\nFederated deep learning system design\n\n(b) Implementation component\nFederated deep learning system implementation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0215",
    "title": "Federated Deep Learning Algorithm Design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning. In this project, we will summarize existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm used for federated learning.\n\nSpecific details:\n(a) Design component\nalgorithm\n\n(b) Implementation component\nalgorithm\n\n(a) Research component\nsurvey federated learning algorithms\n\n(b) Development component\n\nDesign new federated learning algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0216",
    "title": "Federated deep learning algorithm study",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm using federated learning. In this project, we will review all existing federated learning algorithms. Then, we will explore new federated learning algorithm to improve the performance of the federated learning. \n\nSpecific details:\n(a) Design component\nWe will design new algorithm\n\n(b) Implementation component\nWe will implement new algorithm in the federated learning system\n\n(a) Research component\nwe will survey all existing federated learning algorithms\n\n(b) Development component\nwe will try to develop new algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0217",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0218",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0219",
    "title": "Federated deep learning algorithm study",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm using federated learning. In this project, we will review all existing federated learning algorithms. Then, we will explore new federated learning algorithm to improve the performance of the federated learning. \n\nSpecific details:\n(a) Design component\nWe will design new algorithm\n\n(b) Implementation component\nWe will implement new algorithm in the federated learning system\n\n(a) Research component\nwe will survey all existing federated learning algorithms\n\n(b) Development component\nwe will try to develop new algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0220",
    "title": "Federated Deep Learning Algorithm Design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. To solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning. In this project, we will summarize existing algorithms in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new algorithm used for federated learning.\n\nSpecific details:\n(a) Design component\nalgorithm\n\n(b) Implementation component\nalgorithm\n\n(a) Research component\nsurvey federated learning algorithms\n\n(b) Development component\n\nDesign new federated learning algorithm",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0221",
    "title": "Federated learning study",
    "summary": "Federated Learning is a hot topic in the recent years due to the increased emphasis for data privacy. Therefore, with less accessibility to restricted private data, federated learning is designed to bring the deep learning models to the private data for anonymous training. However, with increasingly complex model architecture, large latency during model transfer can be induced and model training can take up a lot of time. Therefore, to solve this, we would like to suggest adaptations to the conventional federated learning process. In this project, students will research on different adaptation techniques to the conventional federated learning. This can include deep reinforcement learning for model pruning to reduce the complex model's size.\n\nSpecific details:\n(a) Design component\nfederated learning framework\n\n(b) Implementation component\nfederated learning framework\n\n(a) Research component\ndifferential privacy technique\n\n(b) Development component\nDevelop existing differential privacy technique in the federated learning",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Blockchain"
    ]
  },
  {
    "projectNo": "CCDS25-0222",
    "title": "Federated deep learning system survey and design",
    "summary": "Federated learning is one of the hottest topics in deep learning now. However, to solve the insufficient data problem, we need more data. Thus, the federated learning solution is proposed.  It similar to distributed deep learning.  In this project, we will summarise existing systems in the federated deep learning. Then, we will implement them and evaluate. Next, we will design a new system using federated learning.\n\nSpecific details:\n(a) Design component\nFederated deep learning system design\n\n(b) Implementation component\nFederated deep learning system implementation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0223",
    "title": "Artificial Intelligence (AI) Foundation Models Research",
    "summary": "1. Introduction\n\nFoundation models, like GPT-4 and BERT, have transformed our ability to generate and process text, images, and more. However, while their capabilities are vast, so too are the challenges and questions they present. This proposal aims to conduct in-depth research into the various facets of foundation models, examining their potential, their limitations, and their broader impact on society.\n\n2. Objectives\n\nUnderstanding Model Behavior: Delve into the intricacies of foundation models to decipher their decision-making processes and understand their generated outputs.\n\nEthical Implications: Explore the ethical dimensions of these models, including concerns about biases, misinformation, and their potential for misuse.\n\nOptimization and Efficiency: Investigate methods to optimize training processes, reduce computational costs, and make models more accessible.\n\n3. Methodology\n\nLiterature Review: A thorough examination of current literature to understand the state-of-the-art and identify gaps in knowledge.\n\nExperimental Analysis: Setting up controlled experiments to understand the behavior of foundation models under various conditions.\n\nStakeholder Interviews: Engaging with end-users, developers, and ethicists to gain diverse perspectives on the use and implications of foundation models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Zhao Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0224",
    "title": "Smart BirdSound: AI-Powered Real-Time Bird Call Recognition for Enhanced Conservation and Engagement",
    "summary": "Recent advancements in deep learning have significantly improved bird sound recognition, aiding conservation and wildlife monitoring. Zhang et al. (2023) combined CNNs with a transformer encoder, achieving 97.99% accuracy on the Birdsdata dataset. Heinrich et al. (2024) introduced AudioProtoPNet, an interpretable deep learning model enhancing classification transparency. Guei (2023) developed ECOGEN, a deep learning-based synthetic bird song generator, improving classifier performance.\n\nDespite these advancements, three key challenges remain:\n\n    Limited real-time adaptability � Models require high computational power, limiting mobile use.\n    Lack of context-awareness � Systems struggle to differentiate overlapping calls in noisy environments.\n    User-unfriendly integration � Existing models lack practical applications for birdwatchers and conservationists.\n\nThis research develops Smart BirdSound, an AI-powered mobile app using a hierarchical multi-agent system (MAS) framework. It integrates adaptive learning, noise filtration, and real-time species identification to improve accuracy, efficiency, and usability.\nResearch Objective and Method:\n\nThis study develops Smart BirdSound, an AI-powered app for real-time bird sound recognition using CNNs, adaptive filtering, and cross-agent validation to:\n\n    Enhance adaptability on mobile devices.\n    Improve classification accuracy in noisy environments.\n    Increase user engagement through a user-friendly mobile app.\n\nUsing frameworks from Heinrich et al. (2024) and Guei (2023), this research ensures practical deployment.\nResearch Questions:\n\n    How can CNNs be optimized for real-time bird sound recognition?\n    What impact does cross-agent validation have on classification accuracy?\n    How does AI-powered bird sound recognition enhance engagement and conservation?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nDataset Collection: Assemble a comprehensive dataset of bird calls, including background noise variations.\nDeep Learning Model Training: Implement CNN models trained on spectrogram representations of bird sounds.\nNoise Reduction &amp; Feature Extraction: Develop an adaptive filtering algorithm to enhance recognition in overlapping sound environments.\nModel Evaluation: Use accuracy, recall, and F1-score metrics to compare performance with existing models.\n\n\n(b) Development component\nMobile App Development: Design a cross-platform application with intuitive UI/UX.\nAI Model Integration: Deploy the CNN-based bird sound recognition model into the mobile app.\nReal-Time Audio Processing: Implement edge AI capabilities to ensure low-latency processing.\nUser Features: Include interactive bird species identification, real-time mapping, and data logging for researchers.\nBeta Testing &amp; Feedback: Conduct pilot testing with birdwatchers and conservation groups.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Smartphone Systems and Applications",
      "Human Computer Interaction",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0225",
    "title": "Enhancing Design Thinking Education through AI-Powered Learning Validation: An Integration of Large Language Models and Multi-Agent Systems",
    "summary": "Design Thinking (DT) is a critical methodology for fostering creativity, problem-solving, and innovation in education. Lee and Rhee (2024) highlight its positive impact on student learning, emphasizing the need for structured assessment frameworks (Lee &amp; Rhee, 2024). However, current DT education faces challenges in evaluating student competencies, providing real-time feedback, and adapting learning activities to student progress.\n\nJiang et al. (2024) propose a von Neumann Multi-Agent System (MAS) framework, demonstrating its potential in AI-driven education, but its application in DT learning validation remains unexplored (Jiang et al., 2024). While LLMs are widely used in educational contexts, their integration with MAS for adaptive feedback and personalized learning in DT is an emerging area of research.\n\nTo address these gaps, this study develops a hybrid LLM-MAS framework for validating student learning in DT education, enabling automated assessment, adaptive feedback, and real-time progress tracking.\n\nThis research aims to develop and evaluate an AI-driven learning validation system for Design Thinking education using LLMs and MAS. The system will:\n\n    Improve student learning assessment by leveraging LLMs for real-time analysis of student work.\n    Adapt learning pathways dynamically using MAS to personalize feedback and guide students through DT exercises.\n    Enhance interdisciplinary applications by creating a flexible AI-powered framework for DT learning validation.\n\n\nResearch Questions:\n\n    How can the integration of LLMs and MAS improve the validation of student learning in Design Thinking education?\n    What impact does AI-generated adaptive feedback have on student engagement and performance in DT coursework?\n    How can MAS facilitate dynamic adjustments in Design Thinking learning activities based on real-time assessment data?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis study builds upon Jiang et al. to create a scalable framework assessment.\nLiterature Review: Analyze DT assessment models, LLM applications in education, and MAS-based learning frameworks.\nFramework Development: Design a hybrid LLM-MAS system for real-time student evaluation.\nImplementation: Deploy the system in DT courses to assess effectiveness.\nData Collection: Gather quantitative and qualitative insights on student engagement and performance.\nEvaluation: Compare AI-driven vs. traditional DT learning validation methods.\n\n(b) Development component\nSystem Architecture: Develop an LLM-powered evaluation model integrated with MAS agents.\nFeedback Mechanism: Implement real-time, personalized AI feedback to enhance student engagement.\nAdaptive Learning Pathways: Use MAS to dynamically adjust learning activities based on student progress.\nUsability Testing: Conduct student trials and refine the system for practical DT education applications.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Human Computer Interaction",
      "Software and Applications",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0226",
    "title": "Enhancing HCI Education: AI-Driven Question Generation for Adaptive and Engaging Learning",
    "summary": "Advancements in AI-driven educational tools have enabled automated question generation (AQG) using large language models (LLMs). Bulathwela et al. (2023) explored scalable question generation with pre-trained models, demonstrating adaptability and diversity in AI-generated questions. Kharrufa and Johnson (2024) examined generative AI in Human-Computer Interaction (HCI) education, highlighting its potential for engagement and personalized instruction. However, their study lacked a structured framework for integrating AI-driven question generation into HCI curricula. Liu and Li (2021) introduced creative question generation for HCI but focused on open-ended queries rather than structured assessment-driven formats.\n\nAI-driven question generation (AQG) lacks real-time adaptability and context-awareness, limiting effectiveness in dynamic learning environments. Existing models focus on multiple-choice questions, failing to address diverse assessment needs in HCI education. The proposed MAS framework for HCI education includes specialized agents for requirement analysis, question generation, validation, and execution. By incorporating adaptive learning and real-time validation, the system enhances question quality, student engagement, and learning outcomes. Building on prior studies (Bulathwela et al., 2023; Kharrufa &amp; Johnson, 2024), this study introduces a collaborative, adaptive AI-driven question-generation system to overcome existing limitations.\n\nResearch Questions:\nHow does a hierarchical MAS framework improve accuracy and relevance in AI-generated questions for HCI education compared to single-agent models?\nWhat impact does real-time cross-agent validation have on adaptability and effectiveness in AI-driven question generation?\nHow does adaptive learning within MAS influence student engagement and learning outcomes in HCI courses?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nAnalyze existing AI-based question generation systems and their applications in HCI education (Bulathwela et al., 2023; Kharrufa &amp; Johnson, 2024).\nDesign and implement a hierarchical MAS with specialized agents for different stages of question generation.\nAssess the system's performance through experimental studies in HCI courses, measuring accuracy, student engagement, and learning outcomes.\n Compare the MAS framework�s effectiveness against single-agent models to evaluate improvements.\n\n\n(b) Development component\nAgent Design: Develop specialized agents for requirement analysis, question generation, validation, and execution.\nIntegration: Implement adaptive learning algorithms and real-time cross-agent validation to enhance system accuracy.\nUser Interface: Create an educator-friendly UI for customizing questions and monitoring performance.\nPilot Testing: Deploy the system in HCI courses, collecting data to assess effectiveness and engagement.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining",
      "Software and Applications",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0227",
    "title": "LLM-based virtual assistant for diet and nutrition management",
    "summary": "LLM-based virtual assistant for diet and nutrition management can be a useful tool to help individuals make informed and healthy food choices. The virtual assistant can be trained on a dataset of nutrition guidelines, including recommendations on macronutrient intake, portion sizes, and dietary restrictions.\n\nThe virtual assistant can be designed to be user-friendly, allowing users to input their dietary preferences and restrictions, such as vegetarianism, gluten-free diets, or food allergies. The LLM-based model can then provide personalized nutrition advice and meal recommendations based on the user's dietary preferences and restrictions.\n\nThe virtual assistant can also be trained to recognize and analyze food images, allowing users to take pictures of their meals and receive personalized nutrition advice and feedback on their food choices. The deep learning model can be trained on a dataset of food images and nutrition information, allowing it to recognize and analyze the nutritional content of different foods.\n\nIn addition, the virtual assistant can provide guidance on healthy meal planning and preparation, as well as suggestions for healthy snacks and drinks. It can also provide information on the nutritional content of restaurant meals and fast food options.\n\nReal-Time Tracking: Integration with wearable devices, such as fitness trackers and smartwatches, will allow the app to provide dynamic insights into physical activity levels and caloric expenditure. This integration will enable users to receive more accurate, real-time recommendations tailored to their activity levels.\n\nExpanded Personalization: Advanced machine learning models will be incorporated to enhance recommendation precision. These models will analyze user\nbehavior, preferences, and dietary patterns to deliver highly tailored advice and content. This level of personalization will cater to individual needs, making the app more relevant and effective.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nData Collection: The first step in developing aLLM-based virtual assistant for diet and nutrition management is to collect data related to nutrition guidelines, dietary preferences, and restrictions.\n\nData Preprocessing: The collected data can be preprocessed to remove duplicates, outliers, and irrelevant information. \n\nLLM-based Model Training: The ChatGPT-based model can be trained on the preprocessed dataset to generate personalized nutrition advice and meal recommendations. \n\nIntegration with Deep Learning Model: The ChatGPT-based virtual assistant can be integrated with a deep learning model for food recognition and analysis.\n\n(b) Development component\nDeveloping a LLM-based virtual assistant for diet and nutrition management mobile application can be a useful tool to help individuals make informed and healthy food choices.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Smartphone Systems and Applications",
      "Natural Language Processing/ Text Mining",
      "Human Computer Interaction",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0228",
    "title": "VirtualPal � Mobile Virtual Avatars for Enhancing Social Interaction and Well-Being Among Elderly Populations",
    "summary": "Recent studies have explored AI-driven virtual avatars to alleviate loneliness among older adults. Yang et al. (2025) highlighted the potential of virtual companions to enhance social interactions and emotional well-being, while Saito et al. (2025) emphasized their role in detecting social isolation. However, these studies focus on text-based interactions, which may not be ideal for elderly users who are less comfortable with text input.\n\nBuilding upon these findings, this research proposes VirtualPal, an AI-driven mobile avatar leveraging NLP, Generative AI, and voice-based interaction to provide personalized companionship through spoken dialogues, emotion detection, and adaptive interactions. By enabling voice-first engagement, VirtualPal ensures seamless, accessible, and empathetic communication, allowing elderly users to interact with an AI companion in a more intuitive and engaging way. This approach aims to increase adoption, reduce loneliness, and improve social well-being in aging populations.\n\nResearch Method\n    Data Collection: Gather physiological and interaction data from users to tailor responses and refine avatar interactions.\n    NLP and Emotion Detection: Implement NLP models to interpret voice input and detect emotions for empathetic responses.\n    User Interaction Analysis: Analyze interaction patterns to assess engagement levels and identify areas for improvement.\n    User Acceptance Evaluation: Conduct surveys and interviews to evaluate satisfaction and acceptance of the virtual avatar.\n    Theoretical Framework: Apply the Technology Acceptance Model (TAM) to assess VirtualPal�s effectiveness in reducing loneliness.\n\nResearch Questions\n    How effective is VirtualPal in reducing loneliness among elderly users?\n    How do users perceive the usability and acceptance of VirtualPal as a voice-based AI companion?\nWhat impact does VirtualPal have on the emotional well-being and social connectivity of elderly users?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research Component\nDevelop and validate methodologies for AI-driven virtual avatars to reduce loneliness, including testing NLP and emotion-detection models tailored for elderly communication, analyzing user interaction patterns, and evaluating user acceptance using metrics like the Cobot-I-7 loneliness scale to measure engagement and emotional well-being.\n\n(b) Development Component\nCreate a mobile app featuring a 3D virtual avatar, implement NLP models for natural conversation, and incorporate emotion detection for empathetic interactions. Develop a backend framework that adapts interactions based on user data, enabling dynamic personalization and providing a meaningful companionship experience for elderly users.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Smartphone Systems and Applications",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0229",
    "title": "Enhancing Personalized Learning in Intelligent Tutoring Systems Using Cognitive Diagnostic Models (CDMs)",
    "summary": "Recent advancements in Intelligent Tutoring Systems (ITS) have incorporated Cognitive Diagnostic Models (CDMs) to assess students� learning gaps and provide personalized feedback. Chen &amp; Liang (2024) introduced the BNMI-DINA model, which integrates Bayesian networks into CDMs to improve learning assessments (Chen &amp; Liang, 2024). Tato et al. (2023) demonstrated the effectiveness of Bayesian-based cognitive diagnosis in detecting specific skill gaps and misconceptions in learners (Tato et al., 2023).\n\nHowever, current ITS implementations lack real-time, automated feedback mechanisms based on CDM outputs. This study addresses this gap by developing an ITS prototype that applies CDMs to assess students' knowledge states and deliver targeted learning recommendations.\nResearch Objective &amp; Method\n\nThis research aims to design and evaluate an ITS model that applies CDMs to assess student learning gaps and provide personalized feedback.\n\n    Develop a lightweight ITS framework that integrates a CDM-based assessment module.\n    Implement adaptive feedback mechanisms based on CDM-generated learning profiles.\n    Evaluate system effectiveness by measuring student performance before and after using the ITS.\n\nResearch Questions\n\n    How accurately can CDMs diagnose student learning gaps in an ITS?\n    How does personalized feedback based on CDMs impact student learning outcomes?\n    What is the student experience and engagement level with an ITS that adapts learning based on CDM results?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review � Study prior applications of CDMs in ITS.\nSystem Development � Build an ITS prototype integrating CDM-based assessment and feedback.\nPilot Testing � Conduct small-group testing with students using a quiz-based learning platform.\nData Collection � Pre- and post-test analysis to measure learning improvement.\nAnalysis &amp; Conclusion � Evaluate CDM accuracy and feedback effectiveness.\n\n(b) Development component\nDevelop a Question Bank � Align questions with CDM diagnostic capabilities.\nImplement Adaptive Feedback � Generate personalized feedback based on student responses.\nDesign a Simple User Interface � Enable students to receive and act on recommendations.\nTest with a Small Group � Collect student performance and engagement data.\nRefine Based on Results � Adjust ITS recommendations based on test outcomes.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining",
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0230",
    "title": "Predicting Student Performance in Intelligent Tutoring Systems Using Dynamic Bayesian Networks (DBNs)",
    "summary": "Dynamic Bayesian Networks (DBNs) have been widely used in predicting student learning progress in Intelligent Tutoring Systems (ITS). Frontiers in Psychology (2024) demonstrated how DBNs can monitor learners� progress dynamically and predict future performance based on past learning behaviors (Frontiers, 2024). Levy (2019) used DBNs to model learning behaviors in educational video games, showing real-time updates of student knowledge levels (Levy, 2019).\n\nHowever, most existing ITS models do not dynamically adjust learning paths based on DBN predictions. This research fills that gap by designing an ITS prototype that employs DBNs to predict student performance trends and adapt learning content accordingly.\nResearch Objective &amp; Method\n\nThis study aims to develop an ITS that leverages DBNs to track and predict student learning progress, enabling real-time adaptation of instructional content.\n\n    Build a predictive learning model using DBNs to analyze past learning behaviors.\n    Implement an adaptive learning system that modifies lessons based on DBN predictions.\n    Evaluate student performance trends by testing the system with real learners.\n\nResearch Questions\n\n    How accurately can DBNs predict student learning progress in an ITS?\n    How does real-time learning adaptation based on DBN predictions impact learning outcomes?\n    What is the effect of predictive analytics on student engagement and retention?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review � Study DBN applications in ITS.\nSystem Development � Implement DBNs in an ITS framework.\nPilot Testing � Track student interactions over multiple learning sessions.\nData Collection � Compare actual vs. predicted student performance.\nAnalysis &amp; Conclusion � Assess DBN effectiveness in predicting learning trends.\n\n(b) Development component\n    Develop a Student Learning Log � Capture past learning behaviors.\n    Implement DBN Prediction Models � Forecast future student progress.\n    Design Adaptive Content Selection � Adjust quizzes based on predictions.\n    Conduct Small-Scale Testing � Evaluate prediction accuracy with real students.\n    Refine Based on Insights � Improve ITS recommendations using test results.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Software and Applications",
      "Natural Language Processing/ Text Mining",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0231",
    "title": "Enhancing UX/UI Design Education with AI-Driven Adaptive Learning: A Design-Based Learning Approach",
    "summary": "Recent advancements in Large Language Models (LLMs) and AI-driven adaptive learning have shown potential in enhancing UX/UI design education. Giretti et al. (2023) explored LLMs in artistic and design tasks, emphasizing AI-assisted scaffolded learning for iterative design education. Their findings suggest AI improves creative ideation and engagement. Similarly, Xu et al. (2023) examined AI-powered conversational agents in education, highlighting human-centered design principles in building trust and usability in adaptive learning.\n\nHowever, current research lacks structured pedagogical integration, particularly in aligning LLMs with Design-Based Learning (DBL) for UX/UI education. Existing studies focus on LLMs as creative tools but do not fully explore their role in adaptive scaffolding or real-time learning feedback. This research addresses this gap by developing an AI-powered adaptive learning platform that integrates real-time scaffolding, interactive design guidance, and user-centered AI interactions, aligning with DBL principles.\n\nThis study aims to develop and evaluate an AI-driven adaptive learning platform that enhances UX/UI design education by providing real-time, personalized AI assistance. Integrating LLMs into a scaffolded learning environment, the system supports students at different skill levels, offering context-aware design feedback and iterative support. Building on Giretti et al. (2023) and Xu et al. (2023), this research improves AI-driven feedback alignment with DBL principles, ensuring structured and adaptive learning experiences.\n\nHow can LLM-driven adaptive learning enhance UX/UI design skills in scaffolded learning environments?\nWhat impact does real-time AI assistance have on student engagement and iterative design in UX/UI education?\nHow does AI-powered scaffolding with DBL principles influence knowledge retention and practical skill application in UX/UI students?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research Component\n    Literature Review: Examine LLM integration in UX/UI education and adaptive learning (Giretti et al., 2023; Xu et al., 2023).\n    Platform Development: Design an AI-learning platform offering real-time, context-aware feedback.\n    Pilot Testing: Implement in UX/UI classrooms to evaluate AI-driven feedback.\n    Data Collection: Assess student engagement and learning outcomes via surveys.\n    Data Analysis: Compare AI-scaffolded learning with traditional methods to evaluate effectiveness.\n\n(b) Development Component\n    Requirement Analysis: Identify UX/UI student needs for AI-driven learning.\n    System Design: Develop a platform integrating LLMs with adaptive feedback.\n    Implementation: Create an AI-powered scaffolded learning system with interactive feedback.\n    Testing &amp; Iteration: Conduct user studies to refine the system based on feedback.\n    Deployment: Launch and continuously improve based on performance data.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Software and Applications",
      "Natural Language Processing/ Text Mining",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0232",
    "title": "Empowering Communities through Digital Literacy: Leveraging Technology for Inclusive Engagement",
    "summary": "Digital literacy has become a crucial component of socio-economic development and community participation. Astuty et al. (2023) explored the integration of digital literacy in higher education, demonstrating its effectiveness in enhancing student engagement and critical thinking. Connected Nation (2023) emphasized the importance of digital literacy programs in promoting digital equity, particularly for underserved communities. Similarly, MediaSmarts (2023) highlighted the role of digital literacy initiatives in fostering civic engagement and digital inclusion.\n\nDespite these advancements, existing research lacks a structured approach to integrating digital literacy programs into local communities with sustainable technology-driven strategies. Most studies focus on institutional education rather than grassroots community-based approaches that emphasize technology-enabled engagement for marginalized populations. This research addresses this gap by developing and assessing a community-focused digital literacy program, ensuring accessibility, engagement, and socio-economic impact.\n\nThis study aims to design and evaluate a digital literacy framework that enhances community engagement through technology. The research will focus on:\n\n    Developing a structured digital literacy curriculum tailored to diverse community needs.\n    Partnering with local organizations to implement technology-enabled learning initiatives.\n    Assessing the program�s impact on digital inclusion, engagement, and socio-economic participation.\n\nThe study aligns with Astuty et al. (2023) by extending digital literacy beyond education into community.\n\n    How can digital literacy programs enhance community engagement and socio-economic participation?\n    What are the key barriers and enablers of technology adoption in community-driven digital literacy initiatives?\n    How effective is an integrated digital literacy framework in fostering long-term engagement and skill development?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review: Examine previous research on tablet-based learning, digital literacy programs, and community engagement (Astuty et al., 2023; Connected Nation, 2023).\nProgram Development: Design a tablet-optimized digital literacy curriculum with interactive lessons (MediaSmarts, 2023).\nImplementation: Deploy the tablet-based program within community centers, libraries, and local organizations.\nData Collection: Conduct pre- and post-training surveys, usability testing, and skill assessments.\nData Analysis: Evaluate learning outcomes, engagement levels, and adoption challenges.\n\n(b) Development component\nIntegrate pre-installed learning apps and offline learning features for accessibility.\nPilot Testing: Distribute tablets to selected participants and track learning progress and engagement.\nProgram Optimization: Refine based on user feedback and performance analytics.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Smartphone Systems and Applications",
      "Mobile Applications",
      "Human Computer Interaction",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0233",
    "title": "Full-Stack Web Development of an Automated Assessment Platform for UML Diagrams",
    "summary": "In this project, student are required to develop a web platform for auto-assessment. The assessments are drawing different UML diagram for object-oriented programming problems. The front-end part requires to have a text editor interface to let users to do their coding. The back-end part requires to have a database, server etc to do the evaluation of submitted work.\nOther additionally features can be added on it if students are capable to do so. \nStudent is required to have knowledge in full-stack web development. For more information, please consult with supervisor.\n\nSpecific details:\n(a) Design component\nweb platform development\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Cloud Computing",
      "Cyber Security",
      "Database Systems",
      "Program Analysis and Optimization",
      "Programming Languages &amp; Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0234",
    "title": "Text Clustering for Handwritten Mathematical Expressions",
    "summary": "Handwritten mathematical expressions present unique challenges for machine learning and pattern recognition due to their variability in writing styles and the complexity of symbols. This project aims to develop a system for clustering handwritten mathematical expressions into meaningful groups, assisting in organizing and recognizing handwritten content for applications such as educational tools, digital archiving, and automated grading systems.\n\nThe objective is to build a system that automatically recognizes, groups, and clusters similar handwritten mathematical expressions using deep learning and clustering algorithms. This system would assist in categorizing mathematical content, enabling efficient searching and retrieval in large datasets.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nImplement a model to recognize handwritten mathematical expressions.\nUse clustering algorithms to group similar handwritten expressions.\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Software and Applications",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0235",
    "title": "Text Replacement in Scene Images",
    "summary": "The rapid growth of image processing technologies has made it possible to extract, manipulate, and replace textual content within scene images, such as street signs, banners, or advertisements. This project aims to develop a system that detects and replaces text in scene images using advanced computer vision and machine learning techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nDevelop an algorithm to replace the detected text with user-specified content\nImplement post-processing techniques to preserve image quality and ensure that the replaced text appears natural.\n\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Artificial Intelligence",
      "Information Retrieval/ Processing",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0236",
    "title": "Tablet for Paperless Assessments (Hardware)",
    "summary": "In this project, student is required to develop a device from sketch for test and exam. The tablet need to be able use for coding and link to some browser-based auto-assessment. Student also develop the hardware part.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nHardware development is limited to integrate the existing hardware components. The challenge of the development mainly on the software and operating system.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Web-based Applications",
      "e-Learning",
      "Operating Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0237",
    "title": "Exploring the Performance and Energy Efficiency of Raspberry Pi Cluster Computing",
    "summary": "This research could investigate the feasibility and performance of building a cluster of Raspberry Pi computers for high-performance computing workloads, such as scientific simulations, data analytics, or machine learning. The study could explore different configurations of the Raspberry Pi cluster, including the number of nodes, the interconnect fabric, and the software stack. The research could also evaluate the energy efficiency of the Raspberry Pi cluster compared to traditional high-performance computing systems, such as server farms or cloud computing platforms. The study could provide insights into the potential use of low-cost and energy-efficient Raspberry Pi clusters for research, education, or small-scale computing applications.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudy on building a cluster of Raspberry Pi computer\n\n(b) Development component\nDevelop a platform to study raspberry pi on cluster computing and run some HPC application on the platform.",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Research & Development",
    "keywords": [
      "Distributed Computing Systems",
      "High-Performance Computing",
      "Cloud Computing",
      "Parallel Computing",
      "Hardware Acceleration"
    ]
  },
  {
    "projectNo": "CCDS25-0238",
    "title": "Smart Object Counter",
    "summary": "Counting people from surveillance videos, counting cells from microscopic images are very tedious and time-consuming work for human being. In this project, a software will be developed to localize and count the objects with similar characteristic in the image or video. We may assumed that the object is known with some prior knowledge for machine learning. However, objects may have some variations from the image due to size, lighting, perspective view issue, overlapping issue etc.   \n\nFor more information, please consult with supervisor.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nDevelop an algorithm which can count items in the images or videos\n\n(b) Development component\nDevelop a software to automatically count items",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Knowledge Representation/ Ontology",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0239",
    "title": "Simultaneous Localization and Mapping (SLAM) in Dynamic Environments",
    "summary": "In this project, we aim at robot localization and 3D reconstruction simultaneously via computer vision techniques. It is also known as Visual SLAM. The challenge of this project is that the environment can be dynamic. The object can be movable. The light condition can be changing over the time especially in the outdoor environment. We not only needs to be able to recognize the objects in the scene, but also be able to classify them as a dynamic object or a static object. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nWe aim to integrate the work of object recognition, semantic segmentation with SLAM.\n\n(b) Development component\nrobust software development is also required. It should be working in real-time.",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Image Analysis &amp; Processing",
      "Artificial Intelligence",
      "Information Retrieval/ Processing",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0240",
    "title": "Class-Agnostic Object Detection for Generalized Scene Understanding",
    "summary": "Class-agnostic object detection refers to the task of detecting and localizing objects in an image without explicitly assigning them to specific classes or categories. \n\nThis research project aims to investigate and develop methods for class-agnostic object detection, a crucial aspect of computer vision that focuses on identifying and localizing objects in images without explicit classification into predefined categories. The project will explore novel approaches to enhance the versatility and efficiency of object detection models in scenarios where object classes are not predefined \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nPropose an improved model for object detection\n\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Video/Audio/Speech Processing",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0241",
    "title": "Tablet for Paperless Assessments (Software)",
    "summary": "In this project, student is required to develop a device from sketch for test and exam. The tablet need to be able use for coding and link to some browser-based auto-assessment. Student also require to build a linux system from sketch. etc.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component\nHardware development is limited to integrate the existing hardware components. The challenge of the development mainly on the software and operating system.",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Web-based Applications",
      "e-Learning",
      "Operating Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0242",
    "title": "Handwritten Mathematical Expression Recognition",
    "summary": "Digitizing handwritten mathematical expression has been an increase in the usage in academia. Researchers may need to write many sophisticated mathematical expressions in their report, research papers etc. in word or Latex. However, it is not a easy job.\n\nIn this project, student will study existing machine learning techniques and develop a system of handwritten mathematical expression recognition. The system will convert the handwritten mathematical expressions into Latex format. It can also apply on auto-assessment system for mathematics quiz. \n\nFor more information, please consult with supervisor.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudy state-of-the-art work on Handwritten Mathematical Expression Recognition. students with good work may have a chance to take part some international competition in the end\n\n(b) Development component\nDevelop a online/offline system to auto detect and recognize the handwritten mathematical expression.",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Artificial Intelligence",
      "Information Retrieval/ Processing",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0243",
    "title": "Detection, Recognition and Understanding Document Layout",
    "summary": "In this project, student is going to develop a software application to detect the document layout. Since the layout of documents (eg. invoice, newspaper, magazine, financial reports etc.) are not standards, different documents which provide the same information can be in a totally different layout. The application needs to adapt the quality of the documents, the style of different document.\n\nFor more information, please consult with supervisor.\n\nSpecific details:\n(a) Design component\nDesign a robust software application to detect the financial tables. \n\n(b) Implementation component\nStudent is free to choose the platform which he/she prefers.\n\n(a) Research component\n \n\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Machine Learning",
      "Database Systems",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0244",
    "title": "Haze Removal From An Image or A Video via Generative Adversarial Networks",
    "summary": "Haze is a common phenomenon in the natural scene. It includes fog, smoke and rain etc. A hazy image or video will make the high-level image processing such as object segmentation and recognition became challenging. Moreover, collecting the hazy image and dehaze image pair data is nearly impossible. Under the different weather conditions and different time instances, it is hard to obtain a pair of images with and without the haze.\n\nIn the project, student will study to use GAN to learn a model to decompose the haze from a hazy image to obtain a clear image.\n\nFor more information, please consult with supervisor.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudy the existing work and propose a new improved solution\n\n(b) Development component\nan simple application to demonstrate the proposed solution",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Video/Audio/Speech Processing",
      "High-Performance Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0245",
    "title": "Time Series Model Unlearning: Addressing Privacy Concerns and Beyond",
    "summary": "Our work is going to explore the emerging challenge of machine unlearning for time series models, particularly in privacy-sensitive domains. While time series modeling has become increasingly powerful and widely applied across various fields, it simultaneously raises significant privacy concerns. In high-privacy scenarios such as electrocardiogram (ECG) analysis, users should retain the right to request the removal of their personal data from trained models. This creates a growing demand for effective unlearning techniques specific to time series models. Despite the importance of this issue, unlearning methods for time series models remain underexplored compared to other machine learning domains. Our work addresses this research gap by examining unique challenges in time series unlearning, proposing novel approaches to selectively remove personal temporal data, and evaluating these methods across healthcare applications where privacy preservation is paramount.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0246",
    "title": "Developing a Trust Evaluation Platform for Data Structures and Algorithms Learning Resources Using TrustRank and AI Verification",
    "summary": "Recent advancements have focused on enhancing the reliability of online educational resources. The TrustRank algorithm, introduced by Gy�ngyi et al. (2004), has been pivotal in distinguishing reputable websites from malicious ones by propagating trust through link structures (Gy�ngyi et al., 2004). Additionally, Large Language Models (LLMs) have been integrated into educational settings to assess content accuracy. For instance, a study by Mu�oz et al. (2024) analyzed the use of AI to verify algorithmic correctness in online learning platforms, highlighting the necessity of AI-driven assessment frameworks (Mu�oz et al., 2024). Furthermore, a peer-reviewed study by Ferdowsi et al. (2024) explored AI's role in validating AI-generated educational materials, demonstrating how AI models can enhance transparency and reproducibility (Ferdowsi et al., 2024).\n\nResearch Objective and Method\nBuilding upon these developments, our objective is to create a platform that evaluates the trustworthiness of Data Structures and Algorithms (DSA) learning resources. By applying the TrustRank algorithm, we aim to identify reputable websites, followed by utilizing LLMs to verify the correctness and efficiency of the content. This approach addresses the gap in automated verification of educational materials, ensuring learners access reliable resources. The integration of link-based trust scoring and AI verification ensures that content is evaluated objectively and rigorously, reducing misinformation in online learning platforms.\n\nResearch Questions\n    How can the TrustRank algorithm be adapted to identify trustworthy DSA educational websites?\n    In what ways can LLMs be employed to assess the correctness and efficiency of DSA content on these platforms?\n    What impact does the integration of TrustRank and AI verification have on the quality of DSA learning resources?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\na) Research Component\nThe study follows key steps: Data Collection compiles DSA educational websites, analyzing their link structures via peer-reviewed sources like ACM Digital Library and IEEE Xplore (Smith et al., 2023). TrustRank Application assigns trust scores using citation patterns to identify reputable sources. AI Verification employs LLMs to assess correctness (test cases), efficiency (Big-O analysis), and code quality. Evaluation measures the correlation between trust scores and actual content quality to validate effectiveness.\n\nb) Development Component\nPlatform Design develops an interface for seamless access to evaluated DSA resources. Integration combines TrustRank and AI analysis for automated content verification. Feedback System enables user input to enhance resource quality. Continuous Improvement ensures periodic AI updates, incorporating research and user feedback to refine trust scoring and resource validation.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining",
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0247",
    "title": "Enhancing Interactive Video Tutorial-Based Programming Education with Large Language Models (LLMs)",
    "summary": "Recent studies have examined the role of Large Language Models (LLMs) in programming education. Cooper et al. (2024) emphasized how LLMs enhance coding, teaching, and inclusion, enabling researchers and students to access knowledge efficiently. Wills et al. (2024) discussed the implications of generative AI for coding in academia, highlighting its benefits and challenges. Millard et al. (2024) explored the potential drawbacks of LLM reliance, such as reduced collaboration and support opportunities among students and researchers.\n\nThis research aims to transform passive video-based programming tutorials into interactive, dialogue-driven learning environments using LLMs. It builds on prior research by investigating LLMs' role in personalized education, reducing cognitive load, and enhancing engagement in complex topics like Data Structures and Algorithms (DSA). The study aligns with constructivist learning theories, focusing on guided problem-solving, real-time feedback, and interactive visualization to improve learning outcomes.\n\nResearch Questions\nHow can LLMs enhance student engagement and comprehension in programming education?\nWhat are the benefits and drawbacks of integrating generative AI into video-based programming tutorials?\nHow can LLM-assisted interactive learning balance automation and human support to foster collaboration?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis study employs a constructivist learning approach, integrating inquiry-based learning and scaffolding, as highlighted by Cooper et al. (2024). The methodology includes: (1) designing an LLM-powered interactive system, (2) conducting a controlled study comparing traditional and interactive tutorials, (3) evaluating student engagement, comprehension, and cognitive load through surveys and performance metrics, and (4) iteratively refining the system based on feedback.\n\n(b) Development component\nThis follows a structured design-based research approach. (1) Develop an AI-powered dialogue system to provide real-time feedback and adaptive scaffolding. (2) Implement an interactive visualization tool to support hands-on learning, addressing the concerns raised by Wills et al.. (3) Integrate collaboration features to counteract potential isolation effects, as noted by Millard et al. (4) Conduct iterative testing to refine engagement and effectiveness.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Human Computer Interaction",
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0248",
    "title": "PoseBuddy: Enhancing Fitness Engagement and Performance through Real-Time Pose Estimation and AI-Driven Personalized Guidance",
    "summary": "Recent advancements in artificial intelligence have significantly impacted fitness applications, especially through real-time pose estimation and AI-guided workouts. Gabarron et al. (2024) demonstrated how AI-driven solutions improve physical activity by increasing engagement and motivation. Ancillao et al. (2021) highlighted technological innovations in human movement assessment, such as pose estimation, which are effective in evaluating physical performance accurately and objectively, essential for personalized fitness feedback.\n\nThis research aims to develop \"PoseBuddy,\" an innovative fitness platform integrating real-time pose estimation technology with large language models (LLMs) for AI-driven guidance. Aligning with previous studies, this research addresses the gap in real-time adaptive feedback by leveraging pose data to personalize fitness guidance effectively. The method involves designing and implementing the PoseBuddy platform, integrating advanced pose estimation and LLMs, and evaluating its effectiveness through controlled experiments.\n\nResearch Questions\nHow do personalized AI-driven workouts utilizing real-time pose data impact users' fitness progress?\nHow does real-time intelligent guidance influence user adherence to fitness routines?\nHow effective are LLMs in delivering personalized fitness advice informed by real-time pose estimation data?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe research methods include (1) literature review based on Ancillao et al. (2021) to guide system development, (2) integration of real-time pose estimation and LLM-driven feedback, (3) controlled trials comparing traditional versus PoseBuddy-enhanced workouts, (4) data collection on user engagement, adherence, and physical outcomes, and (5) qualitative feedback gathering via interviews and surveys to refine the system iteratively.\n\n(b) Development component\nDevelopment includes: (1) designing an intuitive interface capturing real-time pose data, (2) implementing adaptive AI workout recommendations based on user movements, (3) integrating LLM-driven personalized feedback for interactive guidance, (4) seamless integration of real-time pose estimation technologies, and (5) iterative testing and refinement based on structured user feedback to enhance system accuracy, usability, and overall user engagement.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Software and Applications",
      "Human Computer Interaction",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0249",
    "title": "Crowdsourcing Musical Narratives for Sustainable Peace and Development: A Mobile App Approach",
    "summary": "Recent research has highlighted music's role as a powerful medium for social change and peacebuilding. Studies have shown that mobile applications effectively facilitate participatory action research and global collaboration, supporting positive social transformation (Grant &amp; Dingle, 2022). Crowdsourcing via mobile apps has emerged as a critical method in ethnomusicology for collecting, preserving, and disseminating local musical heritage and narratives, particularly in conflict or development contexts (Solis, 2022). Further, research demonstrates the significant role that digital platforms play in empowering communities to document and address social injustices through musical expression (Brunt &amp; Holt, 2022).\n\nThis research aims to develop a mobile app utilizing crowdsourcing to collect and share musical narratives that promote sustainable peace and development. Aligning with previous research, this project addresses the gap in effectively harnessing local media (audio, video, image) to foster peace narratives, enhance social cohesion, and distribute critical information on a global scale. The method includes participatory design with stakeholders, iterative development, and rigorous usability and effectiveness evaluation.\n\nResearch Questions\nHow can mobile crowdsourcing apps effectively capture and disseminate musical narratives for promoting sustainable peace?\nWhat are the impacts of participatory music initiatives delivered via mobile apps on social cohesion and peacebuilding?\nHow do communities in conflict perceive the effectiveness and ethical implications of sharing local narratives globally via mobile technologies?\n\nSpecific details:\na) Design component\n\n\n\n\n\n(b) Implementation component\n\n(a) Research component\nResearch methods include: (1) literature review on ethnomusicology and crowdsourcing platforms, (2) participatory workshops for collaborative design, (3) iterative mobile app development with stakeholder input, (4) field testing the app for effectiveness in capturing and sharing local narratives, (5) qualitative and quantitative evaluation of user engagement, usability, and the impact on social cohesion and peace narratives.\n\n(b) Development component\nDevelopment involves: (1) designing an intuitive mobile app interface for media data capture and annotation, (2) implementing metadata tagging features for crowd-sourced media, (3) developing repository search functionality ensuring compliance with content restrictions, (4) integrating media sharing capabilities, and (5) iterative user testing and refinement cycles to enhance usability, accessibility, and effectiveness in fostering community engagement and promoting peace narratives.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Smartphone Systems and Applications",
      "Human Computer Interaction",
      "Data Mining",
      "Social Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0250",
    "title": "Revolutionizing Recruitment: AI-Driven Intelligent Candidate Matching using Deep Learning and NLP",
    "summary": "Recent research highlights the effectiveness of deep learning and NLP techniques in recruitment processes. Ponnaboyina et al. (2022) demonstrated the significant benefits of integrating NLP-driven methods in resume parsing, candidate assessment, and matching, resulting in improved hiring efficiency. Ironhack (2022) noted that using AI, particularly NLP, reduces bias and accelerates recruitment cycles. These systems primarily automate resume screening and assess candidate compatibility effectively.\n\nThis research aims to create a real-time, intelligent recruitment system leveraging deep learning and NLP. It addresses accuracy, efficiency, and user trust issues identified in previous research by integrating real-time feedback, personalized interviews, and agent-driven candidate matching. The method involves designing an NLP pipeline, LLM-based interactive candidate evaluations, and rigorous usability and accuracy assessments through experimental studies.\n\nResearch Questions\nHow effectively can LLM-based agents extract structured information from unstructured resumes?\nHow does semantic and syntactic analysis through NLP improve candidate-job matching accuracy?\nWhat is the impact of agent-driven interactive assessments on candidate evaluation?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe methodology involves: (1) literature review to identify effective NLP and deep learning techniques, (2) designing an agent-driven NLP pipeline for resume parsing and skill extraction, (3) developing an interactive candidate evaluation module utilizing LLM agents, (4) performing experimental evaluations of matching accuracy and usability, and (5) iterative refinement based on accuracy metrics and user feedback.\n\n(b) Development component\nThe development includes: (1) creating an NLP-powered resume extraction agent for precise data structuring, (2) integrating semantic and syntactic similarity measures for accurate job matching, (3) developing LLM-driven interactive candidate assessments with real-time feedback, (4) designing a transparent and explainable recommendation system, and (5) iterative testing and refinement based on user interaction and feedback.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Human Computer Interaction",
      "Software and Applications",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0251",
    "title": "Real-Time Interactive Mobile Interface for Self-Learning Singing Pitch Training using Large Language Models (LLMs)",
    "summary": "Recent research highlights the benefits and limitations of integrating mobile applications into vocal training. �zden and Uysal (2023) demonstrated that mobile apps effectively enhance technical vocal skills but emphasized traditional methods' superiority for fundamental techniques. Pinho et al. (2022) noted mobile apps' effectiveness in providing flexible, immediate feedback to users. Furthermore, �zden and Uysal (2023) found that mHealth apps offer convenience and effective alternatives to traditional face-to-face training. Leveraging these insights, integrating Large Language Models (LLMs) can further enhance real-time personalized feedback, adaptive evaluations, and targeted training recommendations.\n\nThis research aims to develop a real-time interactive mobile app integrating LLM technology to improve self-learning singing pitch training. It focuses on enhancing intonation and timing through adaptive, personalized, real-time feedback. The method involves designing an LLM-powered classifier for pitch accuracy assessment, a scoring mechanism, and interactive pitch training exercises. Experimental studies will validate its effectiveness by comparing user performance before and after app usage.\n\nResearch Questions\nHow effective is real-time feedback powered by LLMs in improving singing intonation and timing?\nWhat is the user perception of LLM-driven adaptive feedback in mobile-based singing pitch training?\nHow does integrating LLMs into mobile applications affect users' engagement and effectiveness compared to traditional vocal training methods?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe study employs an experimental approach: (1) Literature review to inform system design, (2) Design and integrate LLM algorithms for real-time feedback on pitch accuracy and timing, (3) Conduct controlled trials comparing traditional and app-based training, (4) Gather quantitative and qualitative data on performance improvements and user experiences, (5) Iteratively refine based on collected user feedback.\n\n(b) Development component\nDevelopment includes (1) integrating an LLM-based classifier for pitch accuracy and timing, (2) implementing a real-time scoring and feedback system to inform users immediately, (3) creating interactive, personalized vocal exercises driven by LLM recommendations, and (4) developing an intuitive mobile interface, followed by (4) rigorous iterative testing and user feedback to refine usability, engagement, and educational effectiveness.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Mobile Applications",
      "Smartphone Systems and Applications",
      "Video/Audio/Speech Processing",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0252",
    "title": "Person-centred care for dementia patients: Back end and Front end system student #3",
    "summary": "This is an existing project.\nStudent has to inherit code and work effectively with other team members.\nStudent is expected to ensure system consistency between  front and back end.\nStudent will need to work on software system testing.\n\nSpecific details:\nCandidate is expected to be keen and competent to work with both front end and back end requirements.\nHarmonise UX from mobile app and webapp.\nEnforce robust testing.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0253",
    "title": "Person-centred care for dementia patients (Back end system) student #1",
    "summary": "This is an existing team project.\nStudent has to inherit code and work effectively with other team members.\n\nThe backend system is required to support various users including caregivers, doctors, guardians, and game therapists.\nIt has to store/retrieve patients records in the database.\nIt also has to schedule activities and generate reports/alerts/notifications, etc.\nIt also needs to provision API endpoints for web/mobile access.\n\nSpecific details:\nDesign the backend system and web interface to support more user functions.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0254",
    "title": "Person-centred care for dementia patients (backend system) student #2",
    "summary": "This is an existing team project.\nStudent has to inherit code and work effectively with other team members.\n\nThe backend system is required to support various users including caregivers, doctors, guardians, and game therapists.\nIt has to store/retrieve patients records in the database.\nIt also has to schedule activities and generate reports/alerts/notifications, etc.\nIt also needs to provision API endpoints for web/mobile access.\n\nSpecific details:\nEnhance the backend system and web interface to support more user functions with security features.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0255",
    "title": "Person-centred care for dementia patients (backend system) student #3",
    "summary": "This is an existing team project.\nStudent has to inherit code and work effectively with other team members.\n\nThe backend system is required to support various users including caregivers, doctors, guardians, and game therapists.\nIt has to store/retrieve patients records in the database.\nIt also has to schedule activities and generate reports/alerts/notifications, etc.\nIt also needs to provision API endpoints for web/mobile access.\n\nSpecific details:\nEnhance the backend system and web interface to support more user functions with security features.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0256",
    "title": "Person-centred care for dementia patients: Back end and Front end system student #1",
    "summary": "This is an existing project.\nStudent has to inherit code and work effectively with other team members.\nStudent is expected to ensure system consistency between  front and back end.\nStudent will need to work on software system testing.\n\nSpecific details:\nCandidate is expected to be keen and competent to work with both front end and back end requirements.\nHarmonise UX from mobile app and webapp.\nEnforce robust testing.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0257",
    "title": "Person-centred care for dementia patients: Back end and Front end system student #2",
    "summary": "This is an existing project.\nStudent has to inherit code and work effectively with other team members.\nStudent is expected to ensure system consistency between  front and back end.\nStudent will need to work on software system testing.\n\nSpecific details:\nCandidate is expected to be keen and competent to work with both front end and back end requirements.\nHarmonise UX from mobile app and webapp.\nEnforce robust testing.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0258",
    "title": "Person-centred care for dementia patients (Front end Mobile App) student #1",
    "summary": "This is an existing team project.\nStudent has to inherit code and work effectively with other students in the team.\n\nThis project will design and implement an app to capture the background information of dementia patients in order to provide person-centre care. The app is to be used by nursing staff and needs to connect to a database server. Consideration of user requirements is essential.\n\nSpecific details:\nDesign a good input interface and an efficient interface to the backend database to support the information capture and easy retrieval.\nNew interface may also be added in to support additional features and different device sizes.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Smartphone Systems and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0259",
    "title": "Person-centred care for dementia patients (Front end Mobile App) student #2",
    "summary": "This is an existing team project.\nStudent has to inherit code and work effectively with other students in the team.\n\nThis project will design and implement an app to capture the background information of dementia patients in order to provide person-centre care. The app is to be used by nursing staff and needs to connect to a database server. Consideration of user requirements is essential.\n\nSpecific details:\nDesign a good input interface and an efficient interface to the backend database to support the information capture and easy retrieval.\nNew interface may also be added in to support additional features and different device sizes.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Smartphone Systems and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0260",
    "title": "Person-centred care for dementia patients (backend system) student #4",
    "summary": "This is an existing team project.\nStudent has to inherit code and work effectively with other team members.\n\nThe backend system is required to support various users including caregivers, doctors, guardians, and game therapists.\nIt has to store/retrieve patients records in the database.\nIt also has to schedule activities and generate reports/alerts/notifications, etc.\nIt also needs to provision API endpoints for web/mobile access.\n\nSpecific details:\nEnhance the backend system and web interface to support more user functions with security features.",
    "supervisor": "A/P Chan Syin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0261",
    "title": "Free-form deformation of solid geometric models",
    "summary": "Free-form deformation (FFD) is an important tool in computer-assisted geometric design and animation. Sederberg and Parry proposed a general technique which deformed objects by deforming the space in which the object is embedded. In this framework, surface primitives of any type or degree can be deformed, for example: planes, quadrics, parametric surface patches, or implicit surfaces. This technique is based on trivariate Bernstein polynomials. It enables deformation of objects by manipulating the control points. This free-form deformation technique can be thought of as a method for sculpturing models. \n\nSpecific details:",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0262",
    "title": "Digital Makeup",
    "summary": "In the digital age, portrait and self-portrait photographs are extremely popular and have spread to every corner of the world. When a user checks out his/her friends� status updates on social networks, such as Facebook, Wechat and Instagram, it is not difficult to find many of them like taking their selfie pictures with a new outfit, a cool hairstyle or while enjoying a delightful dinner. There are many programs and apps available for photo editing, spanning from the general purpose software, such as Adobe Photoshop, to the makeover tools to beautify one�s face. These programs can edit eyes, brighten skin, remove wrinkles, reshape face and even perfect the body shape. However, the majority of the tools are designed for only editing raster images. It is well known that vector graphics provides several practical benefits over raster graphics, including sparse representation, compact storage, geometric editablity, information reuse and resolution-independence. In this project, student will learn how to use the state-of-the-art machine learning algorithms to develop a digital makeup algorithm, that can significantly reduce the time/efforts to polish the facial images.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0263",
    "title": "Deep Learning for 3D Digital Geometry Processing (Part 2)",
    "summary": "In this project, student will learn the state-of-the-art techniques for 3D deep learning and its applications to digital geometry processing, such as 3D shape generation, segmentation, parameterization, etc. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0264",
    "title": "Deep Learning for 3D Digital Geometry Processing (Part III)",
    "summary": "In this project, student will learn the state-of-the-art techniques for 3D deep learning and its applications to digital geometry processing, such as 3D shape generation, segmentation, parameterization, etc. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0265",
    "title": "Deep Learning and Computer Chess (Part 3)",
    "summary": "Student will learn the state-of-the-art techniques of computer chess and then develop  a deep neural network based chess engine.  Prerequisites include basic knowledge of chess rules and tools for training deep neural networks. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0266",
    "title": "Deep Learning and Computer Chess (Part 3)",
    "summary": "Student will learn the state-of-the-art techniques of computer chess and then develop  a deep neural network based chess engine.  Prerequisites include basic knowledge of chess rules and tools for training deep neural networks. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0267",
    "title": "Deep Learning for 3D Digital Geometry Processing (Part III)",
    "summary": "In this project, student will learn the state-of-the-art techniques for 3D deep learning and its applications to digital geometry processing, such as 3D shape generation, segmentation, parameterization, etc. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0268",
    "title": "Deep Learning for 3D Digital Geometry Processing (Part 2)",
    "summary": "In this project, student will learn the state-of-the-art techniques for 3D deep learning and its applications to digital geometry processing, such as 3D shape generation, segmentation, parameterization, etc. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0269",
    "title": "Deep Learning for 3D Digital Geometry Processing (Part I)",
    "summary": "In this project, student will learn the state-of-the-art techniques for 3D deep learning and its applications to digital geometry processing, such as 3D shape generation, segmentation, parameterization, etc. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0270",
    "title": "Deep Learning and Computer Chess (Part 2)",
    "summary": "Deep learning has proven a successful technique for boosting the performance of computer chess engines. For example, AlphaZero from Google searches only 80,000 positions per second in chess, and it significantly outperforms the conventional minimax based algorithms. In this project, students will focus on Monte Carlo Tree Search for finding promising moves. A basic knowledge of chess rules is preferred.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P He Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0271",
    "title": "Emotion-Sensitive Conversational AI: Text-Based Emotion Recognition for Enhanced Chatbot Interaction",
    "summary": "Recent research emphasizes text-based emotion recognition to improve conversational AI interactions. Pereira et al. (2022) highlighted the significance of sentiment analysis in enhancing chatbot empathy but noted shortcomings in real-time responsiveness. Goel et al. (2022) demonstrated that accurately detecting textual emotion in real-time significantly enhances conversational quality, empathy, and trust. However, existing studies lack comprehensive real-time adaptive response capabilities.\n\nAddressing gaps noted by Pereira et al. (2022), our research aims to develop an emotion-sensitive conversational AI capable of real-time textual sentiment detection to dynamically improve chatbot interactions. This AI system focuses exclusively on text, enabling adaptive emotional responses and enhancing user trust and satisfaction in conversational interactions on messaging platforms like Slack and WhatsApp.\n\n\nResearch Questions:\n    How accurately can real-time text-based emotion recognition models predict user sentiment?\n    Does integrating adaptive text-based emotional responsiveness significantly enhance perceived empathy and trustworthiness of conversational AI?\n    How does real-time emotional responsiveness impact overall user satisfaction?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nPrevious studies applied supervised machine learning techniques, specifically deep learning models (e.g., BERT and transformer architectures), trained on labeled textual datasets (Pereira et al., 2022). Emotion detection accuracy was validated using metrics like precision, recall, and F1-score. Additionally, user-centered evaluation methods were conducted through user surveys measuring perceived empathy, satisfaction, and chatbot trustworthiness (Goel et al., 2022).\n\n(b) Development component\nCollect labeled textual emotional datasets.\nPreprocess and annotate data for emotion categories.\nTrain emotion recognition models (e.g., fine-tuned transformers).\nIntegrate the model into Slack and WhatsApp APIs.\nEvaluate performance via user feedback, refining iteratively.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Software and Applications",
      "Smartphone Systems and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0272",
    "title": "Visual Question and Answering",
    "summary": "A visual question and answering (VQA) system takes as input an image and a free-form, open-ended, natural language question about the image and produces a natural language answer as the output. This is an AI complete task. Students are required to develop a VQA system that achieves state-of-the-art performance on VQA2.0 benchmark.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n1. Image representation\n2. Natural language representation\n3. Attention model\n\n(b) Development component\n\nAn end-to-end VQA system",
    "supervisor": "A/P Zhang Hanwang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0273",
    "title": "Visual Dialog System",
    "summary": "Visual Dialog is a novel task that requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history (consisting of the image caption and a sequence of previous questions and answers), the agent has to answer a follow-up question in the dialog. To perform well on this task, the agent needs to ground the query not only in the visual content but also in the dialog history. In this project, you are required to design a visual chatbot and evaluate your results on https://visualdialog.org/challenge/2018\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n1. Dialog system\n2. Visual dialog\n3. Memory networks\n\n(b) Development component\nVisual chatbot system",
    "supervisor": "A/P Zhang Hanwang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0274",
    "title": "Bias Detection and Mitigation in AI Models",
    "summary": "This project focuses on identifying biases in machine learning models. It involves developing an algorithm that detects and quantifies bias in datasets and models, then applies fairness-aware techniques (e.g., reweighting, adversarial debiasing) to mitigate bias.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nLarge-language models, reinforcement learning\n\n(b) Development component\n\nLarge-language model API like ChatGPT, DeepSeek API tools, PyTorch",
    "supervisor": "A/P Zhang Hanwang",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0275",
    "title": "Fake News Detection Using Natural Language Processing (NLP)",
    "summary": "This project involves developing an NLP-based system to detect misinformation and fake news. It will use deep learning models like transformers (e.g., BERT, RoBERTa) to classify news articles based on credibility scores.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nLarge-language model, Reinforcement learning\n(b) Development component\n\nLarge-language model API like ChatGPT, DeepSeek API tools, PyTorch",
    "supervisor": "A/P Zhang Hanwang",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0276",
    "title": "Reinforcement Learning-Based Object Trajectory Prediction for Dynamic Environments",
    "summary": "This project focuses on using Reinforcement Learning (RL) to predict the trajectory of moving objects in dynamic environments. By leveraging deep RL algorithms (e.g., DDPG, PPO, SAC), the model will learn to anticipate object motion based on past trajectories and environmental conditions. Applications include autonomous vehicles, robotics, and sports analytics.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nLarge-language model, and reinforcement learning\n\n(b) Development component\n\nLarge-language model API like ChatGPT, DeepSeek API tools, PyTorch",
    "supervisor": "A/P Zhang Hanwang",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0277",
    "title": "High-Fidelity Image Generation Using Diffusion Models for Realistic Synthesis",
    "summary": "This project explores the use of diffusion models (e.g., Stable Diffusion, DDPM, or Latent Diffusion Models) for generating high-quality images from noise. The model will be trained on diverse datasets to synthesize realistic images with controllable attributes, enabling applications in artistic content creation, medical imaging, and data augmentation.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Zhang Hanwang",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0278",
    "title": "Diffusion Models for Intelligent Image Editing and Inpainting",
    "summary": "This project focuses on leveraging diffusion models (e.g., Stable Diffusion, Imagen, or DALLE-2) for image editing, inpainting, and style transfer. The model will enable context-aware modifications, such as object removal, background replacement, and style transformation, by learning to reconstruct and modify images while preserving realism. Applications include photo restoration, creative design, and AI-assisted content generation.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Zhang Hanwang",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0279",
    "title": "Learning-Augmented Algorithms (Part D)",
    "summary": "Online computation seeks to develop algorithms that do not know the entire inputs beforehand and have to make irrevocable decisions as inputs are gradually released over time. This kind of problems are prevalent in real-world applications. There have been two main approaches to address the uncertainty in future inputs. One approach is to design online algorithms and benchmark their performance through competitive analysis against optimal offline solutions that have prior knowledge of the entire inputs. However, the resultant worst-case guarantees are usually very pessimistic without any assumptions on future inputs at all. Another approach is to train machine learning models with historical data to predict future inputs and then respond according to the predictions. But a major drawback is that this method often lacks provable performance guarantees. To overcome their respective disadvantages, a recent trend is to combine these two approaches by augmenting online algorithms with machine-learned predictions. The goal is to come up with algorithms having practical performance and theoretical guarantees improving with the quality of predictions and meanwhile staying bounded when predictions have large errors. In this project, the student will apply the framework of learning-augmented algorithms to a selected problem such as scheduling or caching. The student will implement and evaluate existing algorithms that make sensible use of predictions in addressing the problem with some real datasets. If possible, the student will also design new algorithms or enhance existing algorithms to improve their performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign new algorithms or enhance existing algorithms to improve their performance.\n\n(b) Development component\n\nImplement and evaluate existing learning-augmented algorithms with real datasets.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Theory &amp; Algorithms",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0280",
    "title": "Evaluating Job Scheduling Algorithms in Clouds (Part B)",
    "summary": "In modern data intensive computing, it is increasingly common for jobs to be executed in a distributed fashion across multiple machine clusters or datacenters to take advantage of data locality. Given the limited amount of resources available at each cluster or datacenter, the jobs inherently compete for resources with each other. Therefore, it is essential to design fair and efficient algorithms for sharing resources among concurrently running distributed jobs. Distributed jobs with parallel tasks have salient characteristics such as they do not need to acquire resources from various clusters or datacenters simultaneously in any fixed proportions and a job is completed only when all of its tasks are finished. These characteristics introduce new research challenges to job scheduling. The objective of this project is to analyze a real job trace from production systems such as Google and Alibaba and evaluate various job scheduling algorithms using the trace. If possible, the student will also design new algorithms to improve the job scheduling efficiency.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nAnalyze a real job trace and evaluate various job scheduling algorithms using the trace. \n\n(b) Development component\n\nDesign and implement new algorithms to improve the job scheduling efficiency.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Theory &amp; Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0281",
    "title": "Evaluating Resource Allocation Algorithms in Clouds (Part B)",
    "summary": "In modern data intensive computing, it is increasingly common for jobs to be executed in a distributed fashion across multiple machine clusters or datacenters to take advantage of data locality. Given the limited amount of resources available at each cluster or datacenter, the jobs inherently compete for resources with each other. Therefore, it is essential to design fair and efficient algorithms for sharing resources among concurrently running distributed jobs. Distributed jobs with parallel tasks have salient characteristics such as they do not need to acquire resources from various clusters or datacenters simultaneously in any fixed proportions and a job is completed only when all of its tasks are finished. These characteristics introduce new research challenges to job scheduling. The objective of this project is to analyze a real job trace from production systems such as Google and Alibaba and evaluate various job scheduling algorithms using the trace. If possible, the student will also design new algorithms to improve the job scheduling efficiency.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nAnalyze a real job trace and evaluate various job scheduling algorithms using the trace. \n\n(b) Development component\n\nDesign and implement new algorithms to improve the job scheduling efficiency.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Theory &amp; Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0282",
    "title": "Learning-Augmented Algorithms (Part A)",
    "summary": "Online computation seeks to develop algorithms that do not know the entire inputs beforehand and have to make irrevocable decisions as inputs are gradually released over time. This kind of problems are prevalent in real-world applications. There have been two main approaches to address the uncertainty in future inputs. One approach is to design online algorithms and benchmark their performance through competitive analysis against optimal offline solutions that have prior knowledge of the entire inputs. However, the resultant worst-case guarantees are usually very pessimistic without any assumptions on future inputs at all. Another approach is to train machine learning models with historical data to predict future inputs and then respond according to the predictions. But a major drawback is that this method often lacks provable performance guarantees. To overcome their respective disadvantages, a recent trend is to combine these two approaches by augmenting online algorithms with machine-learned predictions. The goal is to come up with algorithms having practical performance and theoretical guarantees improving with the quality of predictions and meanwhile staying bounded when predictions have large errors. In this project, the student will apply the framework of learning-augmented algorithms to a selected problem such as scheduling or caching. The student will implement and evaluate existing algorithms that make sensible use of predictions in addressing the problem with some real datasets. If possible, the student will also design new algorithms or enhance existing algorithms to improve their performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign new algorithms or enhance existing algorithms to improve their performance.\n\n(b) Development component\n\nImplement and evaluate existing learning-augmented algorithms with real datasets.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Theory &amp; Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0283",
    "title": "Evaluating Job Scheduling Algorithms in Clouds (Part A)",
    "summary": "In modern data intensive computing, it is increasingly common for jobs to be executed in a distributed fashion across multiple machine clusters or datacenters to take advantage of data locality. Given the limited amount of resources available at each cluster or datacenter, the jobs inherently compete for resources with each other. Therefore, it is essential to design fair and efficient algorithms for sharing resources among concurrently running distributed jobs. Distributed jobs with parallel tasks have salient characteristics such as they do not need to acquire resources from various clusters or datacenters simultaneously in any fixed proportions and a job is completed only when all of its tasks are finished. These characteristics introduce new research challenges to job scheduling. The objective of this project is to analyze a real job trace from production systems such as Google and Alibaba and evaluate various job scheduling algorithms using the trace. If possible, the student will also design new algorithms to improve the job scheduling efficiency.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nAnalyze a real job trace and evaluate various job scheduling algorithms using the trace. \n\n(b) Development component\n\nDesign and implement new algorithms to improve the job scheduling efficiency.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Theory &amp; Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0284",
    "title": "Evaluating Resource Allocation Algorithms in Clouds (Part A)",
    "summary": "In modern data intensive computing, it is increasingly common for jobs to be executed in a distributed fashion across multiple machine clusters or datacenters to take advantage of data locality. Given the limited amount of resources available at each cluster or datacenter, the jobs inherently compete for resources with each other. Therefore, it is essential to design fair and efficient algorithms for sharing resources among concurrently running distributed jobs. Distributed jobs with parallel tasks have salient characteristics such as they do not need to acquire resources from various clusters or datacenters simultaneously in any fixed proportions and a job is completed only when all of its tasks are finished. These characteristics introduce new research challenges to job scheduling. The objective of this project is to analyze a real job trace from production systems such as Google and Alibaba and evaluate various job scheduling algorithms using the trace. If possible, the student will also design new algorithms to improve the job scheduling efficiency.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nAnalyze a real job trace and evaluate various job scheduling algorithms using the trace. \n\n(b) Development component\n\nDesign and implement new algorithms to improve the job scheduling efficiency.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Theory &amp; Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0285",
    "title": "Learning-Augmented Algorithms (Part C)",
    "summary": "Online computation seeks to develop algorithms that do not know the entire inputs beforehand and have to make irrevocable decisions as inputs are gradually released over time. This kind of problems are prevalent in real-world applications. There have been two main approaches to address the uncertainty in future inputs. One approach is to design online algorithms and benchmark their performance through competitive analysis against optimal offline solutions that have prior knowledge of the entire inputs. However, the resultant worst-case guarantees are usually very pessimistic without any assumptions on future inputs at all. Another approach is to train machine learning models with historical data to predict future inputs and then respond according to the predictions. But a major drawback is that this method often lacks provable performance guarantees. To overcome their respective disadvantages, a recent trend is to combine these two approaches by augmenting online algorithms with machine-learned predictions. The goal is to come up with algorithms having practical performance and theoretical guarantees improving with the quality of predictions and meanwhile staying bounded when predictions have large errors. In this project, the student will apply the framework of learning-augmented algorithms to a selected problem such as scheduling or caching. The student will implement and evaluate existing algorithms that make sensible use of predictions in addressing the problem with some real datasets. If possible, the student will also design new algorithms or enhance existing algorithms to improve their performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign new algorithms or enhance existing algorithms to improve their performance.\n\n(b) Development component\n\nImplement and evaluate existing learning-augmented algorithms with real datasets.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Theory &amp; Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0286",
    "title": "Learning-Augmented Algorithms (Part F)",
    "summary": "Online computation seeks to develop algorithms that do not know the entire inputs beforehand and have to make irrevocable decisions as inputs are gradually released over time. This kind of problems are prevalent in real-world applications. There have been two main approaches to address the uncertainty in future inputs. One approach is to design online algorithms and benchmark their performance through competitive analysis against optimal offline solutions that have prior knowledge of the entire inputs. However, the resultant worst-case guarantees are usually very pessimistic without any assumptions on future inputs at all. Another approach is to train machine learning models with historical data to predict future inputs and then respond according to the predictions. But a major drawback is that this method often lacks provable performance guarantees. To overcome their respective disadvantages, a recent trend is to combine these two approaches by augmenting online algorithms with machine-learned predictions. The goal is to come up with algorithms having practical performance and theoretical guarantees improving with the quality of predictions and meanwhile staying bounded when predictions have large errors. In this project, the student will apply the framework of learning-augmented algorithms to a selected problem such as scheduling or caching. The student will implement and evaluate existing algorithms that make sensible use of predictions in addressing the problem with some real datasets. If possible, the student will also design new algorithms or enhance existing algorithms to improve their performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign new algorithms or enhance existing algorithms to improve their performance.\n\n(b) Development component\n\nImplement and evaluate existing learning-augmented algorithms with real datasets.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Theory &amp; Algorithms",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0287",
    "title": "Learning-Augmented Algorithms (Part B)",
    "summary": "Online computation seeks to develop algorithms that do not know the entire inputs beforehand and have to make irrevocable decisions as inputs are gradually released over time. This kind of problems are prevalent in real-world applications. There have been two main approaches to address the uncertainty in future inputs. One approach is to design online algorithms and benchmark their performance through competitive analysis against optimal offline solutions that have prior knowledge of the entire inputs. However, the resultant worst-case guarantees are usually very pessimistic without any assumptions on future inputs at all. Another approach is to train machine learning models with historical data to predict future inputs and then respond according to the predictions. But a major drawback is that this method often lacks provable performance guarantees. To overcome their respective disadvantages, a recent trend is to combine these two approaches by augmenting online algorithms with machine-learned predictions. The goal is to come up with algorithms having practical performance and theoretical guarantees improving with the quality of predictions and meanwhile staying bounded when predictions have large errors. In this project, the student will apply the framework of learning-augmented algorithms to a selected problem such as scheduling or caching. The student will implement and evaluate existing algorithms that make sensible use of predictions in addressing the problem with some real datasets. If possible, the student will also design new algorithms or enhance existing algorithms to improve their performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign new algorithms or enhance existing algorithms to improve their performance.\n\n(b) Development component\n\nImplement and evaluate existing learning-augmented algorithms with real datasets.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Theory &amp; Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0288",
    "title": "Learning-Augmented Algorithms (Part E)",
    "summary": "Online computation seeks to develop algorithms that do not know the entire inputs beforehand and have to make irrevocable decisions as inputs are gradually released over time. This kind of problems are prevalent in real-world applications. There have been two main approaches to address the uncertainty in future inputs. One approach is to design online algorithms and benchmark their performance through competitive analysis against optimal offline solutions that have prior knowledge of the entire inputs. However, the resultant worst-case guarantees are usually very pessimistic without any assumptions on future inputs at all. Another approach is to train machine learning models with historical data to predict future inputs and then respond according to the predictions. But a major drawback is that this method often lacks provable performance guarantees. To overcome their respective disadvantages, a recent trend is to combine these two approaches by augmenting online algorithms with machine-learned predictions. The goal is to come up with algorithms having practical performance and theoretical guarantees improving with the quality of predictions and meanwhile staying bounded when predictions have large errors. In this project, the student will apply the framework of learning-augmented algorithms to a selected problem such as scheduling or caching. The student will implement and evaluate existing algorithms that make sensible use of predictions in addressing the problem with some real datasets. If possible, the student will also design new algorithms or enhance existing algorithms to improve their performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign new algorithms or enhance existing algorithms to improve their performance.\n\n(b) Development component\n\nImplement and evaluate existing learning-augmented algorithms with real datasets.",
    "supervisor": "A/P Tang Xueyan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Theory &amp; Algorithms",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0289",
    "title": "Enhancing Software Engineering Interview Preparedness through AI-Driven Multi-Agent Simulations",
    "summary": "Recent advancements in AI-driven interview preparation have shown significant potential in improving student confidence and technical skills. Wu et al. (2024) demonstrated that AI-based interview simulations enhance problem-solving abilities through real-time feedback and adaptive questioning. Similarly, Zhang et al. (2025) explored Large Language Models (LLMs) in software engineering education, demonstrating increased engagement and personalized learning. However, these studies primarily rely on single-agent AI interactions, which limit realism and diversity in interview scenarios. Furthermore, Ferino et al. (2025) highlighted the need for structured pedagogical frameworks in AI-driven learning, an aspect often overlooked in current approaches.\n\nTo address these gaps, this project applies Alshammari and Singh�s (2021) Adaptive Learning Framework, which emphasizes individualized instruction as crucial for sustained academic progress and student satisfaction. Unlike traditional static interview simulations, this research introduces a Multi-Agent System with LLMs, which adapts to each learner's unique needs by simulating diverse interviewer roles�technical evaluators, behavioral interviewers, and senior engineers�to create a realistic, personalized, and structured interview experience.\n\nResearch Questions\nHow effective is an AI-driven multi-agent interview simulation tool in improving software engineering students' technical interview performance?\nWhat are students� perceptions of the usability, realism, and effectiveness of MAS-based AI interview simulations?\nHow does personalized learning and adaptive AI feedback impact students' confidence and procedural knowledge acquisition for real-world software engineering interviews?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nDevelop an AI-driven Multi-Agent Interview Simulation Tool that adapts to individual student needs, improving their technical interview preparedness.\nImplement individualized learning mechanisms that adjust question difficulty, focus areas, and feedback based on real-time learner performance.\nEvaluate the effectiveness of this adaptive simulation in improving students' confidence, problem-solving skills, and real-world interview performance.\n\n(b) Development component\n (1) Designing MAS architecture to simulate diverse interviewer behaviors; (2) Integrating LLMs to enable adaptive questioning and context-aware response evaluation; (3) Developing an intuitive user interface for interactive AI-driven interviews; (4) Implementing personalized feedback mechanisms, following SAT principles; (5) Conducting iterative testing with students to refine system effectiveness and usability based on real-world interview performance tracking.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Software and Applications",
      "Natural Language Processing/ Text Mining",
      "Programming Languages &amp; Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0290",
    "title": "SSL-TLS Security Flaws 4",
    "summary": "The HTTPS protocol is supposed to be encrypted and secure against eavesdropper. This project looks at cases where it can go wrong. Cases studied are from real life cases. Interested students will study from a list of cases proposed by supervisor. They can even propose other cases subject to agreement of supervisor.\n\nStudents will have to take the module Crypto and Network security and have some mathematical maturity to read mathematical crypto stuff in papers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Data Analytics",
      "Theory &amp; Algorithms",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0291",
    "title": "Topics in RSA cryptosystem",
    "summary": "A mathematical study of RSA public key crypto algorithms.\nRSA is the most famous public key cryptosystems. \nSome parameters are weak.\nin this project student will study the algorithm and understand how to generate secure parameters for RSA.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nstudy existing systems\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0292",
    "title": "Topics in ECC (Elliptic Curve Cryptosystem)",
    "summary": "ECC is one of the famous cryptosytem. student will study the underlying algorithms and also their properties.\nstudent must be interested in some math.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0293",
    "title": "Study of Post-quantum algorithms 1",
    "summary": "Post quantum algorithms are being developed to be an answer to cryptography in the scenario where quantum computers becomes a reality.\nwe will study one of the famous algos and students will have a choice.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0294",
    "title": "Study of Post quantum algorithms 2",
    "summary": "Post quantum algorithms are being developed to be an answer to cryptography in the scenario where quantum computers becomes a reality.\nwe will study one of the famous algos and students will have a choice.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0295",
    "title": "Topics in Cryptography",
    "summary": "Students are free to work on any areas in cryptography in consultation with advisor. project scope can range from easy survey to more in depth implementation, depending on student ability.\nstudents are advised to take up 4010 applied crypto course.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0296",
    "title": "Topics in Crypto 3",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0297",
    "title": "Topics in Crypto 4",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0298",
    "title": "Topics in Crypto 5",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0299",
    "title": "Topics in Crypto 6",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0300",
    "title": "Topics in Crypto 7",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0301",
    "title": "Topics in Crypto 4",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0302",
    "title": "Topics in Crypto 3",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0303",
    "title": "Study of Post quantum algorithms 2",
    "summary": "Post quantum algorithms are being developed to be an answer to cryptography in the scenario where quantum computers becomes a reality.\nwe will study one of the famous algos and students will have a choice.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0304",
    "title": "Topics in Crypto 3",
    "summary": "Cryptography is the science of scrambling bits with key, and is used to protect data from prying eyes. It is a vast field. In this project students will be free to pursue any line of crypto work in consultation with me.\nstudents are expected to code parts of his/her work\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Security",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0305",
    "title": "Topics in combinatorics or number theory or probability or other areas of discrete math -1",
    "summary": "Study and implement solutions to some interesting math problems encountered in computer science. students can choose their own sourced problems. I will suggest some problems for students to consider.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Discrete Math"
    ]
  },
  {
    "projectNo": "CCDS25-0306",
    "title": "Topics in Discrete Math 2",
    "summary": "Study and implement solutions to some interesting math problems encountered in computer science. students can choose their own sourced problems. I will suggest some problems for students to consider.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Discrete Math"
    ]
  },
  {
    "projectNo": "CCDS25-0307",
    "title": "Topics in Discrete Math 3",
    "summary": "Study and implement solutions to some interesting math problems encountered in computer science. students can choose their own sourced problems. I will suggest some problems for students to consider.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tay Kian Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Discrete Math"
    ]
  },
  {
    "projectNo": "CCDS25-0308",
    "title": "Efficient Visual Localization on Heterogeneous Computing Platforms",
    "summary": "This project aims to implement a self-supervised visual localization algorithm on a heterogeneous computing platform comprising a CPU, GPU, and hardware accelerator. The objective is to achieve real-time performance and maximize energy efficiency by strategically distributing computational tasks across the available processing units based on their strengths.  The algorithm will be designed to optimize data flow and minimize latency through parallel processing, memory sharing, and load balancing between the CPU, GPU, and hardware accelerator. Performance will be evaluated in terms of frame rate and power consumption to ensure the system meets the stringent requirements of real-time operation in resource-constrained environments.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nParallel processing, memory sharing, and load balancing between the CPU, GPU, and hardware accelerator.\n\n(b) Development component\nImplementation on a heterogeneous computing platform.",
    "supervisor": "A/P Lam Siew Kei",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Research & Development",
    "keywords": [
      "Computer Architecture",
      "Hardware Acceleration",
      "Microprocessor-based Systems",
      "Real-Time / Embedded Systems",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0309",
    "title": "Realistic Simulation of Multi-Robot Visual SLAM for Remote Teleoperation",
    "summary": "This project aims to develop a realistic simulation of a remote environment where multiple mobile robots equipped with visual SLAM (Simultaneous Localization and Mapping) capabilities operate collaboratively to capture and merge 3D point clouds of objects in the environment. The simulation will model the real-world challenges of a hazardous environment. Advanced SLAM algorithms will enable the robots to autonomously explore the environment, localize themselves, and map objects in real-time. The merged 3D point clouds will provide a comprehensive and consistent representation of the remote environment, which will serve as the foundation for effective human teleoperation and remote manipulation. The simulation will be validated based on localization accuracy, mapping consistency, and real-time performance under simulated environmental conditions.\n\nSpecific details:\n(a) Design component\nThe simulation will model the real-world challenges of a hazardous environment.\n\n(b) Implementation component\nDevelop a realistic simulation of a remote environment where multiple mobile robots equipped with visual SLAM (Simultaneous Localization and Mapping) capabilities operate collaboratively to capture and merge 3D point clouds of objects in the environment.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lam Siew Kei",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Virtual Reality",
      "Human Computer Interaction",
      "Visual Computing",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0310",
    "title": "3D Reconstruction and Intuitive Interface for Remote Teleoperation",
    "summary": "This project focuses on the reconstruction of 3D point clouds collected by multiple mobile robots into a realistic virtual object that a human operator can visualize. The human operator can also  instruct the robots through an intuitive interface. The 3D reconstruction process will involve aligning and fusing point clouds to create a consistent virtual model of the remote object. The interface will allow the human operator to interact intuitively with the virtual object. The operator�s inputs will be translated into precise commands for the robots. Performance will be evaluated based on the accuracy of the reconstructed object, the responsiveness of the interface, and the operator�s ability to control the remote environment effectively.\n\nSpecific details:\n(a) Design component\nIntuitive interface for human operator to manipulate virtual object and provide high level commands to robots.\n\n(b) Implementation component\nReconstruction of 3D point clouds collected by multiple mobile robots into a realistic virtual object.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lam Siew Kei",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Human Computer Interaction",
      "Robotics",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0311",
    "title": "Simulation Environment for Human-Virtual Robot Collaboration",
    "summary": "This project aims to design and implement a simulation environment where a human operator can interact with and collaborate alongside virtual robots to accomplish complex tasks. The simulation will capture the human's movements and actions within the virtual world, allowing virtual robots to adapt their behaviors and responses based on real-time human input. The robots will have the capability to autonomously adjust their task execution strategy or follow direct human instructions to optimize overall productivity. The student will have the flexibility to propose interesting and challenging working environments, such as manufacturing lines, disaster response scenarios, or medical settings, to test and refine the collaboration dynamics. The simulation�s performance will be evaluated based on task completion time, accuracy, and the adaptability of the virtual robots to human actions.\n\nSpecific details:\n(a) Design component\nDesign a simulation environment where a human operator can interact with and collaborate alongside virtual robots to accomplish complex tasks. \n\n(b) Implementation component\nImplement a simulation environment where a human operator can interact with and collaborate alongside virtual robots to accomplish complex tasks. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lam Siew Kei",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Virtual Reality",
      "Visual Computing",
      "Human Computer Interaction",
      "Robotics",
      "Gamification"
    ]
  },
  {
    "projectNo": "CCDS25-0312",
    "title": "Development of a Wearable for Human-Virtual Robot Interaction",
    "summary": "This project focuses on the design and development of a wearable device equipped with visual SLAM (Simultaneous Localization and Mapping) and NLP (Natural Language Processing) capabilities to enable seamless human-robot collaboration in a mixed virtual and physical environment. The wearable will track the human operator�s location and movements within the virtual world while allowing the operator to issue high-level commands through natural language. The SLAM system will provide accurate localization and environmental mapping, while the NLP system will interpret and translate human instructions into actionable commands for the virtual robots. The wearable will enable intuitive control and efficient task execution, improving the overall coordination between the human and virtual robots. Performance will be measured based on the accuracy of localization, command responsiveness, and task completion efficiency.\n\nSpecific details:\n(a) Design component\nDesign of a wearable device equipped with visual SLAM and NLP  capabilities to enable seamless human-robot collaboration in a mixed virtual and physical environment.\n\n(b) Implementation component\nImplementation of a wearable device equipped with visual SLAM and NLP  capabilities to enable seamless human-robot collaboration in a mixed virtual and physical environment.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lam Siew Kei",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Architecture",
      "Microprocessor-based Systems",
      "Low-power Computing",
      "Real-Time / Embedded Systems",
      "Mixed Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0313",
    "title": "RL-Free Multi-Agent LLM Framework for Human Value Alignment",
    "summary": "Large language models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks, yet ensuring that their outputs align with human values and societal norms remains a critical challenge. While Reinforcement Learning from Human Feedback (RLHF) has shown promise in achieving value alignment, it also faces limitations such as high training costs, low sample efficiency, and complex policy design. To address these concerns, we propose a multi-agent framework that does not rely on reinforcement learning. Instead, it establishes roles and interaction mechanisms among multiple LLM-based agents, combined with explicit constraints on human values and norms, and an iterative feedback loop to refine the outputs. Through multi-turn discussion, negotiation, and evaluation, this approach dynamically identifies and corrects potential misalignments, reducing training overhead and providing a new perspective on value alignment. Our framework offers a viable solution for high-stakes applications�such as education, healthcare, and legal systems�where safe and reliable alignment with human values is paramount, and opens new avenues for further research on LLM-based human value alignment.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0314",
    "title": "Privacy-Preserving Classification of Human vs. LLM-Generated Text: Mitigating Leakage Risks in Sensitive Contexts",
    "summary": "The rapid proliferation of large language models (LLMs) has blurred the boundaries between human and machine-generated content, creating critical needs for reliable classification systems. While existing research predominantly focuses on improving detection accuracy through advanced algorithms, these approaches often neglect the crucial dimension of privacy preservation � particularly problematic when handling sensitive texts containing personal identifiers, medical histories, or confidential business information. This study addresses the under-explored challenge of developing classification frameworks that simultaneously maintain detection efficacy and prevent privacy leakage during analysis processes.  \n\nWe identify three key vulnerabilities in conventional detection pipelines: 1) Exposure of raw text to third-party classifiers, 2) Traceability of analysis patterns that could reveal protected content, and 3) Absence of compliance mechanisms for regulated industries. Through systematic analysis of real-world scenarios involving healthcare documentation, legal contracts, and educational materials, we demonstrate how current state-of-the-art methods inadvertently expose sensitive information even while performing legitimate classification tasks.  \n\nOur research establishes novel evaluation criteria for privacy-aware detection systems, emphasizing the balance between classification precision and information protection robustness. By formalizing threat models specific to text authorship attribution, we reveal fundamental tensions between feature extraction requirements and privacy constraints. The proposed framework contributes to AI safety research by providing methodological guidelines for implementing end-to-end protections without compromising detection utility, particularly crucial for applications governed by GDPR, HIPAA, and other data protection regulations. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Dong Wei",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Security"
    ]
  },
  {
    "projectNo": "CCDS25-0315",
    "title": "Multimodal AI-Powered Storytelling: Integrating Text, Image, and Video Generation for Personalized Children's Narratives",
    "summary": "Recent AI advancements have enabled storytelling applications integrating text, image, and video generation, enhancing children's engagement and learning. Chen (2024) highlights AI�s role in early education, showing how LLMs improve language acquisition. Jeong (2025) presents a multimodal AI system that fuses text and image generation for coherent storytelling. Han et al. (2022) explore video synthesis using multimodal conditioning, combining text and visuals for animated content. These studies emphasize the need for a seamless pipeline that connects text, image, and video in AI storytelling. This research builds on these findings by proposing a framework where LLMs generate narratives, text-to-image models create illustrations, and text-to-video models animate content, ensuring an immersive storytelling experience.\n\nThis study aims to develop an AI-powered storytelling application integrating specialized AI models to enhance engagement, personalization, and educational value. The system will be evaluated using user interaction analytics, F1 scores for recommendation accuracy, and usability studies to ensure optimal storytelling. F1-score, balancing precision and recall, has been widely used in evaluating recommendation systems (Gunawardana &amp; Shani, 2015; Luo et al., 2022; Zhang &amp; Wang, 2023). These methods will ensure AI-generated content remains coherent, engaging, and personalized.\n\nResearch Questions\n    How does integrating AI models for text, image, and video improve coherence and personalization in AI-generated stories?\n    What are the educational benefits of using AI-driven storytelling in early childhood learning?\n    How can real-time user interaction data be leveraged to refine and personalize AI-generated storytelling experiences?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research Component\nThis study develops a multimodal AI storytelling application, building on Chen (2024) and Jeong (2025). LLMs fine-tuned with children's literature will generate structured stories. Text-to-image models will create illustrations, ensuring coherence, while text-to-video models animate these visuals. A hybrid recommendation system will adapt content based on user preferences. System performance will be evaluated using user engagement metrics, usability studies, and F1-score for recommendation accuracy (Gunawardana &amp; Shani, 2015; Luo et al., 2022; Zhang &amp; Wang, 2023).\n\n(b) Development Component\n    User Interface Design: Child-friendly interactive design.\n    AI Model Integration: Implementing LLMs, text-to-image, and text-to-video models.\n    Personalization Engine: Adapting content based on user behavior.\n    Backend Infrastructure: Real-time cloud-based AI processing.\n    Usability Testing &amp; Optimization: A/B testing and iterative refinements.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Video/Audio/Speech Processing",
      "Natural Language Processing/ Text Mining",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0316",
    "title": "The Social Library: Integrating AI-Powered Recommendations and Social Networking for Enhanced Book Sharing",
    "summary": "Recent advancements in AI-driven book recommendation systems have enhanced personalization and user satisfaction. Tarus et al. (2023) highlight AI�s role in improving accuracy, but challenges such as data sparsity, scalability, and user engagement remain. Traditional recommender systems (Zhang et al., 2020) lack social context, making book suggestions purely algorithmic rather than community-driven. Studies on library services (Johnson, 2024; Rasmussen &amp; Jochumsen, 2023) stress the need for digital platforms that promote social book-sharing ecosystems. However, no existing system combines AI-powered recommendations with social networking, missing opportunities to leverage user connections, borrowing behavior, and peer influence for improved recommendations.\n\nThis research bridges the gap by integrating AI-based recommendations with social networking features, allowing users to borrow, lend, and gift books within a trusted network. The proposed hybrid recommendation system goes beyond content-based and collaborative filtering, incorporating social borrowing trends, peer interactions, and reading habits to enhance accuracy and engagement.\nResearch Objective and Method\n\nTo address research gaps, this system will:\nCombine recommendation models with borrowing networks for book discovery.\nEnhance engagement via social-driven book exchanges and recommendations.\nLeverage user feedback and borrowing data to refine recommendations.\n\nSystem effectiveness will be measured through user engagement, F1-score for accuracy, and usability studies, ensuring personalized, community-driven recommendations.\n\nResearch Questions\nHow does integrating AI-driven recommendations with social book sharing impact engagement and reading habits?\nWhat role does user-generated data (borrow history, ratings, reviews) play in improving recommendation accuracy?\nHow can a social-based recommendation model address the limitations of traditional AI recommendation systems?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research Component (950 characters)\nThis study develops a social-driven AI book recommendation system using data-driven methods.  Feature extraction includes book metadata, borrowing history, and social interactions. A hybrid recommendation algorithm combining collaborative filtering, content-based filtering, and social network analysis will be implemented. The system will be evaluated F1-score for accuracy, and usability studies, ensuring effective and personalized recommendations.\n\n(b) Development Component (950 characters)\nThe mobile application will feature a user-friendly interface for book scanning, lending, and recommendations. A cloud-based backend will support real-time book tracking, AI processing, and data management. A hybrid AI recommendation system will integrate social network refinements for improved accuracy. Usability testing, A/B testing, and iterative optimization will be conducted to enhance user experience and recommendation precision.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Smartphone Systems and Applications",
      "Natural Language Processing/ Text Mining",
      "Software and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0317",
    "title": "Privacy-Preserving On-Device Chat Analysis Plugin for Telegram Using LLMs",
    "summary": "Recent advancements in privacy-preserving NLP have enabled real-time text analysis while ensuring user data security. Cloud-based NLP systems pose privacy risks, necessitating on-device processing as a safer alternative. Jedrzejewski (2022) outlined the challenges of privacy-focused NLP, while Ullah et al. (2023) examined security risks in LLM-powered chat tools. Jedrzejewski et al. (2024) further highlighted adversarial machine learning vulnerabilities, emphasizing the need for secure real-time chat models.\n\nTelegram�s open API allows the creation of local chat analysis tools, ensuring user control over data. Unlike cloud NLP, which transmits data externally, this research proposes an on-device Telegram chat analysis plugin that processes chats entirely on local devices, prioritizing privacy-first AI processing. This study bridges the gap by developing an on-device Telegram chat analysis plugin powered by local LLMs, ensuring no data is stored or uploaded externally.\n\nResearch Objective and Method\nThis study aims to develop and evaluate an AI-driven Telegram plugin that analyzes chat behavior, sentiment, and engagement patterns while ensuring complete data privacy through on-device processing. Unlike cloud-based AI, this plugin operates entirely on the user's local device, integrating directly with Telegram�s API for real-time chat insights. \n\nLeverage Telegram�s API to access real-time messages\nDeploy a lightweight LLM optimized for on-device execution.\nEnsure zero data storage or transmission, complying with GDPR &amp; CCPA regulations.\nAnalyze chat sentiment, engagement trends, and AI-suggested responses in real time.\n\nResearch Questions\nHow does on-device LLM chat analysis for Telegram compare to cloud-based NLP in terms of privacy and accuracy?\nWhat are the performance trade-offs when running real-time chat analysis locally using LLMs?\nHow can privacy-preserving AI models enhance user trust and adoption of AI-driven chat analysis tools?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLLM Selection: Choose a lightweight NLP model optimized for local execution.\nTelegram API Integration: Enable real-time chat access with user permission.\nSentiment &amp; Engagement Analysis: Implement on-device AI for message insights.\nPrivacy &amp; Security Verification: Conduct audits to ensure no data storage or external transmission.\nPerformance Testing: Evaluate model accuracy, latency, and memory usage on mobile/desktop devices.\n\n(b) Development component\nPlugin Development: Create a Telegram plugin that integrates seamlessly with user chats.\nLLM Optimization: Optimize memory-efficient AI models for real-time chat analysis.\nUser Interface Design: Develop an interactive dashboard for message insights.\nPrivacy &amp; Security Implementation: Ensure all processing occurs on-device, with no external API calls.\nTesting &amp; Deployment: Conduct beta testing, refine model efficiency, and release a secure Telegram plugin.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Natural Language Processing/ Text Mining",
      "Artificial Intelligence",
      "Information Retrieval/ Processing",
      "Smartphone Systems and Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0318",
    "title": "Nearbyou: A Crowdsourced Mobile Application for Identifying Urban Quiet Spaces",
    "summary": "Urban noise pollution significantly affects public health and well-being, highlighting the need to identify and preserve quiet urban spaces. Radicchi (2017) introduced the Hush City app, a mobile tool for crowdsourcing and assessing \"everyday quiet areas,\" demonstrating how user-generated sound data can support urban planning.\n\nSimilarly, Sweeney (2013) examined the Stereopublic app, which enables users to geo-tag peaceful locations, upload images, and record ambient soundscapes, emphasizing community-driven urban tranquility mapping (Sweeney, 2013). Trend Hunter (2013) reinforced the effectiveness of crowdsourced applications, showing how real-time user input enhances data accuracy and relevance (Trend Hunter, 2013).\n\nRadicchi explored mobile-based urban sound analysis, emphasizing the impact of community participation in noise mapping on urban planning decisions (Radicchi, 2017). The Hush City Mobile Lab (2017) demonstrated how crowdsourced environmental data could drive sustainable urban soundscape management, supporting the role of mobile applications in environmental well-being (Hush City Mobile Lab, 2017).\n\nThese studies highlight the potential of community-driven data collection for urban quiet space mapping, forming the basis for Nearbyou, a mobile app designed to enhance user engagement, data accuracy, and privacy in urban tranquility mapping.\n\nResearch Objective and Method:\nIntegrate AI-based noise analysis with crowdsourced geo-tagging.\nEnhance engagement by incorporating user feedback, ratings, and visualization tools.\nEnsure privacy and data security while validating real-time user contributions.\n\nResearch Questions:\n    How effective is crowdsourcing in identifying and mapping urban quiet spaces through mobile applications?\n    What motivates users to participate in crowdsourced data collection for urban tranquility mapping?\n    How can the accuracy and reliability of user-generated data in identifying quiet urban areas be ensured?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearch Methods (500 Characters):\nLiterature Review: Examine previous research on noise pollution and crowdsourced mapping.\nUser-Centered Design: Develop the Nearbyou app prototype based on real-world user feedback.\nPrototype Development: Integrate AI-driven noise mapping with community-based tagging.\nField Testing: Conduct pilot tests to validate data collection and accuracy.\nData Analysis: Assess crowdsourced data reliability and urban tranquility mapping efficiency.\n\n(b) Development component\nBackend Development: Create a coordinating server for user data and crowdsourced queries.\nFrontend Development: Design the Nearbyou app with geo-tagging, media uploads, and real-time updates.\nAI Integration: Implement AI-driven noise analysis to enhance crowdsourced data validation.\nPrivacy &amp; Security: Ensure end-to-end encryption for user privacy protection.\nTesting &amp; Deployment: Conduct beta testing, refine UX/UI, and deploy a scalable version.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Mobile Applications",
      "Human Computer Interaction",
      "Smartphone Systems and Applications",
      "Software and Applications",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0319",
    "title": "Development of an AI-Enhanced PowerPoint Plugin for Real-Time Speech-to-Text Slide Notes with Grammatical Correction",
    "summary": "Recent advancements in speech-to-text (STT) technology and AI-driven grammar correction have significantly improved writing quality, accessibility, and efficiency. Matre &amp; Cameron (2024) conducted a scoping review highlighting that STT enhances writing skills for adolescents with learning difficulties, improving text accuracy and reading comprehension. \n\nSimilarly, AI-powered grammar correction tools have been shown to improve writing fluency and reduce structural errors. Lalira et al. (2024) examined AI-based grammar tools and found that they significantly enhanced students� grammatical accuracy and writing proficiency. Farhan (2025) further explored AI-powered writing tools, showing that automated grammar correction fosters autonomous learning and error reduction, particularly for non-native speakers.\n\nBeyond grammar correction, G�ltekin (2023) investigated the impact of AI-assisted writing on the structure and coherence of written content, demonstrating that AI-supported tools can refine organization and clarity. El Kheir &amp; Ali (2023) also reviewed automatic speech recognition (ASR) technologies, highlighting their effectiveness in pronunciation assessment and speech-to-text processing. However, there remains a gap in integrating STT with AI grammar correction within presentation software like PowerPoint, which could streamline note-taking and improve accessibility for presenters. The study builds upon findings from Matre &amp; Cameron (2024) and Lalira et al. (2024), addressing the gap in STT-driven presentation content generation.\n\nResearch Questions:\n    How does integrating real-time speech-to-text transcription with AI-based grammar correction in PowerPoint improve note-taking efficiency?\n    What is the accuracy of the proposed plugin in transcribing speech and correcting grammatical errors compared to existing methods?\n    How does the use of this plugin impact user satisfaction and productivity during the preparation and delivery of presentations?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe research follows a design-implementation-evaluation cycle. The initial phase involves analyzing existing STT and AI grammar correction technologies, building on findings from Matre &amp; Cameron (2024) and Lalira et al. (2024) regarding STT accuracy and AI-driven writing enhancements. A prototype will be developed and tested with users, focusing on speech recognition efficiency, note accuracy, and usability.\n\n(b) Development component\nThe development process follows a modular architecture approach, ensuring seamless integration with Microsoft PowerPoint's add-in framework. The design phase involves API selection for speech recognition and AI grammar correction, referencing El Kheir &amp; Ali (2023) on the effectiveness of automatic speech recognition systems. A cloud-based vs. local processing feasibility study will determine whether on-device AI processing enhances speed and privacy.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Information Retrieval/ Processing",
      "Video/Audio/Speech Processing",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0320",
    "title": "EmoLearn: An AI-Powered Mobile Application for Enhancing Emotional Literacy and Social Skills in Children Using Context-Aware NLP and Real-Time Emotional Feedback",
    "summary": "Recent advancements in Artificial Intelligence (AI) and Natural Language Processing (NLP) have shown considerable promise in improving emotional literacy among children. ChaCha, a chatbot introduced by Church &amp; de Oliveira (2022), leverages AI-driven conversations to encourage children to share personal experiences, enhancing their emotional awareness. This approach fosters a safe space for self-expression and reflection, aiming to boost emotional intelligence through interactive dialogue. Further studies, such as Chen et al. (2023), suggest that AI applications, specifically chatbots, can support emotional development by promoting self-reflection and facilitating open conversations about feelings.\n\nLalira et al. (2024) emphasized the role of conversational AI in improving social skills by simulating real-life interactions children can relate to. Similarly, Matre et al. (2024) demonstrated that emotionally intelligent feedback embedded in daily interactions significantly enhances children�s emotional literacy. However, a  key gap remains in creating applications that not only support emotional literacy but also enhance social skills through real-time emotional feedback and context-aware NLP.\n\nThis research aims to bridge that gap by proposing EmoLearn, an innovative mobile application that integrates emotion recognition, real-time feedback, and contextual NLP to help children develop both emotional literacy and social interaction skills in real time.\n\n    How does integrating real-time emotion recognition and context-aware NLP improve children�s ability to identify, understand, and manage their emotions in social interactions?\n    What impact does dynamic emotional feedback have on children�s development of social skills, such as empathy, turn-taking, and emotional expression?\n    How does the use of EmoLearn influence children's willingness to engage in meaningful conversations about their emotions and personal experiences?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n First, the development phase will design EmoLearn, integrating emotion recognition and context-aware NLP, building on Chen et al. (2023)�s use of AI for emotional intelligence. User testing will involve longitudinal studies to assess its effectiveness in fostering emotional literacy and social skills, inspired by findings from Matre et al. (2024) on AI tools enhancing emotional growth. \n\n(b) Development component\nIdentify the key emotional learning outcomes and AI technology integration requirements.\nDevelop the EmoLearn architecture, focusing on emotion recognition models and contextual conversation design.\nIntegrate emotion-detection APIs and NLP models to create personalized feedback mechanisms.\nPerform usability testing and pilot studies to evaluate emotional growth and interaction improvement.\nLaunch EmoLearn for broader testing, collect real-time feedback, and refine based on user interactions.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Natural Language Processing/ Text Mining",
      "Artificial Intelligence",
      "Information Retrieval/ Processing",
      "Smartphone Systems and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0321",
    "title": "Advancing Dynamic AI-Powered Prototyping: Real-Time Adaptation of User Interfaces for Personalized Experiences",
    "summary": "Recent advancements in AI-powered prototyping have focused on improving user interface (UI) design through machine learning and real-time user data. Li et al. (2023) emphasized the importance of context-aware AI models that adapt UIs dynamically based on user preferences and interactions. Similarly, Wang et al. (2022) highlighted how real-time adaptation can significantly enhance user experience by continuously adjusting the interface according to user behavior. Chen et al. (2023) discussed integrating real-time feedback to make designs more personalized and responsive to user needs. However, these studies often overlook continuous real-time adjustments to UI during the design process, failing to address how AI models can refine and adapt interfaces on-the-fly while maintaining usability and personalization. This gap is particularly critical for applications requiring adaptive and intuitive UI systems that cater to individual user needs during the prototyping phase.\n\nThis study aims to develop an adaptive prototyping framework that integrates context-aware machine learning models for dynamic real-time updates to user interfaces based on user interaction data. The framework will allow continuous UI refinement during the prototyping phase, providing personalized user experiences. This approach builds on the work of Li et al. (2023) and Wang et al. (2022), filling the gap of real-time, data-driven interface adaptation and responsiveness.\n\nResearch Questions:\n    How can real-time user interaction data be integrated into AI-driven prototyping systems to continuously refine and personalize user interfaces during the design process?\n    What are the impacts of context-aware machine learning models on the adaptability and usability of AI-powered user interfaces?\n    How does the incorporation of continuous user feedback influence the effectiveness of AI-driven UI prototyping frameworks in real-time adjustments?\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis study will assess the effectiveness of the adaptive AI-powered prototyping framework by integrating context-aware machine learning models for real-time UI adjustments based on user interaction data. The development phase will focus on implementing AI models for dynamic refinements of interfaces. User testing will evaluate interface adaptability, usability, and personalization through longitudinal studies. \n\n(b) Development component\nThe development process will focus on building an adaptive prototyping tool that integrates real-time user data with AI-driven context-aware models. Machine learning algorithms will allow dynamic updates to the UI based on user behavior. Usability testing will evaluate interface responsiveness and user engagement. The system will undergo iterative refinements based on user feedback and performance metrics, ensuring optimal personalization and efficiency in the design process.",
    "supervisor": "Dr Owen Noel Newton Fernando",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Human Computer Interaction",
      "Image Analysis &amp; Processing",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0322",
    "title": "Interactive violin performance analysis and  visualisation",
    "summary": "This project has a prerequisite: the student MUST BE ABLE to    play violin or viola or cello (at least grade 4 of ABRSM or equivalent).\n   The project aims at automatic detection of common errors when learning how to play the violin:\n1. Intonation error recognition\n2. Good sound/bad sound identification and analysis, i.e., scratchy, floaty, whistling, harsh, etc.\n3. Steady rhythm recognition and analysis\n   This will be a continuation of the previous FYP in which a feasibility study was conducted on making  an interactive music feedback system which is able to analyse violin performances and provide a visual feedback about them. This project was leveraging on an Audio Spectrogram Transformer (AST) model pre-trained on ImageNet and fine-tuned on a dataset of publicly available 1,400 annotated violin audio samples. The developed system tried  to identify performance issues such as poor pitch and improper bowing techniques. The project received encouraging preliminary results which demonstrated the model's effectiveness in detecting errors and offering correction.  It requires further work which will be conducted by the student,\n\nSpecific details:\n(a) Design component\n\n\n\n(b) Implementation component\n\n(a) Research component\n\nTo research on the way how deep learning techniques can be used for detecting poor violin playing.\n\n(b) Development component\nTo develop an interactive software tool displaying in various forms the violin playing errors.",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0323",
    "title": "One-stop knowledge center for course modules (Frontend)",
    "summary": "Frontend implementation of a one-stop information center for various course modules.  Key features\n- Discussion Forum (Posting, votes, validation, categorization, search, filters).\n- Course assignment creation\n- Knowledge base (Posting, votes, validation, categorization, search, filters).  Materials includes Tech Notes, Slides/Photos/Visual, Video, Test/App code binaries (no source code).\n- Design of Assessment Rubrics and implementation based on votes, validation, # of postings etc.\n- Data Analysis based on forum postings (details TBD).\n- Other feature extension\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0324",
    "title": "6-DOF Robotic ARM based system #1",
    "summary": "Explore and propose uses cases with a system consisting of a 6-DOF robotic ARM, camera, microphone, speakers and/or IMU sensors.\n\nReference: http://www.yahboom.net/study/Dofbot-Pi\n\nControlling of the robotic ARM is via RPI. \nIMU sensors are available on sensor board with BLE connection to RPI.\nCamera mounted on robotic ARM allows image recognition to be done.\nMicrophone and speakers enable user interactions.\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Sensor Networks",
      "Web-based Applications",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0325",
    "title": "Virtual Teaching Assistant #1",
    "summary": "Full stack implementation with following features\n- Generative AI based utility (chatbot, forum moderator etc)  to handle course related queries\n- Customised model to course lab and lecture content\n- Student queries monitoring to identify key problem areas to focus on\n- Feedback system to enable continuous improvement\n- Enable self-directed learning among students and promote critical thinking.\n- Other features extension, e.g. integration to Knowledge Based System\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Cloud Computing",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0326",
    "title": "Hardware/Software Test and Validation System",
    "summary": "A system to facilitate system debugging. \n\nThe system provide golden hardware for validating user software and provide proven software for verifying user hardware.\n- Design standard methodologies to test hardware and software\n- Develop system to manage test code. For software validation, this includes deployment of user code to respective golden hardware and provide validation feedback. For hardware verification, this includes storage of proven test codes, downloading of test codes to user hardware and provide validation feedback.\n- Local/remote access to test system.\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Microprocessor-based Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0327",
    "title": "One-stop knowledge center for course modules (backend)",
    "summary": "Backend implementation of a one-stop information center for various course modules.  Key features\n- Discussion Forum (Posting, votes, validation, categorization, search, filters).\n- Course assignment creation\n- Knowledge base (Posting, votes, validation, categorization, search, filters).  Materials includes Tech Notes, Slides/Photos/Visual, Video, Test/App code binaries (no source code).\n- Design of Assessment Rubrics and implementation based on votes, validation, # of postings etc.\n- Data Analysis based on forum postings (details TBD).\n- Other feature extension\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0328",
    "title": "6-DOF Robotic ARM based system #2",
    "summary": "Explore and propose uses cases with a system consisting of a 6-DOF robotic ARM, camera, microphone, speakers and/or IMU sensors.\n\nReference: http://www.yahboom.net/study/Dofbot-Pi\n\nControlling of the robotic ARM is via RPI. \nIMU sensors are available on sensor board with BLE connection to RPI.\nCamera mounted on robotic ARM allows image recognition to be done.\nMicrophone and speakers enable user interactions.\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Sensor Networks",
      "Web-based Applications",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0329",
    "title": "Virtual Teaching Assistant #2",
    "summary": "Full stack implementation with following features\n- Generative AI based utility (chatbot, forum moderator etc)  to handle course related queries\n- Customised model to course lab and lecture content\n- Student queries monitoring to identify key problem areas to focus on\n- Feedback system to enable continuous improvement\n- Enable self-directed learning among students and promote critical thinking.\n- Other features extension, e.g. integration to Knowledge Based System\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Cloud Computing",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0330",
    "title": "Using sound feedback during 3D interaction",
    "summary": "In this project, sound feedback has to be added to 3D interaction with complex geometric objects. The sound has to replace haptic (touch) feedback when exploring the object's surface and inner parts. Interaction with the objects will be performed using the Leap Motion hand tracking device (https://www.ultraleap.com) in UNITY 3D system (https://unity.com).\n   The students must first learn the basics of sound and its generation by computer.\n    Then, interactive sound following motions of a hand being tracked by the Leap Motion device will be generated and studied.\n    Finally, the sound model has to de developed to be used when virtual hands interact with 3D objects. \n\nSpecific details:\n(a) Design component\n\nTo design the sound model\n\n(b) Implementation component\n\nTo implement 3D interaction using sound feedback\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0331",
    "title": "Workflow for processing video clips from camera deployed in forest",
    "summary": "This project involves the student building a workflow for processing video image to detect and classify animals.  Due o the large number of camera deployed a more efficient workflow is required to be build. \n\nSpecific details:\n(a) Design component\nUnderstand the problem and testing out different workflow platform as well as various ML tools. \n\n(b) Implementation component\nTo deploy the workflow and also get feedback form industry partner \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lee Bu Sung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0332",
    "title": "Analysis of network traffic within a HPC cluster running AI application",
    "summary": "AI application required communication between nodes in a cluster. This project is to look at and investigate the traffic pattern across nodes when running an AI application. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Lee Bu Sung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Networks",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0333",
    "title": "Reflexive Conversational Feedback Chatbot System using Multi-Agent",
    "summary": "This project requires the student to design, and develop a Chatbot or QnA Agent specifically intended for courses with a large number of participants, exceeding 500. The Chatbot should be equipped with a set of pre-defined FAQs and be able to provide general information to learners about course administration, assessment components, learning mechanisms, timetabling, venue, and other relevant topics. \n\nIn addition, the chatbot will be fed with desire feedback form e.g. end course survey, and then the form will be broken into parts. These parts or related questions will be prompted to the user at a suitable time or along with a relevant topic of discussion/conversation. \n\nThe user feedback will be recorded in the database and this partial feedback can be later re-consolidated into the full responses for one or more feedbacks depending on the mapping of purpose for multiple feedback forms. This will help the user to take part in the survey and feedback seamlessly (less burdening) and allow the departments or educators to achieve a higher response rate.\n\nThe student taking up this project should possess a good understanding and skillset to work with LangChain, Multi-Agent RAG, and various Microsoft Azure cloud services.\n\nSpecific details:\n(a) Design component\nSystem Design\nUser Interaction Design\n\n(b) Implementation component\nSystem Implementation\nAPI integration\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "e-Learning",
      "Natural Language Processing/ Text Mining",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0334",
    "title": "A Study on Cross Domain Adaptation on Long Tail Distribution Data using GAI",
    "summary": "Domain adaption in deep neural networks is a technique that utilizes knowledge gained from one task or domain to enhance performance on a related but different task or domain. The fundamental concept behind this approach is to leverage the knowledge acquired in a source domain and apply it to a target domain, ensuring maximum confusion between the source and target distributions (i.e., domain confusion).\n\nIn this project, student will conduct a comprehensive study, research, and analysis on recent domain adaptation techniques, it's application, strengths, and weaknesses. The student will conduct a series of experiments on selected dataset with long tail distribution (seen and unseen data),  produce a baseline/benchmark, and summarize the findings.\n\nStudent taking up this project should possess good knowledge and skillset in PyTorch.\n\nRelated reading:\nFarahani, A., Voghoei, S., Rasheed, K. and Arabnia, H.R., 2021. A brief review of domain adaptation. Advances in Data Science and Information Engineering: Proceedings from ICDATA 2020 and IKE 2020, pp.877-894.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nComprehensive literature review on domain adaptation\nCompare and contrast various domain adaptation techniques\n\n(b) Development component\nExperiment with a few selected domain adaptation techniques with publicly available datasets.",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Computer Graphics",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0335",
    "title": "Background Removal for Leaves & Herbarium Images",
    "summary": "In this project, the students are required to explore, analyze, design, and, develop a machine-learning model to remove noise and background of leaves and herbarium images. \n\nStudent taking up this project will explore and study the current state-of-the-art techniques for plant image detection and segmentation, adopt and evaluate, and refine or redesign a better model for the background removal / masking task. \n\nSome Preliminary Reading Materials:\n\t� White, Alexander E., et al. \"Generating segmentation masks of herbarium specimens and a data set for training segmentation models using deep learning.\" Applications in Plant Sciences 8.6 (2020): e11352.\n\t� Triki, Abdelaziz, et al. \"Deep learning based approach for digitized herbarium specimen segmentation.\" Multimedia Tools and Applications 81.20 (2022): 28689-28707.\n\t� Triki, Abdelaziz, et al. \"Deep leaf: Mask R-CNN based leaf detection and segmentation from digitized herbarium specimen images.\" Pattern Recognition Letters 150 (2021): 76-83.\nHussein, Burhan Rashid, et al. \"Automated extraction of phenotypic leaf traits of individual intact herbarium leaves from herbarium specimen images using deep learning based semantic segmentation.\" Sensors 21.13 (2021): 4549.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nComprehensive literature review\n\n(b) Development component\nExperiment with a few selected techniques with publicly available datasets.",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Computer Graphics",
      "Artificial Intelligence",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0336",
    "title": "Micro-Credentials Profiling & Leaderboard to Promote Classroom Participation (2nd Gen)",
    "summary": "In this project, the student is expected to analyze and enhance a web-based system allowing educators to set up a series of tasks and record student achievements with digital credentials and badges. \n\nThe 1st Gen version of application can be accessed via:\n- https://github.com/xeroxis-xs/EduQuest-Frontend-ReactJS\n- https://github.com/xeroxis-xs/EduQuest-Backend-Django\n- https://dr.ntu.edu.sg/handle/10356/181198\n- https://www.ntu.edu.sg/docs/librariesprovider118/technovationposter/dec2024/teoh-xi-sheng_promoting-classroom-participation.pdf?sfvrsn=899a1676_1\n- https://youtu.be/CQ_pmSOU2Mk\n\nIn addition to the main features specified above, students may propose additional or complementary features that are deemed useful for the end users.\n\nStudent taking up this project should possess good knowledge and skills in system development, and database design, and be familiar with cloud platforms i.e. Microsoft Azure. The system will ingest exported data from \"class and audience engagement tools\" such as Wooclap. The student taking this project must ensure the system can be installed and deployed easily by the web administrator and produce documentation for the system installation process.\n\nSpecific details:\n(a) Design component\nDesign component\nSystem Design\nUser Interaction Design\n\n(b) Implementation component\nImplementation component\nSystem Implementation\nAPI integration\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications",
      "e-Learning",
      "Gamification",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0337",
    "title": "Chatbot Deployment and Management Tools",
    "summary": "This project requires the student to develop an automated and secure deployment tool for LLM-powered chatbot on Microsoft Azure cloud platform. The tool should be intuitive with effective UI, allowing the administrator to deploy and manage the developed chatbot at scale. The tool should also provision required services for individual chatbot and connect the service to the app.\n\nThe student taking up this project should have a good understanding on Cloud Computing platforms such as Microsoft Azure cloud services and Azure Resource Manager.\n\n\nRelated Projects:\n - https://dr.ntu.edu.sg/handle/10356/181189\n\nResources:\n- https://learn.microsoft.com/en-us/training/courses/az-900t00\n- http://learn.microsoft.com/en-us/azure/azure-resource-manager/\n- https://learn.microsoft.com/en-us/training/courses/az-104t00\n\nSpecific details:\n(a) Design component\nPrototype design\n\n(b) Implementation component\nPrototype development\nPrototype deployment and evaluation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Cloud Computing",
      "System Security",
      "Human Computer Interaction",
      "Multimedia Systems",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0338",
    "title": "LLM-based NTU Course Recommendation Systems (4th Gen)",
    "summary": "In this project, the student is expected to explore and analyze the opportunity to develop a web-based system that allows students to explore the study pathway following the course plan distributed by the school. The system should be able to provide some recommended pathways based on the desired career prospected by matching the specialization for elective selection when given a collection of unstructured documents. \n\nIn addition to the main features specified above, students may propose additional or complementary features that are deemed useful for the end users.\n\n1st Gen: https://www.ntu.edu.sg/docs/librariesprovider118/technovationposter/dec2024/sohshinghao_nturoadmaps.pdf?sfvrsn=ba68039e_1 | https://youtu.be/vXACRHFwycc\n2nd Gen: Completing\n3rd Gen: On-going\n\nStudents taking up this project should possess good knowledge and skills in system development, and database design, and be familiar with LLM Frameworks i.e. LangChain as well as cloud platforms i.e. Microsoft Azure.  \n\nSpecific details:\n(a) Design component\nDesign component\nSystem Design\nUser Interaction Design\n\n(b) Implementation component\nImplementation component\nSystem Implementation\nAPI integration\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications",
      "Multimedia Systems",
      "Human Computer Interaction",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0339",
    "title": "Evaluation of The Confluence: An Open Innovation Ecosystem for Scalable and Evolutionary Educational Mobile Chatbot",
    "summary": "This project requires the student to evaluate an existing Open Innovation Ecosystem for Mobile Chatbot, The Confluence.\nThe existing system consists of a web-based application developed using ReactJS running on NodeJS as well as a mobile app developed with ReactNative. The mobile app runs on Expo Go for sandboxing and testing purposes.\n\nStudents taking up this project should have some familiarity on LLM-powered chatbot development and the required framework i.e. LangChain. Students will be exposed to Azure Cloud Platform services i.e. Azure Function, Azure Active Directory, etc.\n\nThe student will identify, recruit, and conduct a few user evaluations and surveys to gauge insightful findings for research and for prototype improvement.\n\nThis project spans across both Research and Development, The outcome of the project includes:\n1) Enhanced Prototyped\n2) Digital Handbook/Documentation  for the prototype\n3) Publishable findings/user survey data\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nSystematic User Survey\n\n(b) Development component\nEnhanced Software and Mobile App Design\nEnhanced Software and Mobile App Development &amp; Deployment",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Mobile Applications",
      "Smartphone Systems and Applications",
      "Human Computer Interaction",
      "Web-based Applications",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0340",
    "title": "RAGLens: A Study on Understanding, Evaluating, and Comparing Retrieval-Augmented Generation Techniques (2nd Gen)",
    "summary": "In this project, students are expected to conduct a comprehensive review, analysis, experiments, and evaluation of various Retrieval-Augmented Generation techniques for text-based chatbots. Student taking up this project \n\nStudents taking up this project should have some familiarity with LLM-powered chatbot development and the required framework i.e. LangChain and related vector store / Knowledge Graph. Students will be exposed to Azure Cloud Platform services i.e. Azure AI Search, etc.\n\nThe student will identify, recruit, and conduct a few user evaluations and surveys to gauge insightful findings for research and prototype improvement.\n\n\nThis project spans across both Research and Development,\nThe outcome of the project includes:\n1) Enhanced Prototyped\n2) Digital Handbook/Documentation  for the prototype\n3) Publishable findings/user survey data\n\n1st Gen: Completing\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nReview and findings consolidation\n\n(b) Development component\nPrototype development for experiements",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Natural Language Processing/ Text Mining",
      "Theory &amp; Algorithms",
      "Machine Learning",
      "Information Retrieval/ Processing",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0341",
    "title": "Reinforcement Learning for LLM-powered Educational Chatbot (3rd Gen)",
    "summary": "This project requires the student to analyze and enhance an on-going project, a LLM-powered Chatbot for Educational Q&amp;A. The chatbot should have the capability to consult the instructor for non-trivial queries that cannot be answered, and take the feedback from the instructor to update the knowledge base. Other useful or relevant features can be integrated into the enhanced chatbot and tested if deemed appropriate.  \n\nThe student will also need to develop a simple and deployable API simulating the chatbot engine working on the backend. Students taking up this project should possess a good understanding and skillset and have an interest in working with LangChain, Multi-Agent RAG, and also Microsoft Azure cloud services.\n\nSpecific details:\n(a) Design component\nPrototype design\n\n(b) Implementation component\nPrototype development\nAPI Development\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Software and Applications",
      "Program Analysis and Optimization",
      "Information Retrieval/ Processing",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0342",
    "title": "Security on GenAI/LLM-powered Chatbot",
    "summary": "In this project, students are expected to conduct a comprehensive review of recent exploitations and incidents that occurred specifically on chatbots powered by the Large Language Model (LLM) and to systematically consolidate their findings by looking for attack patterns, intents, or motivation, remediations, and other aspect or vulnerabilities along with the review.\n\nThe outcome of the project includes:\n1) Handbook for Secure Chatbot Development\n2) Relevant Python Packages (if any)\n3) Publishable findings / user survey data\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Incident Review, finding consolidation\n- CVEs &amp; CWEs\n\n(b) Development component\n- Experiments\n- Prototype development simulating potential attacks\n- Digital Handbook",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "System Security",
      "Cyber Security",
      "Data Security",
      "Natural Language Processing/ Text Mining",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0343",
    "title": "Faculty-TA Collaborative Tool (3rd Gen)",
    "summary": "In this project, students taking this project are expected to evaluate previously developed applications and compare them with publicly available tools. \n\n1st Gen: https://dr.ntu.edu.sg/handle/10356/175077\n2nd Gen: pending completion\n\nThe student will then propose recommendations for improvement and develop an enhanced web-based system that enables and simplifies the Faculty &amp; Teaching Assistant (TA) for course management, communication, and incident reporting and response. \n\nThe system covers the following main features:\n\t- Allowing Faculty members to assign/delegate tasks to TA as tickets with thread.\n\t- TA could report incidents or issues for the session under their care for Faculty attention with thread.\n\t- Email will be sent to users involved when there is an update for a task or incident.\n\t- Task and incident monitoring and tracking\n\t- The system uses OAuth for user account registration and user authentication. \n\t- Data visualization and dashboard\n\t- Additional relevant features which make the improve the system's usability, efficiency, and security \n\nStudent taking up this project should possess good knowledge and skills in full-stack development, and database design, and be familiar with cloud platforms i.e. Microsoft Azure\n\nSpecific details:\n(a) Design component\nDatabase design\nSystem Design\n\n(b) Implementation component\nSystem implementation and deployment\nData analysis and visualization\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications",
      "Data Analytics",
      "Human Computer Interaction",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0344",
    "title": "Gesture-Based Virtual Instrument Using Hand Tracking with Leap Motion device",
    "summary": "This project will utilize Leap Motion (Ultraleap) hand tracking to create a touchless, gesture-controlled music system. The users of this system will play virtual instruments like a piano, drums, or synthesizer by moving their hands in the air. This system should provide a fun and interactive way to create music without physical instruments, making it ideal for music education, performance, and accessibility for people with disabilities.\nObjectives:\n1. To develop a virtual instrument system controlled by Leap Motion.\n2. To map hand movements and gestures to musical notes and beats.\n3. To enable different play modes for various instruments (e.g., piano, drums, guitar).\n4. To integrate real-time audio feedback for an immersive experience\n5. To support customization (e.g., change instruments, scales, or effects).\nSoftware: Unity/Unreal Engine (for visualization), Max/MSP (https://cycling74.com/products/max ) or MIDI-compatible DAWs (for sound synthesis), C#/Python\n\nThe student is expected to be able to play some musical instrument and be familiar with the theory of music (scales, chord progression, etc.)\n\nSpecific details:\n(a) Design component\n\nTo design the hand tracking system\n\n(b) Implementation component\n\nTo implement the system on a personal computer/notebook.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Multimedia Systems",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0345",
    "title": "Comparing Cardinality Constraint Encodings in SAT Solving and Counting",
    "summary": "This project proposes a comparative study of different cardinality constraint encodings for Boolean satisfiability (SAT) solving and model counting. Cardinality constraints, which specify the number of literals in a set which must be true, are fundamental in various applications, including combinatorial optimization, planning, and knowledge representation. The goal of the project is to compare several different encoding techniques across various dimensions, such as succinctness, propagation properties, and overall performance in practice.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Timothy van Bremen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Theory &amp; Algorithms",
      "Discrete Math"
    ]
  },
  {
    "projectNo": "CCDS25-0346",
    "title": "Entity Resolution Using Markov Logic",
    "summary": "Entity matching, the task of identifying records that refer to the same real-world entity across different data sources, is an important step in data integration and cleaning. This project proposes investigating the application of Markov Logic Networks (MLNs) to entity matching. MLNs are a powerful class of machine learning models that combine first-order logic with probabilistic graphical models. They offer an interpretable approach to representing relationships between entities.\n\nSome past work has been done on this topic (�Entity Resolution with Markov Logic�, Singla and Domingos, ICDM 2006), which we will use as a starting point for the project.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Timothy van Bremen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning",
      "Data Mining",
      "Knowledge Representation/ Ontology",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0347",
    "title": "Control Mechanisms for Large Language Models",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, but their behaviour can be unpredictable and difficult to control. This project aims to investigate the application of control mechanisms to guide and constrain LLM outputs: for example, a control mechanism could impose the constraint that the LLM output contains a certain word, or that two particular words must appear in a certain relative order. This project would aim to conduct a comparative study on various approaches in the literature for controlling LLMs, and study their application to realistic use cases.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Timothy van Bremen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Natural Language Processing/ Text Mining",
      "Machine Learning",
      "Logic and Formal Methods"
    ]
  },
  {
    "projectNo": "CCDS25-0348",
    "title": "Generative AI (GPT) + Quant Finance for Wealth Management",
    "summary": "Wealth management is the process of maximizing financial returns for one's financial assets.   Traditionally, investment analysts and portfolio managers use\nquant finance to determine the risk of clients' investment assets and identify assets with potential growth.   This requires access to proprietary systems like Bloomberg and Morningstar.   With Generative AI (GPT), financial information is now available to all.   This FYP explores the possibility of augmenting quant finance with generative AI for wealth management.\n\nThe tasks include, but are not limited to the followings:\n1) Determine the risk of their portfolio of assets,  if users already have an investment portfolio.\n2) Create an investment portfolio, if users do not have an investment portfolio.\n3) Create financial alerts to real-time inform users of market and macroeconomic events that affect their investment portfolio.\n\nThis FYP can be an individual project, or a team-based project where each FYP student work on one or more aspects of the overall software/app/system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain",
      "Machine Learning",
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0349",
    "title": "Web3 and Blockchain Applications for Real World Problems",
    "summary": "Design an Ethereum-based blockchain decentralized app (dAPP) with a front-end on mobile device or browser.  The app should solve a real world problem where blockchain technology makes sense. This FYP is a learning opportunity for students to learn about programming smart contracts on the Ethereum blockchain and building UI clients on mobile or browser devices to interface with the blockchain.   An example of a dAPP is Blockchainix:\n\nhttps://apps.apple.com/us/app/id1518744838\nhttps://play.google.com/store/apps/details?id=com.commendo.blockchainizeasset\n\nwhich you can download onto your iOS or Android phones to try out.\n\nSpecific details:\n(a) Design component\n\nDesign smart contract to solve real world problem.\n\n(b) Implementation component\n\nImplement it as front-end client (mobile app) and back-end blockchain.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Blockchain",
      "Mobile Applications",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0350",
    "title": "Web3 and Blockchain Applications for Real World Problems",
    "summary": "Design an Ethereum-based blockchain decentralized app (dAPP) with a front-end on mobile device or browser.  The app should solve a real world problem where blockchain technology makes sense. This FYP is a learning opportunity for students to learn about programming smart contracts on the Ethereum blockchain and building UI clients on mobile or browser devices to interface with the blockchain.   An example of a dAPP is Blockchainix:\n\nhttps://apps.apple.com/us/app/id1518744838\nhttps://play.google.com/store/apps/details?id=com.commendo.blockchainizeasset\n\nwhich you can download onto your iOS or Android phones to try out.\n\nSpecific details:\n(a) Design component\n\nDesign smart contract to solve real world problem.\n\n(b) Implementation component\n\nImplement it as front-end client (mobile app) and back-end blockchain.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Blockchain",
      "Mobile Applications",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0351",
    "title": "Generative AI (GPT) + Quant Finance for Wealth Management",
    "summary": "Wealth management is the process of maximizing financial returns for one's financial assets.   Traditionally, investment analysts and portfolio managers use\nquant finance to determine the risk of clients' investment assets and identify assets with potential growth.   This requires access to proprietary systems like Bloomberg and Morningstar.   With Generative AI (GPT), financial information is now available to all.   This FYP explores the possibility of augmenting quant finance with generative AI for wealth management.\n\nThe tasks include, but are not limited to the followings:\n1) Determine the risk of their portfolio of assets,  if users already have an investment portfolio.\n2) Create an investment portfolio, if users do not have an investment portfolio.\n3) Create financial alerts to real-time inform users of market and macroeconomic events that affect their investment portfolio.\n\nThis FYP can be an individual project, or a team-based project where each FYP student work on one or more aspects of the overall software/app/system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain",
      "Machine Learning",
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0352",
    "title": "Web3 and Blockchain Applications for Real World Problems",
    "summary": "Design an Ethereum-based blockchain decentralized app (dAPP) with a front-end on mobile device or browser.  The app will solve a real world problem where blockchain technology makes sense. This FYP is a learning opportunity for students to learn about programming smart contracts on the Ethereum blockchain and building UI clients on mobile or browser devices to interface with the blockchain.   An example of a dAPP is Blockchainix:\n\nhttps://apps.apple.com/us/app/id1518744838\nhttps://play.google.com/store/apps/details?id=com.commendo.blockchainizeasset\n\nwhich you can download onto your iOS or Android phones to try out.\n\nSpecific details:\n(a) Design component\n\nDesign smart contract to solve real world problem.\n\n(b) Implementation component\n\nImplement it as front-end client (mobile app) and back-end blockchain.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Blockchain",
      "Mobile Applications",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0353",
    "title": "Web3 and Blockchain Applications for Real World Problems",
    "summary": "Design an Ethereum-based blockchain decentralized app (dAPP) with a front-end on mobile device or browser.  The app will solve a real world problem where blockchain technology makes sense. This FYP is a learning opportunity for students to learn about programming smart contracts on the Ethereum blockchain and building UI clients on mobile or browser devices to interface with the blockchain.   An example of a dAPP is Blockchainix:\n\nhttps://apps.apple.com/us/app/id1518744838\nhttps://play.google.com/store/apps/details?id=com.commendo.blockchainizeasset\n\nwhich you can download onto your iOS or Android phones to try out.\n\nSpecific details:\n(a) Design component\n\nDesign smart contract to solve real world problem.\n\n(b) Implementation component\n\nImplement it as front-end client (mobile app) and back-end blockchain.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Blockchain",
      "Mobile Applications",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0354",
    "title": "Web3 and Blockchain Applications for Real World Problems",
    "summary": "Design an Ethereum-based blockchain decentralized app (dAPP) with a front-end on mobile device or browser.  The app will solve a real world problem where blockchain technology makes sense. This FYP is a learning opportunity for students to learn about programming smart contracts on the Ethereum blockchain and building UI clients on mobile or browser devices to interface with the blockchain.   An example of a dAPP is Blockchainix:\n\nhttps://apps.apple.com/us/app/id1518744838\nhttps://play.google.com/store/apps/details?id=com.commendo.blockchainizeasset\n\nwhich you can download onto your iOS or Android phones to try out.\n\nSpecific details:\n(a) Design component\n\nDesign smart contract to solve real world problem.\n\n(b) Implementation component\n\nImplement it as front-end client (mobile app) and back-end blockchain.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Blockchain",
      "Mobile Applications",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0355",
    "title": "Web3 and Blockchain Applications for Real World Problems",
    "summary": "Design an Ethereum-based blockchain decentralized app (dAPP) with a front-end on mobile device or browser.  The app will solve a real world problem where blockchain technology makes sense. This FYP is a learning opportunity for students to learn about programming smart contracts on the Ethereum blockchain and building UI clients on mobile or browser devices to interface with the blockchain.   An example of a dAPP is Blockchainix:\n\nhttps://apps.apple.com/us/app/id1518744838\nhttps://play.google.com/store/apps/details?id=com.commendo.blockchainizeasset\n\nwhich you can download onto your iOS or Android phones to try out.\n\nSpecific details:\n(a) Design component\n\nDesign smart contract to solve real world problem.\n\n(b) Implementation component\n\nImplement it as front-end client (mobile app) and back-end blockchain.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Blockchain",
      "Mobile Applications",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0356",
    "title": "Generative AI (GPT) + Quant Finance for Wealth Management",
    "summary": "Wealth management is the process of maximizing financial returns for one's financial assets.   Traditionally, investment analysts and portfolio managers use\nquant finance to determine the risk of clients' investment assets and identify assets with potential growth.   This requires access to proprietary systems like Bloomberg and Morningstar.   With Generative AI (GPT), financial information is now available to all.   This FYP explores the possibility of augmenting quant finance with generative AI for wealth management.\n\nThe tasks include, but are not limited to the followings:\n1) Determine the risk of their portfolio of assets,  if users already have an investment portfolio.\n2) Create an investment portfolio, if users do not have an investment portfolio.\n3) Create financial alerts to real-time inform users of market and macroeconomic events that affect their investment portfolio.\n\nThis FYP can be an individual project, or a team-based project where each FYP student work on one or more aspects of the overall software/app/system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain",
      "Machine Learning",
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0357",
    "title": "Generative AI (GPT) + Quant Finance for Wealth Management",
    "summary": "Wealth management is the process of maximizing financial returns for one's financial assets.   Traditionally, investment analysts and portfolio managers use\nquant finance to determine the risk of clients' investment assets and identify assets with potential growth.   This requires access to proprietary systems like Bloomberg and Morningstar.   With Generative AI (GPT), financial information is now available to all.   This FYP explores the possibility of augmenting quant finance with generative AI for wealth management.\n\nThe tasks include, but are not limited to the followings:\n1) Determine the risk of their portfolio of assets,  if users already have an investment portfolio.\n2) Create an investment portfolio, if users do not have an investment portfolio.\n3) Create financial alerts to real-time inform users of market and macroeconomic events that affect their investment portfolio.\n\nThis FYP can be an individual project, or a team-based project where each FYP student work on one or more aspects of the overall software/app/system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain",
      "Machine Learning",
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0358",
    "title": "Generative AI (GPT) + Quant Finance for Wealth Management",
    "summary": "Wealth management is the process of maximizing financial returns for one's financial assets.   Traditionally, investment analysts and portfolio managers use\nquant finance to determine the risk of clients' investment assets and identify assets with potential growth.   This requires access to proprietary systems like Bloomberg and Morningstar.   With Generative AI (GPT), financial information is now available to all.   This FYP explores the possibility of augmenting quant finance with generative AI for wealth management.\n\nThe tasks include, but are not limited to the followings:\n1) Determine the risk of their portfolio of assets,  if users already have an investment portfolio.\n2) Create an investment portfolio, if users do not have an investment portfolio.\n3) Create financial alerts to real-time inform users of market and macroeconomic events that affect their investment portfolio.\n\nThis FYP can be an individual project, or a team-based project where each FYP student work on one or more aspects of the overall software/app/system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain",
      "Machine Learning",
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0359",
    "title": "Generative AI (GPT) + Quant Finance for Wealth Management",
    "summary": "Wealth management is the process of maximizing financial returns for one's financial assets.   Traditionally, investment analysts and portfolio managers use\nquant finance to determine the risk of clients' investment assets and identify assets with potential growth.   This requires access to proprietary systems like Bloomberg and Morningstar.   With Generative AI (GPT), financial information is now available to all.   This FYP explores the possibility of augmenting quant finance with generative AI for wealth management.\n\nThe tasks include, but are not limited to the followings:\n1) Determine the risk of their portfolio of assets,  if users already have an investment portfolio.\n2) Create an investment portfolio, if users do not have an investment portfolio.\n3) Create financial alerts to real-time inform users of market and macroeconomic events that affect their investment portfolio.\n\nThis FYP can be an individual project, or a team-based project where each FYP student work on one or more aspects of the overall software/app/system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain",
      "Machine Learning",
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0360",
    "title": "Generative AI (GPT) + Quant Finance for Wealth Management",
    "summary": "Wealth management is the process of maximizing financial returns for one's financial assets.   Traditionally, investment analysts and portfolio managers use\nquant finance to determine the risk of clients' investment assets and identify assets with potential growth.   This requires access to proprietary systems like Bloomberg and Morningstar.   With Generative AI (GPT), financial information is now available to all.   This FYP explores the possibility of augmenting quant finance with generative AI for wealth management.\n\nThe tasks include, but are not limited to the followings:\n1) Determine the risk of their portfolio of assets,  if users already have an investment portfolio.\n2) Create an investment portfolio, if users do not have an investment portfolio.\n3) Create financial alerts to real-time inform users of market and macroeconomic events that affect their investment portfolio.\n\nThis FYP can be an individual project, or a team-based project where each FYP student work on one or more aspects of the overall software/app/system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P W. K. Ng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain",
      "Machine Learning",
      "Software and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0361",
    "title": "Realtime Chatlog Annotator and Visualization Tools",
    "summary": "In this project, students taking this project are expected to evaluate previously developed applications. \n\n1st Gen: https://github.com/denzel-afk/ChatLogAnnotators\n\nThe student will then propose recommendations for improvement and develop an enhanced web-based system that enables the researcher to annotate conversations and messages with dynamic categories (Conversation Message Annotator). The application should allow the administrator to recruit/manage/assign annotators.  \n\nStudents with prior skills and knowledge of Microsoft Azure will be added advantages. \n\nStudent taking up this project should possess good knowledge and skills in full-stack development, and database design, and be familiar with cloud platforms i.e. Microsoft Azure  i.e. Python: Streamlit/reactjs, Django, PyMongo, LangChain\n(2) Cloud Deployment: Web App Deployment &amp; Management on various Microsoft Azure Services.\n\nThe final product must be usable, intuitive, and ease for deployment. Good UI design and data visualization is crucial\n\nSpecific details:\n(a) Design component\nDatabase design\nSystem Design\n\n(b) Implementation component\nSystem implementation and deployment\nData analysis and visualization\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications",
      "Data Analytics",
      "Human Computer Interaction",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0362",
    "title": "DSAI Project for Chatlog Analysis -  Effectiveness and Acceptance of Chatbot as Learning Companion in Higher Education (Educational Research)",
    "summary": "The student taking up this assignment is expected to contribute to a Research Project on Chatbot Development. Students will start with an intensive and comprehensive literature review on the effectiveness and acceptance of LLM-powered Chatbot as a Learning Companion in Higher Education.\n\nThe student will then be tasked to analyze user survey data, chatlog, and other related data which will drive the development of components/modules/functions that will be incorporated into the existing chatbot. Students with prior skills and knowledge of Microsoft Azure will be added advantages. \n\nMain tasks include (but not limited to):\nTask 1: Intensive &amp; Critical Literature Review on Educational Chatbot (Research)\nTask 2: Chatlog Evaluation &amp; Insight Generation\nTask 3: Survey Data Analysis\nTask 4: Reporting on the findings and publishable insightful recommendations\n\nSkills Requirement:\n(1) Required Skill: Programming &amp; Frameworks i.e. Python: Streamlit, PyMongo, LangChain, RAGAS, etc\n(2) DS/ML Skillset &amp; Workflow\n(3) Usage of Large Language Model i.e. Azure OpenAI GPT model, RAG Techniques, &amp; VectorStore.\n(4) Data Analytics &amp; Data Science/ML Pipeline\n(5) Independent Research\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Literature Review\n- Data analysis\n- Paper publication\n\n(b) Development component\n- Model building\n- Insight generation\n- Experiments",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Data Mining",
      "Machine Learning",
      "Information Retrieval/ Processing",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0363",
    "title": "Open Project on Applied LLM 25S1-1",
    "summary": "This is an open topic for students who wish to propose any App Development that will be powered by any Large Language Model (LLM). \n\nIdeally, the application should be deployable and Microsoft Azure will be the preferred environment for deployment\n\nSpecific details:\n(a) Design component\nSoftware Architecture and Design\n\n(b) Implementation component\nSoftware Development and Deployment\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications",
      "Multimedia Systems",
      "Human Computer Interaction",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0364",
    "title": "LLM-based Learning Companion & Co-pilot with Self Regulated Learning  (SRL)",
    "summary": "In this project, students are expected to conduct a comprehensive review, analysis, experiments, and evaluation of various GenAI Powered SRL application/techniques for Higher Education. Students taking up this project should have some familiarity with LLM-powered chatbot development and the required framework i.e. LangChain, Agentic Frameworks, and related vector store / Knowledge Graph. Students will be exposed to Azure Cloud Platform services\n\nThe student will identify, recruit, and conduct user evaluations and surveys to gauge insightful findings for research and prototype improvement.\n\n\nThis project spans across both Research and Development,\nThe outcome of the project includes:\n1) Enhanced Prototyped\n2) Digital Handbook/Documentation  for the prototype\n3) Publishable findings/user survey data\n\n1st Gen: Completing\n\n\nReading Resources:\n- https://www.sciencedirect.com/topics/social-sciences/self-regulated-learning#:~:text=Self%2Dregulated%20learning%20can%20be,%E2%80%9D%20(Pintrich%2C%202000%2C%20p\n- https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=self-regulated+learning+genai&amp;btnG=\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nSelf Regulated Learning Framework (SRL)\n\n\n(b) Development component\nSoftware Architecture and Design\nSoftware Development and Deployment",
    "supervisor": "Mr Ong Chin Ann",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Web-based Applications",
      "Software and Applications",
      "Multimedia Systems",
      "Natural Language Processing/ Text Mining",
      "e-Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0365",
    "title": "Predicting Fluid Intelligence Performance Using Task-Based functional MRI",
    "summary": "Task-based functional MRI (fMRI) is gathered when a subject is performing a cognitive task in an magnetic resonance imaging (MRI) scanner. Using task-based fMRI data to predict individual performance in fluid intelligence tests is a promising research direction, as it provides a direct capture of neural activity during cognitive processes. Fluid intelligence reflects an individual�s ability to solve novel problems. By analyzing brain activity patterns during cognitive tasks, we can gain deeper insights into the neural basis of intelligence performance.\n\nIn this project, we will develop deep learning models to establish the relationship between brain activity patterns and fluid intelligence test scores. We will explore architectures such as Convolutional Neural Networks, Transformers, and Mamba models, integrating foundation models to capture both spatial and temporal features. Students will use Python and the PyTorch library to develop algorithms, with primary tasks including preprocessing task-based fMRI data, designing and implementing deep learning models, evaluating model prediction accuracy, and analyzing the contributions of key brain regions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe student will research on techniques to predict human fluid intelligence from functional MRI\n\n(b) Development component\nThe student will develop the necessary techniques and routines in Python using Pytorch/Tensorflow framework",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Medical Informatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0366",
    "title": "Multi-Modal functional MRI Fusion for Cognitive Ability Prediction",
    "summary": "Functional MRI (fMRI) provides insights into brain activity under different conditions, including both resting-state and task-based fMRI. As a core component of human cognitive ability, fluid intelligence is associated with complex brain network interactions. This project proposes an innovative multi-modal fusion approach, utilizing both resting-state and task-based fMRI data to build a cognitive ability prediction model. These two data types offer complementary perspectives on brain function: one provides a static view of functional connectivity, while the other reveals the dynamic processes of cognitive engagement.\n\nWe will explore deep learning architectures such as CNNs, Transformers, and Mamba models, focusing on the interactions between these two modalities. Specifically, we will investigate how resting-state network properties modulate task-related neural responses and how such interactions influence cognitive performance. Students will use Python and PyTorch to develop algorithms and construct this multi-modal fusion framework for cognitive ability prediction. This research will offer new insights into the neural basis of cognitive ability and contribute to the development of more precise biomarkers for personalized cognitive assessment.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on analysis and fusion of resting-state fMRI and task-fMRI for prediction of cognitive function\n\n(b) Development component\nThe student will develop necessary techniques and routines in Python using Pytorch/Tensorflow frameworks",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0367",
    "title": "Explainable AI for functional MRI Deep Learning Model Analysis",
    "summary": "Functional MRI (fMRI) is gathered when a subject is either resting or performing a cognitive task in an magnetic resonance imaging (MRI) scanner. Despite the significant success of deep learning in fMRI data analysis, its black-box nature limits clinical applications. This project aims to develop explainable AI techniques to uncover how deep learning models utilize fMRI data to make predictions. Current research shows that deep learning models perform exceptionally well in fMRI analysis, but their decision-making process lacks transparency, which restricts clinical adoption. The main challenge lies in the complex nonlinear transformations within the models, making it difficult to directly link brain activity patterns to cognitive states. \n\nWe will leverage advanced architectures such as diffusion models, Transformers, and Mamba to explore explainability techniques for fMRI-based deep learning models. The goal is to interpret how these models analyze fMRI data and make predictions. Students will use Python and PyTorch to develop algorithms, with key tasks including implementing explainability algorithms, developing visualization tools, validating the biological plausibility of interpretations, and evaluating the effectiveness of explainability methods.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on XAI techniques identify fMRI features in predictive models. \n\n\n(b) Development component\nStudent will develop necessary techniques and routines in Python using Pytorch/Tensorflow frameworks",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0368",
    "title": "Robot car with robotic arm #1",
    "summary": "Explore and propose uses cases with a system consisting of a robot car equipped with robotic ARM, camera, microphone, speakers and/or IMU sensors. \n\nReference: https://category.yahboom.net/products/transbot-se\n\nControlling of the robotic ARM is via RPI. \nIMU sensors (if required) are available on separate sensor board with BLE/USB connection to RPI.\nCamera mounted on robot allows image recognition to be done.\nMicrophone and speakers available (if needed) for user interactions.\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Sensor Networks",
      "Web-based Applications",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0369",
    "title": "Interactive Newtonian Physics Learning Using Leap Motion and Unity 3D",
    "summary": "This project aims to create an interactive physics simulation in Unity 3D, where users can explore Newtonian mechanics using hand gestures tracked by Leap Motion. The goal is to provide an engaging, hands-on learning experience for students by allowing them to interact with virtual objects and observe real-time physics principles such as force, motion, gravity, and collisions.\n   Objectives:\n1. Integrate Leap Motion hand tracking with Unity 3D physics engine.\n2.  Create interactive simulations of Newtonian physics concepts.\n4.  Allow users to apply forces, manipulate objects, and observe physics laws in action.\n5.  Enhance learning through real-time visualization of physics equations.\n   This will require to install Leap Motion SDK, configure it with Unity 3D and simultaneously study Newtonian physics principles relevant to the project. Then the student has to implement rigid body dynamics in Unity and simulate key Newtonian concepts, such as:  Newton�s Laws of Motion (e.g., push objects to see acceleration); Gravity and free fall (drop objects and measure acceleration); Collisions and momentum transfer (simulate billiard ball collisions); Projectile motion (throw virtual objects and observe trajectories). The system should enable enable grabbing, throwing, and pushing objects using Leap Motion; Apply forces to objects based on hand velocity and movement and Display real-time force, velocity, and acceleration values as visual overlays.\n\nSpecific details:\n(a) Design component\n\nTo design the system using UNITY 3D physics engine and Leap Motion hand tracking\n(b) Implementation component\nTo implement the system.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Alexei Sourin",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Graphics",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0370",
    "title": "Identifying antibody-antigen interactions with XAI and design of antibodies with gen AI",
    "summary": "The project is to develop eXplainable AI (XAI) and generative AI (genAI) technique for the design of antibodies to use as therapeutic agents for cancer. \nAntibodies, naturally produced by the immune system to fight off foreign substances, are increasingly used as drugs, or therapeutic antibodies, to treat diseases like cancer. In this project, we first build large language models (LLM) to predict antibody-antigen binding affinity and leverage on XAI approaches such as Integrated Gradients to identify features that lead to the prediction.  Second, using these features as constraints to genAI approaches such as LLM and diffusion models, we generate antibodies that can be used as therapeutic agents.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on predicting binding affinity of antibody-antigen interactions; and generating antibodies with anticancer properties \n\n(b) Development component\nStudent will implement necessary predictive AI, XAI, and genAI techniques in Python with Pytorch/Tensorflow libraries",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0371",
    "title": "Identifying epitope-HLA (Human Leukocyte Antigen) binding interactions with XAI and design of epitopes with genAI",
    "summary": "The project is to develop eXplainable AI (XAI) and generative AI (genAI) technique for the design of peptides (epitopes) to use as therapeutic agents for cancer. \n\nEpitopes, specific regions on antigens recognized by antibodies or T-cell receptors, are increasingly used as therapeutic targets, enabling the development of vaccines, therapies, and treatments for various diseases, including cancer. Epitope-HLA binding interactions are crucial for the immune system's ability to recognize and respond to foreign antigens, with HLA molecules presenting peptide epitopes derived from proteins to T cells. In this project, we first build large language models (LLM) to predict epitope-HLA binding affinity and leverage on XAI approaches such as Integrated Gradients to identify features that lead to the prediction.  Second, using these features as constraints to gen AI approaches such as LLM and diffusion models, we design epitopes that can be used as therapeutic agents.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on predicting binding affinity between epitope-HLA interactions and on generating epitopes that induce anticancer immune response\n\n(b) Development component\nThe student will develop necessary predictive AI, XAI, and gen AI technique in Python with Pytorch/Tensorflow frameworks.",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Medical Informatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0372",
    "title": "Mitigating RIS hardware impairments using deep learning-based beamforming algorithms for enhanced efficiency in 6G terahertz communications",
    "summary": "One of the critical challenges in 6G networks is boosting communication performance while counteracting hardware impairments such as phase noise, amplitude mismatches, and nonlinear distortion especially in dense environments. This project proposes the development of a neural network-based Reconfigurable Intelligent Surface (RIS) system that dynamically adjusts its configuration to counteract both RIS defects and these impairments, all while sustaining high data throughput.\nThe research involves a thorough investigation of how these hardware limitations affect spectral efficiency. You will develop advanced signal processing and compensation algorithms that leverage deep learning and reinforcement learning techniques to mitigate impairments in real time. By integrating adaptive calibration methods with robust design principles, the system aims to balance the competing demands of high throughput and energy conservation. The goal is to create a prototype demonstrator that validates these methods and provides crucial insights for deploying RIS in energy-conscious 6G networks.\nFurthermore, the project will analyze the trade-offs between hardware impairments and network performance, offering strategic insights into integrating RIS for future energy-efficient 6G deployments.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nDetailed modelling and analysis of RIS hardware impairments in THz environments.\nSimulation studies to quantify how these impairments affect spectral efficiency and signal integrity. Recent deep learning and deep reinforcement algorithms that can be used to mitigate these impairments. \n\n(b) Development component\nDesign and implementation of compensation algorithms using advanced signal processing and deep learning techniques.\nDevelopment and testing on a RIS-enabled terahertz environment in MATLAB/Python to evaluate real-time performance improvements.",
    "supervisor": "A/P A S Madhukumar",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Wireless and Mobile Networks",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0373",
    "title": "Robust Reconfigurable Intelligent Surface Architecture for Energy-Efficient 6G Networks",
    "summary": "One of the critical challenges in 6G networks is boosting communication performance while counteracting hardware impairments such as phase noise, amplitude mismatches, and nonlinear distortion especially in dense environments. This project proposes the development of a neural network-based Reconfigurable Intelligent Surface (RIS) system that dynamically adjusts its configuration to counteract both RIS defects and these impairments, all while sustaining high data throughput.\nThis proposal aims to develop a robust RIS architecture that maintain high energy efficiency in demanding THz communication scenarios. By examining the interplay between RIS design imperfections and network energy dynamics, the project will propose a hybrid algorithm using deep learning and deep reinforcement learning that combines adaptive calibration with robust beamforming techniques. Extensive simulations will assess the performance trade-offs and validate the proposed design under varying operating conditions. This work is anticipated to advance the practical deployment of RIS in energy-sensitive 6G networks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nInvestigation into the types and impacts of RIS design on THz signal propagation and energy consumption.\nAnalytical modelling and simulation to derive optimal strategies for impairment mitigation.\nRecent deep learning and deep reinforcement learning algorithms. \n\n(b) Development component\nImplementation of a hybrid algorithm that merges adaptive calibration with robust beamforming for real-time impairment compensation.\nDevelopment and testing on a RIS-enabled terahertz environment in MATLAB/Python to evaluate energy efficiency improvements and validate the algorithm under realistic 6G network conditions.",
    "supervisor": "A/P A S Madhukumar",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Wireless and Mobile Networks",
      "Computer Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0374",
    "title": "Machine Learning and Semantic Communication for Interference Management in Spectrum-Sharing Wireless Networks",
    "summary": "Semantic communication focuses on transmitting only the useful information of a message. Machine learning (ML) techniques play a pivotal role in semantic communication in extracting the meaningful information, such as identifying critical features in an image, key phrases in a text, or relevant sensor readings in Internet of Things (IoT) applications.\n\nOver the years, the spectrum scarcity problem in wireless communication has become one of the most pressing challenges due to the surge in mobile phones and the rapid growth of connected devices, including smart home appliances, industrial machines, healthcare devices, and vehicles.\n\nTo address this issue, spectrum-sharing technologies have emerged as a potential solution. These technologies allow multiple devices to share the same frequency bands. However, when a large number of devices operate within the same frequency band, they create interference for each other, reducing communication quality. This can lead to slower speeds, dropped connections, or even complete signal loss. Therefore, in spectrum-sharing environments, interference management is crucial to maintaining the required quality of service.\n\nThis project aims to minimize interference by integrating semantic communication with conventional techniques such as power control and beamforming. The project will involve employing advanced ML techniques and conducting simulation-based analysis  using Python/MATLAB.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature review of semantic communication for spectrum sharing technologies like cognitive radio and underlay device-to-device technologies.\n\n(b) Development component\nOptimize the performance of the proposed solution, and fine tune for the proposed application. \nTrain and test with simulated data.",
    "supervisor": "A/P A S Madhukumar",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Wireless and Mobile Networks",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0375",
    "title": "Reinforcement and Federated Learning based Resource Allocation in RIS-Based Networks",
    "summary": "Reconfigurable intelligent surfaces (RIS), an emerging technology, can intelligently reflect incoming signals and play a crucial role in improving user data rates. RIS can be strategically deployed on building facades and rooftops, at roadside units, on lamp posts, unmanned aerial vehicles, and inside malls, airports, and stadiums.\n\nHowever, in RIS-based networks efficient resource allocation like user power control, bandwidth allocation, and beamforming optimization is complex due to the large RIS surfaces with hundreds of elements and dynamic channel variations caused by user mobility and time-varying environments. In this context, advanced machine learning (ML) techniques such as reinforcement learning (RL) and federated learning (FL) are gaining significant research interest. RL algorithms like deep Q-networks (DQN), proximal policy optimization (PPO), and multi-agent RL (MARL) can dynamically adjust resources in real-time by learning from interactions with the wireless environment. \n\nFurthermore, traditional ML approaches are typically centralized, which may be impractical due to privacy constraints and communication overhead. FL provides a promising decentralized ML framework that enables RIS-based systems to learn resource allocation policies without sharing raw data. This project aims to analyze the performance of RL and FL-based resource allocation in RIS-based systems using Python/MATLAB.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature review of RL and FL based solutions in wireless communication.\n\nImplement the DQN, PPO and MARL-based solutions to RIS-based systems\n\n(b) Development component\nBuild suitable model variants, and fine tune for the proposed application. \nTrain and test with simulated data.",
    "supervisor": "A/P A S Madhukumar",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Wireless and Mobile Networks",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0376",
    "title": "Developing a Language translation app with edge-enabled LLM",
    "summary": "Enabling real-time, high-quality language translation services for mobile and industrial applications is a critical challenge due to the computational complexity of large-scale language models (LLMs) and the latency constraints of end-user devices. Traditional cloud-based solutions often suffer from high latency and network congestion, making them unsuitable for time-sensitive applications such as multilingual communication in business, healthcare, and emergency response scenarios.\n\nTo address these challenges, this project investigates the integration of AI-driven language translation with edge computing, leveraging computational offloading techniques. Instead of relying solely on centralized cloud processing, complex translation tasks are dynamically distributed between edge devices and cloud servers based on network conditions, device capabilities, and workload demand. By intelligently offloading computations to edge servers, latency is minimized while ensuring real-time translation accuracy and efficiency.\n\nSpecifically, this project aims to develop a language translation app that leverages existing LLM models along with novel offloading policies, evaluated based on processing time and translation accuracy under realistic network conditions. The app will serve as a platform for implementing the offloading strategy. The integration of 5G-and-beyond networks enhances communication reliability and minimizes delays, enabling seamless multilingual interactions among diverse users. \n\nThis research aims to advance the capabilities of AI-driven language translation by optimizing computational resource utilization in edge-enabled environments, making high-performance language services accessible even in bandwidth-limited or high-demand scenarios.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature review of computational offloading.\n\nInvestigating the integration of AI-driven language translation with edge computing, leveraging computational offloading techniques.\n\n(b) Development component\nBuild a suitable app for language translation.\nImplementing edge-enabled LLM.",
    "supervisor": "A/P A S Madhukumar",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Distributed Computing Systems",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0377",
    "title": "Evaluation of beam forming with distributed access points for multi channel free space laser transmitter",
    "summary": "Lightspeed Photonics developed a 12 channel free space laser transmitter and integrated two transmitters with 24 lasers on a PCB. The student needs to study the beam overlap between multiple channels and recommend optimum channels for reduced cross talk and interference, implement the multiple channels as distributed access points to study the feasibility of wider coverage area interference between channels. The student is expected to develop Distributed Learning based algorithms to optimize the spatial geometry.\n\nSpecific details:\n(a) Design component\nDL Algorithms for upto 24 channel optical transmitters \n\n(b) Implementation component\nBeam area coverage for multiple channels, optimized channel coverage\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P A S Madhukumar",
    "isJointOrURECA": "JIP",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Wireless and Mobile Networks",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0378",
    "title": "Extended free space optical link of multi channel laser transmitter using secondary optical elements evaluation",
    "summary": "We propose a free-space optical interconnect for upto 5m distance using laser transmitter and PIN photodetector receiver. \nThe student needs to integrate a commercial Transmitter Optical Sub-Assembly(TOSA)/Receiver Optical Sub-Assembly (ROSA) and Lightspeed Photonics developed transmitters and receivers using a secondary beam expander (for example from Thorlabs) as part of the project.\nThe student will evaluate the system link and conduct performance analysis like signal transmission, tolerance studies, data rate vs errors etc, estimate the Line-of-sight accuracies at multiple channel distances for both TOSA/ROSA and Tx/Rx. \nThe student need to establish uni-directional and bi-directional communication, loop back the Tx signal at the receiver and verify the complete link.\nThe student needs to evaluate TOSA/ROSA and Tx/Rx and benchmark the performance of both commercial TOSA/ROSA Lightspeed transmitters and receivers.\n\nSpecific details:\n(a) Design component\nDesign of interface between transmistter/receiver and secondary optics and front end driving signals.\nI2C program to set up device functionality.\n\n(b) Implementation component\nPerformance evaluation of free space optical link with secondary beam expander\nBenchmarking between test tx/rx and commercial TOSA/ROSA\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P A S Madhukumar",
    "isJointOrURECA": "JIP",
    "category": "Hardware Only",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Digital Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0379",
    "title": "Analysis of water sensor data",
    "summary": "The St Johns island marinetime lab has deployed a boey with sensor in singapore waters. This project goal is to analised the data and match it to some of the weather station data.  The student will build a website to host the data and also to help users navigate through and better analise the data. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis is an experiment and investigation into the correlation of the buoy data. \n\n(b) Development component\nBuild a website to help people analise the data.",
    "supervisor": "A/P Lee Bu Sung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0380",
    "title": "Formalized Mathematics (Towards Mechanizing 1000 Theorems)",
    "summary": "Theorem proving is about writing mathematical results/proofs in a formal,\ncomputer-checkable language; formal proofs have gained significant popularity\nin mathematics and in AI, e.g., it was used recently by Google Deepmind as the\nbacking language for AlphaProof.\n\nIn this project, the student will learn to use a proof assistant, such as\nIsabelle/HOL or Lean, to mechanize one of the proofs in this list\n(https://1000-plus.github.io/all). The choice of result to be formalized will\nbe discussed with the supervisor.  This project is suitable for students who\nwish to pick up theorem proving and have strong background in mathematics.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThe student will be learning how to use a proof assistant.\n\n(b) Development component\n\nThe student will be developing one formal proof from the aforementioned list in the proof assistant.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0381",
    "title": "Mitigating the MathPrompt Jailbreak in LLMs",
    "summary": "MathPrompt is a new jailbreak technique that rephrases harmful requests as math problems using a few-shot prompting method, tricking even state-of-the-art LLMs into producing unsafe content. By framing the query as a formal math problem rather than plain language, the model�s content filters fail to recognize the malicious intent. In tests, MathPrompt bypassed protections in 13 top LLMs with an average 73.6% success rate. For instance, �Explain how to create a phishing scam� was rephrased as a set theory proof about deceptive emails, which the LLM solved and inadvertently explained the scam.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nThis project will be co-supervised with an A*STAR researcher. The student will\nbe allocated a workspace at A*STAR, and will need to travel to A*STAR regularly\nfor access to the necessary equipment.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nLLMs today rely on safety training like RLHF and content filters to block harmful outputs. They undergo regular red-teaming, and known jailbreak tricks are quickly patched via model updates. However, MathPrompt exposes a critical gap: safeguards tuned for natural-language threats struggle against math-encoded prompts. The mathematical encoding alters the prompt�s semantic representation, thus evading standard filters. This finding calls for new defenses in AI safety. We propose to develop techniques for detecting and neutralizing math-formatted malicious prompts, and to incorporate such adversarial examples into training, helping future models resist MathPrompt-style exploits.\n\n(b) Development component",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0382",
    "title": "Vulnerabilities of a Connected AI System",
    "summary": "This proposal aims to develop a simulated environment�using platforms like the\nHumanoid and Autonomous Robot Simulator or Drone Simulator�where multiple\nneural networks interconnect to form a large, complex system. This architecture\nmirrors real-world IoT applications, where AI models for perception,\ndecision-making, and control collaborate seamlessly to ensure overall system\nfunctionality. In autonomous systems such as drones or smart robots, these\nmodels work in unison to facilitate smooth and efficient operations.\n\nHowever, this tight integration also introduces systemic vulnerabilities. An\nattack or failure in one module�be it perception, sensor fusion, or control�can\nsignificantly impact the entire network's performance. For instance,\ncompromising a perception module could feed incorrect data into control\nsystems, disrupting decision-making processes across the network. This scenario\nunderscores the necessity of identifying critical models and prioritizing their\nprotection to maintain system security and robustness against adversarial\nattacks.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nThis project will be co-supervised with an A*STAR researcher. The student will\nbe allocated a workspace at A*STAR, and will need to travel to A*STAR regularly\nfor access to the necessary equipment.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThis project will explore these vulnerabilities and develop strategies to\nenhance the security and performance of each AI model. By doing so, it aims to\ncontribute to more resilient IoT systems capable of withstanding complex\nthreats in real-world environments. The insights gained could inform the design\nof future autonomous systems, ensuring they are both efficient and secure. \n\n(b) Development component",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0383",
    "title": "Graph-Isomorphism Detection via Counting",
    "summary": "The isomorphism type of an arbitrary graph can be uniquely determined by homomorphism counts of certain form. Moreover, there is a known construction of R(n) -- a graph dependent on n -- such that every graph G of order at most n (i.e., at most n nodes), up to isomorphism, has a different number of homomorphisms to R(n). This construction is computationally infeasible, however, since the order of R(n) is superexponential in n.\n\nNevertheless, the order of such R(n) can be made O(n^k) for some fixed k if G is restricted to be drawn from certain classes C of graphs rather than from the whole class of graphs; trivial examples of C include the class of independent sets and the class of complete graphs.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nThis project will be co-supervised with an A*STAR researcher. The student will\nbe allocated a workspace at A*STAR, and will need to travel to A*STAR regularly for meetings.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThis project aims to identify some nontrivial examples of C and, if time permits, to derive a lower bound on the order of the corresponding R(n).\n\n(b) Development component",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Theory &amp; Algorithms",
      "Logic and Formal Methods"
    ]
  },
  {
    "projectNo": "CCDS25-0384",
    "title": "Providence � Supercharge Agentic AI",
    "summary": "This project aims to develops an Agentic AI Software System for autonomous formal verification/software engineering/VAPT/CI/CD Security Pipelines. By integrating AI-driven model checking, theorem proving, and symbolic execution, the system automates software validation, detects vulnerabilities, and improves test coverage. Leveraging LLMs, agentic AI eliminates human intervention in bug detection, vulnerabilities, code verification and testing. The AI will also employ reinforcement learning to refine its accuracy over time.\n\nStudents should be familiar with one or more of the following topics: Python, PyTorch, CUDA; LLM such as ChatGPT, DeepSeek; Formal verification; Ethical hacking, vulnerability assessment, penetration testing; CI/CD security pipeline\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nThis project will be co-supervised with an A*STAR researcher. The student will\nbe allocated a workspace at A*STAR, and will need to travel to A*STAR regularly\nfor access to the necessary equipment.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0385",
    "title": "Unsupervised Graph-Level Representation Learning",
    "summary": "This project aims to learn graph representations in an unsupervised manner, i.e., no labels on graphs are available. Such representations are often used for subsequent tasks such as graph clustering, graph classification, etc. \n\nThe student is required to (1) collect real graphs or benchmark graph datasets from online resources, (2) study state-of-the-art graph representation learning methods; (3) identify shortcomings of existing methods; (4) design and implement an algorithm that is able to address the shortcomings, and (4) evaluate the proposed algorithm on real graphs.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign and implement an algorithm that is able to address the shortcomings of existing graph representation learning methods\n\n(b) Development component",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Artificial Intelligence",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0386",
    "title": "Multi-View Graph Clustering",
    "summary": "This project aims to study the problem of graph clustering under the case when the input data contains multiple views. The student is required to (1) collect real multi-view graphs, (2) study state-of-the-art multi-view graph clustering methods and identify their shortcomings, (3) design and implement an algorithm that is able to address these shortcomings, and (4) evaluate the proposed algorithm on real multi-view graphs. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign and implement an algorithm that is able to address these shortcomings of existing multi-view graph clustering methods.\n\n(b) Development component",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0387",
    "title": "Neuro-Imaging Data Analysis",
    "summary": "This project aims to study the analysis of neuro-imaging data, in particular, the f-MRI data and/or DTI data. The student is required to (1) collect real neuro-imaging data from open databases, (2) study the standard pre-processing pipelines for neuro-imaging data,  (3) study the effect of different components in the pre-processing pipeline to the quality of the output data in the form of brain networks, and (4) come up with a best pre-processing setting that generates brain networks with the best quality.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nResearch the effect of different components in the pre-processing pipeline to the quality of the output data in the form of brain networks.\n\n(b) Development component",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Bioinformatics",
      "Data Analytics",
      "Computational Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0388",
    "title": "Semi-Supervised Node Representation Learning",
    "summary": "This project aims to learn node representations in a semi-supervised manner, i.e., limited labels on nodes are available. Such representations are often used for subsequent tasks such as node classification, link prediction, etc. \n\nThe student is required to (1) collect real graphs or benchmark graph datasets from online resources, (2) study state-of-the-art node representation learning methods; (3) identify shortcomings of existing methods; (4) design and implement an algorithm that is able to address the shortcomings, and (4) evaluate the proposed algorithm on real datasets.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign and implement an algorithm that is able to address the shortcomings of existing node representation learning methods\n\n(b) Development component",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Artificial Intelligence",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0389",
    "title": "Cluster Analysis on Dynamic Graphs",
    "summary": "Graph data is ubiquitous in real life. Examples include social networks, biological networks, transportation networks, communication networks, etc. Graph clustering aims to group vertices in a given graph such that vertices in the same cluster are densely connected, while vertices in different clusters are sparsely connected.\n\nThis project is to study the clustering problem on dynamic graphs that evolve/change over time. Dynamic graph clustering has many practical applications. For example, it can be used in online social networking sites for capturing users� dynamic behaviours and performing dynamic service/apps recommendations.\n \nSpecially, the student is required to (1) collect real dynamic graphs, (2) design and implement an algorithm that is able to find clusters on dynamic graphs, (3) design and implement an algorithm that is able to trace how clusters evolve over time, and (4) evaluate the two algorithms on real dynamic graphs. \n\nPrerequisite: \n-\tGood knowledge in data mining and machine learning\n-\tGood knowledge in algorithm design\n-\tGood programming skill (C++ or Java)\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nDesign an algorithm to cluster dynamic graphs\nDesign an algorithm to trace cluster evolvement\n\n(b) Development component\nImplement the two algorithms\nEvaluate on real dynamic graphs",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Mining",
      "Machine Learning",
      "Data Structure and Algorithms",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0390",
    "title": "Network Analysis on Neuro-imaging Data",
    "summary": "Analyzing neuro-imaging data (MRI data) with network-based methods is demonstrated to be promising recently. This project performs research on graph analytics on brain networks obtained from neuro-imaging data. The student is required to (1) collect and pre-process real neuro-imaging data; (2) research and develop graph analytics methods; (3) validate the performance of the methods on real data, and (4) find interesting insights out of data.\n\nSpecific details:\n(a) Design component\n\nDesign analytic framework/pipeline\n\n\n(b) Implementation component\n\n(a) Research component\n\nResearch and develop graph analytics methods for neuro-imaging data\n\n\n(b) Development component",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning",
      "Bioinformatics"
    ]
  },
  {
    "projectNo": "CCDS25-0391",
    "title": "Mitigating Hallucination in Large Language Models for Medical Research",
    "summary": "The rapid advancement of large language models (LLMs) has revolutionized various fields, including biomedical research. However, these models often generate information that is not factually accurate or \"hallucinations,\" posing significant risks in critical domains such as healthcare and biomedical research. This project aims to develop innovative techniques to detect and mitigate hallucination in LLMs, enhancing their reliability and trustworthiness in the biomedical domain.\n\nThis project addresses a critical challenge in the application of LLMs to biomedical research. By developing robust methods to mitigate hallucination, it aims to enhance the utility and safety of AI-generated content, ultimately contributing to more reliable and effective biomedical research and healthcare solutions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nDevelop approaches to mitigate the risk of hallucination in LLMs.",
    "supervisor": "Ast/P Chan Guo Wei Alvin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0392",
    "title": "Multi-Modal Large Language Model for Healthcare",
    "summary": "Large language models (LLMs) like ChatGPT have demonstrated remarkable performance in language-based tasks. However, their application in healthcare, particularly in patient-facing solutions, remains underexplored. This research project aims to develop a multi-modal LLM-based solution for healthcare, focusing on improving patient interactions and providing accurate, reliable information tailored to individual needs. \nThis project seeks to leverage the power of multi-modal large language models to transform patient-facing healthcare solutions. By integrating various data types and focusing on accurate, personalized interactions, this research aims to enhance patient communication, improve the delivery of healthcare information, and ultimately contribute to better health outcomes.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nDevelop Multi-Modal Capabilities: Integrate various data types, including text, images, and medical data, to create a comprehensive and context-aware healthcare model.\nEnhance Patient Interaction: Design the LLM to engage in meaningful and accurate conversations with patients, providing personalized healthcare advice and support.\nEnsure Accuracy and Reliability: Implement robust mechanisms to minimize misinformation and hallucinations, ensuring the LLM provides accurate and trustworthy medical information.",
    "supervisor": "Ast/P Chan Guo Wei Alvin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Medical Informatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0393",
    "title": "Multi-Modal Large Language Model for Drug Development",
    "summary": "Large language models (LLMs) like ChatGPT have shown remarkable performance for tasks based on human language. However, relatively few work has been done on using these powerful AI models for the development of medicine. This research will focus on the development of an LLM-based model that represents a novel approach in the field of drug discovery. The implications of this research are profound, offering the potential to revolutionize the way drug formulations are discovered and optimized. By leveraging the power of deep learning to understand and model the multi-faceted nature of drug formulations, we can accelerate the pace of discovery and enhance the precision of drug development processes. This, in turn, could lead to the creation of more effective and targeted therapies, ultimately translating to improved clinical outcomes.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research &amp; Development component\nThe student will contribute towards the development of a large language model (LLM) that can predict the efficacy of drug formulation. The student is expected to work in Python programming language and deep learning frameworks such as PyTorch and Tensorflow.",
    "supervisor": "Ast/P Chan Guo Wei Alvin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Biomedical Systems",
      "Computational Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0394",
    "title": "Accessible Deep Learning for Science through Large Language Models",
    "summary": "The lack of artificial intelligence (AI) skills or talent has been cited as the number one challenge to using AI in scientific research and medicine. Large language models (LLMs) like ChatGPT have shown remarkable performance for tasks based on human language and are a promising approach to address this challenge. They could offer an intuitive interface for users to tap into sophisticated deep learning technologies. This project will focus on evaluating the current state of LLMs in scientific research and developing technologies to enhance their capabilities through science-related deep learning models. The work here will contribute towards making deep learning more accessible to scientific research and medicine, accelerating progress in these critical fields.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research &amp; Development component\nThe student will contribute towards the development of a large language model (LLM) that can carry out sophisticated biomedical domain-related inference. The student is expected to work in Python programming language and deep learning frameworks such as PyTorch and Tensorflow.",
    "supervisor": "Ast/P Chan Guo Wei Alvin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Biomedical Systems",
      "Computational Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0395",
    "title": "Multi-Modal Large Language Model for Drug Development",
    "summary": "Large language models (LLMs) like ChatGPT have shown remarkable performance for tasks based on human language. However, relatively few work has been done on using these powerful AI models for the development of medicine. This research will focus on the development of an LLM-based model that represents a novel approach in the field of drug discovery. The implications of this research are profound, offering the potential to revolutionize the way drug formulations are discovered and optimized. By leveraging the power of deep learning to understand and model the multi-faceted nature of drug formulations, we can accelerate the pace of discovery and enhance the precision of drug development processes. This, in turn, could lead to the creation of more effective and targeted therapies, ultimately translating to improved clinical outcomes.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research &amp; Development component\nThe student will contribute towards the development of a large language model (LLM) that can predict the efficacy of drug formulation. The student is expected to work in Python programming language and deep learning frameworks such as PyTorch and Tensorflow.",
    "supervisor": "Ast/P Chan Guo Wei Alvin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Biomedical Systems",
      "Computational Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0396",
    "title": "Reinforcement Learning based motion path planning with obstacle avoidance II",
    "summary": "Multi-arm robot systems operate automatically imitating the action of human arms. Their advantages are strong universality, flexible movement and easy control. They are thus widely employed in various fields.  The working environment of a manipulator is always constrained with obstacles. Planning the optimal trajectory of a robot arm amid obstacles is thus challenging.  This project aims to explore efficient deep reinforcement learning based approaches to plan the trajectory of robot arm(s) with obstacle avoidance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nRL in trajectory planning\n\n(b) Development component\n\nImplementation of the algo",
    "supervisor": "A/P Yeo Chai Kiat",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0397",
    "title": "Reinforcement Learning based motion path planning with obstacle avoidance",
    "summary": "Multi-arm robot systems operate automatically imitating the action of human arms. Their advantages are strong universality, flexible movement and easy control. They are thus widely employed in various fields.  The working environment of a manipulator is always constrained with obstacles. Planning the optimal trajectory of a robot arm amid obstacles is thus challenging.  This project aims to explore efficient deep reinforcement learning based approaches to plan the trajectory of multiple robot arms with obstacle avoidance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nRL in trajectory planning\n\n(b) Development component\n\nImplementation of the algo",
    "supervisor": "A/P Yeo Chai Kiat",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0398",
    "title": "Unsupervised Action Segmentation in Instructional Videos",
    "summary": "The student shall first implement one or more state-of-the-art techniques to segment the various steps in instructional videos. \n\nThereafter, the student shall innovate on the existing techniques to improve the accuracy.  Techniques can include but not limited to use of speech processing, deep learning and  foundational models such as LLM.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Yeo Chai Kiat",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0399",
    "title": "Can LLM help design ER-diagrams?",
    "summary": "This project will let the FYP student explore the possibility of using LLM to generate ER-diagram. ER-diagram is typically designed based on user requirements, and has a lot of design concerns. LLM may have potential in relieving this tedious process. This project is close to a research project, and thus require the student to have sufficient time to be devoted into the project.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThere requires a lot of research efforts in designing and generating prompts. \n\n(b) Development component",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0400",
    "title": "Can LLM interpret system logs? - Part B",
    "summary": "A lot of data systems generate system logs. These logs are helpful for programmers to debug and performance profiling.\nThis project studies whether LLMs are helpful to interpret the system logs. The student is required to run a number of real data systems (such as RocksDB, LevelDB), and use a typical LLM to interpret the system logs. Findings will be summarized in their FYP reports.\n\nSpecific details:\n(a) Design component\nNeed to design LLM prompts to help LLM interpret the system logs.\n\n(b) Implementation component\nNeed to run systems, which requires a lot of technical and programming skills.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0401",
    "title": "Can LLM interpret system logs? - Part A",
    "summary": "A lot of data systems generate system logs. These logs are helpful for programmers to debug and performance profiling.\nThis project studies whether LLMs are helpful to interpret the system logs. The student is required to run a number of real data systems (such as RocksDB, LevelDB), and use a typical LLM to interpret the system logs. Findings will be summarized in their FYP reports.\n\nSpecific details:\n(a) Design component\nNeed to design LLM prompts to help LLM interpret the system logs.\n\n(b) Implementation component\nNeed to run systems, which requires a lot of technical and programming skills.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0402",
    "title": "The dynamic graph learning based on the spiking neural network",
    "summary": "Graph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn complex systems of relations or interactions. Despite the plethora of different models for deep learning on graphs, few approaches have been proposed for dealing with graphs that are dynamic in nature (e.g. evolving features or connectivity over time). \n\nSpiking neural networks (SNNs) are the third-generation neural networks. Unlike conventional neural networks, SNNs transmit information via the precise timing (temporal) of spike trains consisting of a series of spikes (discrete), rather than a real value (continuous). Driven by the sparse nature of spike events and event-driven computation, SNNs offer exceptional power efficiency and are the preferred neural networks in neuromorphic architectures. Despite their excellent potential, SNNs have been limited to relatively simple tasks (e.g., image classification) and small datasets (e.g., MNIST and CIFAR), on a rather shallow structure.\n\nThis project targets the probability of incorporating the SNNs into dynamic graph learning. On the one hand, this combination can help model the temporal data in graph use SNNs manner. On the other hand, it can also help reduce the energy consumption of graph learning.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThe research component includes the basic GNN reference or prediction, the representation learning on dynamic graph, and the SNNs structure.\n\nThe development component includes a detailed combination of dynamic GNN and SNNs. Moreover, the design should keep a low energy consumption with a state-of-the-art accuracy.",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0403",
    "title": "Profiler for RocksDB",
    "summary": "RocksDB stands as a prevalent LSM-tree key-value store system, often serving as an embedded key-value store for various applications. Typically, RocksDB gathers statistical data, including operation execution times and internal event occurrences, and provides this information cumulatively through functions such as statistics.ToString or statistics.getHistogramString. While these functions deliver a comprehensive report up to the current point, the need often arises to analyze data within specific time windows or perform complex real-time calculations on internal events, a process known as stream processing.\n\nIn industry settings, streaming systems like ElasticSearch, Prometheus, and Kafka are commonly employed to collect internal statistical data from database systems. This enables developers and database administrators (DBAs) to monitor events and computations dynamically in real-time. However, RocksDB faces limitations in this regard due to the absence of relevant interfaces. It can only accumulate statistical data in memory and process them in batch, posing challenges for real-time monitoring.\n\nSpecific details:\nYour task is to implement a new class extending the Statistics interface in RocksDB which is able to:\n\n1. Collect statistical data for internal events or operations\n2. Emit the statistics by stream to a streaming system (e.g., push data to a Prometheus instance)\n3. Support common stream processing and windowing\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0404",
    "title": "Crowd Estimation in Images",
    "summary": "It is often very difficult to estimate the sizes of large distant crowds in images taken from high-mounted cameras, due to large variations of crowd density at different locations, as well as perspective distortion. This project is to investigate how the latest texture analysis methods in computer vision can be used in an interactive manner to help solve this problem. This technology will be of great interest to the police and civil defence forces. An extension of this idea to count animals may be of significant interests to the farming communities in other countries.\n\nSpecific details:",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "",
    "type": "",
    "keywords": [
      "Computer vision, Image processing and Pattern recognition"
    ]
  },
  {
    "projectNo": "CCDS25-0405",
    "title": "The Augmented Human - Visual Movement Magnification",
    "summary": "This project is part of a series investigating means of augmenting human capabilities. In this project, the student will investigate and implement computer vision techniques that magnify visual movement, so that users can observe previously indiscernible movement such as breathing, pulse and tiny facial movements of other people in camera video. This is a relatively open-ended project where students are expected to explore different possibilities.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThis will leverage on some previous published research work by other groups. However, the student is welcome to form and investigate his or her own extensions to the core techniques, and also other applied scenarios.\n\n(b) Development component\n\nThe bulk of the work will be in software, but there is added bonus if the student can put together an interactive system with a live video feed on a laptop or mobile phone.",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Mixed Reality",
      "Video/Audio/Speech Processing",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0406",
    "title": "Image Inpainting for Manipulating Scenes and Objects",
    "summary": "In this project, we will investigate further extensions to our recent series of methods on image inpainting / image completion, which enables effects such as object removal and changing facial expressions in images. This project is based on deep learning.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nFor students wanting a more research focus:\nThis project involve understanding our latest work on image inpainting, conducting further experiments on different datasets and image, and testing out new ideas.\n\nFor students wanting a more development focus:\nCreate a nice GUI for image inpainting using existing code.",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Artificial Intelligence",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0407",
    "title": "Panoramic Image Outpainting",
    "summary": "In this project, we will investigate recent work on image outpainting, which is a form of image inpainting but for extending an image beyond its border. This can be used to create panoramic images just from a normal photograph. This project will investigate the use of deep learning to create such a system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nFor students wanting a more research focus:\nThis project aims to extend some of our recent work  in image inpainting, by reversing / extending these concepts to image outpainting.\n\nFor students wanting a more development focus:\nCreate a nice GUI for image outpainting based on existing code.",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Artificial Intelligence",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0408",
    "title": "Body Movement Mimic - Video-based Human Body Motion Transfer",
    "summary": "This project involves exploring methods based on machine learning for video human body motion transfer, in which given an image of a person A and a video of a different person B, a video of person A can be synthesized that mimics person B's movement.  Recent related methods include the first-order motion model.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThe student is expected to investigate the latest methods for human body motion transfer.\n\nThe project can either follow:\n- a research-centric direction, where some new ideas are explored  to extend existing work towards new research; or\n- take a development-centric direction in which an interactive prototype is designed that will showcase existing work.",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Machine Learning",
      "Mixed Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0409",
    "title": "Hyper-Realistic Avatars",
    "summary": "This project involves the investigation of latest methods in computer vision and machine learning for creating highly realistic 3D avatars, to implement and test them. Possible recent methods to explore include articulated neural rendering, PiFU, etc.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThe student is expected to investigate the latest methods for 3D avatar creation.\n\nThe project can either follow:\n- a research-centric direction, where some new ideas are explored  to extend existing work towards new research; or\n- take a development-centric direction in which an interactive prototype is designed that will showcase existing work.",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Machine Learning",
      "Mixed Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0410",
    "title": "Head Movement Mimic - Video-based Human Head Motion Transfer",
    "summary": "This project involves exploring methods based on machine learning for video human head motion transfer, in which given an image of a person A and a video of a different person B, a video of person A can be synthesized that mimics person B's movement.  Recent related methods include HeadGAN.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThe student is expected to investigate the latest methods for human head motion transfer.\n\nThe project can either follow:\n- a research-centric direction, where some new ideas are explored  to extend existing work towards new research; or\n- take a development-centric direction in which an interactive prototype is designed that will showcase existing work.",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Visual Computing",
      "Machine Learning",
      "Mixed Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0411",
    "title": "The Augmented Human - Seeing Sounds",
    "summary": "This project is part of a series investigating means of augmenting human capabilities. In this project, the student will investigate how hearing impaired users may visually sense the type of sounds and the directions from which the sounds are coming from. The sound source direction will be estimated from a pair of stereo microphones. The sounds will then be visualized as splashes of color, depending on the frequency spectrum, and overlaid on a video stream showing the region from which the sounds appear to come from. The student is expected to be self-motivated and keen for hands-on development and experimentation.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThere are some existing published work that the student can refer to on sound source localization.\n\n(b) Development component\n\nThe student will develop code to process stereo sound signals coming from a pair of stereo microphones, in estimating sound direction and frequency spectrum. The rendering of color regions in an image is relatively straightforward. The initial milestone will be an offline system, but there will be added bonus for developing a live system.",
    "supervisor": "Prof Cham Tat Jen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Mixed Reality",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0412",
    "title": "Node Classification on Directed Graphs",
    "summary": "This project is to study the node classification task on directed graphs. Specially, the student is required to (1) collect and preprocess real directed networks/graphs, (2) perform a literature study on state-of-the-art methods for node classification on directed graphs, (3) identify research limitations of existing methods, (4) design and implement a solution to address the limitations, and (5) evaluate the proposed solution in real directed graphs and compare it against existing studies. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nPropose a novel solution to address the identified research limitations.\n\n(b) Development component\n\nImplement the proposed solution and compare it against existing studies",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0413",
    "title": "Graph Neural Network Benchmarking for Material Property Prediction",
    "summary": "This project is to research existing graph neural networks (GNNs) that are developed for material property prediction such as statability, bandgap, etc. Specially, the student is required to (1) collect and preprocess commonly used material structures, (2) perform a literature study on GNNs for material property prediction, (3) implement and evaluate them on material structures for benchmarking and identifying pros and cons of each model.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nPerform a comprehensive survey on the proposed topic\n\n(b) Development component\n\nImplement and evaluate existing models",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0414",
    "title": "AI-Powered Chatbot for Customer Service",
    "summary": "Build a chatbot that leverages Natural Language Processing (NLP) and machine learning to assist customers by answering queries, processing requests, and providing real-time support. The bot can be integrated into websites or mobile apps to automate customer service tasks, improving efficiency and user experience. This project involves training models on large datasets of conversations to understand context, intent, and offer relevant responses.\n\nSpecific details:\n(a) Design component\nstudent must collect large dataset of conversations between customer and customer service officers\n\n(b) Implementation component\nThe student must choose a base LLM and perform training, as well as other tasks like RAG to enhance the chatbot\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0415",
    "title": "Multi-Scale Brain Network Analysis",
    "summary": "This project is to perform neurological disease classification on multi-scale brain networks, where each subject is represented by brain networks with varied number of brain regions. Specially, the student is required to (1) process/acquire multi-scale brain networks based on real neuro-images, (2) perform a literature study on state-of-the-art methods, (3) identify research limitations of existing methods, (4) design and implement a solution to address the limitations, and (5) evaluate the proposed solution and compare it against existing studies. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nPropose a novel solution for multi-scale brain network analysis\n\n(b) Development component\n\nEvaluate the proposed solution and compare it against existing studies.",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0416",
    "title": "AI-Powered Resume Analyzer",
    "summary": "Develop an AI-based resume analyzer that evaluates resumes and provides feedback on structure, skills, and keywords for better job matching. The system will leverage large language models to assess resumes against job descriptions.\n\nSpecific details:\n(a) Design component\nchoosing the right LLM for the task\n\n(b) Implementation component\nTraining the LLM to perform the task to a suitable performance level\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Data Mining",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0417",
    "title": "Leveraging LLMs for Graph Representation Learning",
    "summary": "This project is to research the use of LLMs for graph representation learning for downstream tasks such as node classification, link prediction, graph classification/regression, etc. Specially, the student is required to (1) collect/process real graph data for downstream tasks, (2) perform a literature study on state-of-the-art methods, (3) identify research limitations of existing methods, (4) design and implement a solution to address the limitations, and (5) evaluate the proposed solution and compare it against existing studies. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nImplement a novel solution for using LLMs for graph representation learning\n\n(b) Development component\n\nEvaluate the proposed solution and compare it against existing studies.",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0418",
    "title": "Multi-Modality Brain Network Analysis",
    "summary": "This project is to perform neurological disease classification on multi-modality brain networks, where each subject is represented by brain networks constructed from multiple modalities of neuro-images such as fMRI and DTI. Specially, the student is required to (1) process/acquire multi-modality brain networks based on real neuro-images, (2) perform a literature study on state-of-the-art methods, (3) identify research limitations of existing methods, (4) design and implement a solution to address the limitations, and (5) evaluate the proposed solution and compare it against existing studies. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nPropose a novel solution to the research topic\n\n(b) Development component\n\nEvaluate the proposed solution and compare it against existing studies.",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0419",
    "title": "Alleviating the overfitting issue in brain network analysis",
    "summary": "This project is to research the overfitting issue in existing brain network analysis models. Specially, the student is required to (1) perform a literature study on state-of-the-art methods, (2) identify the severity of their overfitting issues, (3) design and implement a solution that is able to alleviate the overfitting issue in existing models, and (4) evaluate the proposed solution and compare it against existing studies. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nPropose a novel solution to alleviate the overfitting issue in brain network analysis\n\n(b) Development component\n\nEvaluate the proposed solution and compare it against existing studies",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0420",
    "title": "Continuous Benchmarking of Serverless Cloud Providers 2",
    "summary": "To date, there is no standard benchmarking methodology to quantitatively compare the performance of different serverless cloud providers. This project aims to design a framework that regularly runs a set of various microbenchmarks on multiple providers, including AWS Lambda, Azure Functions, Google Cloud Run, and Cloudflare. This project analyzes cold start delays related to image size and other characteristics of serverless functions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Quantify the performance differences among different cloud providers\n\n(b) Development component\n- Design and implement a continuous benchmarking tool",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0421",
    "title": "Optimizing Large Language Model Inference",
    "summary": "Nowadays, Large Language Models (LLMs) such as OPT, LLAMA and GPTs are increasingly capturing people�s attention. Compared with the training phase, the inference phase is equally critical, especially in terms of latency and throughput. The optimization is pivotal, in order to integrate the LLMs into diverse applications and maintain efficiency and effectiveness.LLM inference exhibits distinct characteristics compared to traditional computing tasks: LLM inference is bound by memory capacity in contrast to conventional DNNs bound by computation. Thus, considering the substantial size of the model parameters, lots of techniques are introduced to utilise GPU resources, including paged attention, continuous batching, etc. Recognizing the unique challenges posed by LLM inference, we studied multiple solutions to deploy multiple LLMs on a single high-cost GPU efficiently. By investigating NVIDIA�s Multi-Instance GPU (MIG) technology, we found that contention is the main reason for increased latency. MIG enables the hardware division of a single GPU into up to seven independent instances to avoid PCIe and memory contention. Therefore, each instance could have computing resources and bandwidth with guaranteed quality of service. Compared to the basic approach of running multiple LLMs on the same GPU without any isolation measures, MIG effectively and conveniently enhances throughput. Moving forward, our further research will concentrate on deploying LLMs across multiple machine systems. The approach will include an in-depth exploration of inference optimizations and scheduling policies to enhance the overall throughput.\n\nJustification for the High complexity: the project requires a solid understanding of the systems and machine learning components. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n* Analyze performance\n\n(b) Development component\n* Devise and prototype optimizations",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0422",
    "title": "ML and systems co-design for resource-efficient LLM inference serving",
    "summary": "ML and systems co-design for resource-efficient LLM inference serving by introducing preprocessing and postprocessing stages and query planning for large-scale LLM inference clusters.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n* Analyze the performance of various benchmarks and systems\n* Extend benchmarking methodology\n\n(b) Development component\n* Develop representative benchmarks\n* Develop experimental setup and analysis tools\n* Prepare open-source artifacts",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0423",
    "title": "Benchmarking a multi-modal model inference systems",
    "summary": "This research will provide insights into the challenges and opportunities in serverless computing for multi-modal inference. Aimed at students eager to explore low-level cloud system design and implementation, this project offers a deep dive into the underpinnings of cloud-native technologies, with potential contributions to novel serverless architecture design.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n* Analyze system bottlenecks\n\n(b) Development component\n* Develop tools and improve integration/testing",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems",
      "Computer Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0424",
    "title": "Optimizing Large Language Model Inference 2",
    "summary": "Nowadays, Large Language Models (LLMs) such as LLAMA and GPTs are increasingly capturing people�s attention. Compared with the training phase, the inference phase is equally critical, especially in terms of latency and throughput. The optimization is pivotal, in order to integrate the LLMs into diverse applications and maintain efficiency and effectiveness.LLM inference exhibits distinct characteristics compared to traditional computing tasks: LLM inference is bound by memory capacity in contrast to conventional DNNs bound by computation. Thus, considering the substantial size of the model parameters, lots of techniques are introduced to utilise GPU resources, including paged attention, continuous batching, etc. Recognizing the unique challenges posed by LLM inference, we studied multiple solutions to deploy multiple LLMs on a single high-cost GPU efficiently. By investigating NVIDIA�s Multi-Instance GPU (MIG) technology, we found that contention is the main reason for increased latency. MIG enables the hardware division of a single GPU into up to seven independent instances to avoid PCIe and memory contention. Therefore, each instance could have computing resources and bandwidth with guaranteed quality of service. Compared to the basic approach of running multiple LLMs on the same GPU without any isolation measures, MIG effectively and conveniently enhances throughput. Moving forward, our further research will concentrate on deploying LLMs across multiple machine systems. The approach will include an in-depth exploration of inference optimizations and scheduling policies to enhance the overall throughput.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n* Analyze performance\n\n(b) Development component\n* Devise and prototype optimizations",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "URECA-FYP",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0425",
    "title": "Optimizing Power Consumption For Serverless Computing",
    "summary": "With the growing popularity of serverless solutions, optimizing power consumption in serverless environments has become a critical concern. With dynamic CPU frequency scaling, serverless architectures can significantly reduce power usage without compromising performance. This project aims to integrate frequency scaling in serverless computing to achieve more cost-effective and sustainable cloud computing solutions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Study the sensitivity of serverless functions to CPU frequency\n- Explore scheduling policies in a cluster with various CPU frequencies\n\n(b) Development component\n- Incorporate power monitoring capability into the vHive cluster infrastructure\n- Develop a toolchain for power/performance analysis for a serverless cluster",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0426",
    "title": "Effective Fusion Methods for Multi-View Graph Analysis",
    "summary": "This project is to research fusion methods for multi-view graph analysis, where each sample is represented by multiple input graphs. Specially, the student is required to (1) collect/process real multi-view graph data, (2) perform a literature study on state-of-the-art methods, (3) identify research limitations of existing methods, (4) design and implement a solution to address the limitations, and (5) evaluate the proposed solution and compare it against existing studies. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nPropose a novel fusion method for multi-view graph analysis\n\n(b) Development component\n\nEvaluate the proposed solution and compare it against existing studies.",
    "supervisor": "A/P Ke Yiping, Kelly",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Graph Theory"
    ]
  },
  {
    "projectNo": "CCDS25-0427",
    "title": "Benchmarking and optimization of large-scale serverless deployments",
    "summary": "This project will allow students to explore the architectural design and implementation challenges of deploying serverless applications in a distributed computing landscape. Students will gain hands-on experience and foster a deep understanding of the principles of cloud-edge serverless systems. \n\nThe focus of this project is on the low-level computer systems part, requiring substantial motivation and effort to work at the software-hardware system interface, studying CPU, GPU, network, and disk usage patterns. The student will also be able to get more familiar with cloud-edge workloads and explore opportunities for optimizing the cloud-edge infrastructure for these emerging workloads.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n* Analyze the performance of various benchmarks and systems\n* Extend benchmarking methodology\n\n(b) Development component\n* Develop representative benchmarks\n* Develop experimental setup and analysis tools\n* Prepare open-source artifacts",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0428",
    "title": "Serverless Cloud Benchmarking with Serverless Function Traces 1",
    "summary": "Currently, many cloud providers have serverless solutions, raising a question about performance comparisons across providers. This project aims to make a system able to perform analysis of existing serverless solutions with provider-agnostic methodology and both real-world workloads sampled from Azure Functions production traces and a set of purposely-built synthetic workloads. The resulting system should provide exhaustive information, which is necessary to compare providers with each other and make conclusions about performance degradation sources.\n\nThis project will focus on extending upon the existing benchmarking methodology and performance analysis toolchain, aiming to include more cloud providers into the analysis and develop automation tools to facilitate conducting experiments and analyzing  the obtained results.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Analyze the performance of a set of cloud providers under load\n\n(b) Development component\n- Adopt the in-vitro load generator for a commercial cloud benchmarking\n- Write tools for experiment automation and data analysis",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems",
      "Computer Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0429",
    "title": "LLM Inference Serving Production Trace & System Performance Analysis 2",
    "summary": "To date, there is no standard benchmarking methodology to quantitatively compare the performance of different LLM inference cloud providers. This project aims to design a framework that regularly runs a set of various microbenchmarks on multiple providers. This project analyzes cold start delays related to image size and other characteristics of serverless functions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Quantify the performance differences among different cloud providers\n\n(b) Development component\n- Design and implement a continuous benchmarking tool",
    "supervisor": "Ast/P Dmitrii Ustiugov",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Operating Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0430",
    "title": "AI Chatbots for MOOC Education and Learning at Scale",
    "summary": "This project explores the use of ChatGPT and AI chatbots in education, focusing on Massive Open Online Courses (MOOCs) and large-scale learning environments. Students will learn key artificial intelligence concepts, including machine learning for AI-driven education. The project requires strong foundations in machine learning and proficiency in full-stack development (Node.js).\n\nSpecific details:\n(a) Design component\n\n\n\n(b) Implementation component\n\n(a) Research component\n\nThis project explores the use of ChatGPT and AI chatbots in education, focusing on Massive Open Online Courses (MOOCs) and large-scale learning environments. Students will learn key artificial intelligence concepts, including machine learning for AI-driven education. The project requires strong foundations in machine learning and proficiency in full-stack development (Node.js).\n\n(b) Development component\n\nSoftware development in AI chatbots  that run on Node.js server and cloud computing platform.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Data Structure and Algorithms",
      "e-Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0431",
    "title": "Data science in Python of large language models for AI-assisted programming",
    "summary": "This project will study the data science in Python  programming environment for AI-assisted programming using large language models like OpenAI API and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study the data science in Python  programming environment for AI-assisted programming using large language models like OpenAI API.\n\n(b) Development component\nDevelop a software as a service.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0432",
    "title": "Data science in C/C++  programming environment for AI-assisted programming in embedded systems",
    "summary": "This project will study the data science in C/C++  programming environment for AI-assisted programming in embedded systems using large language models like OpenAI API and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study the data science in C/C++  programming environment for AI-assisted programming in embedded systems using large language models like OpenAI API and open-sourced ones like code llama.\n\n(b) Development component\nDevelop a software as a service.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0433",
    "title": "Data science in Java/Javascript programming environment for AI-assisted programming",
    "summary": "This project will study the data science in Java/Javascript programming environment for AI-assisted programming using large language models like OpenAI API and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study the data science in Java/Javascript programming environment for AI-assisted programming using large language models like OpenAI API and open-sourced ones like code llama.\n\n(b) Development component\nDevelop a software as a service.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0434",
    "title": "Competitive programming for advanced algorithms using large language models",
    "summary": "This project will study competitive programming for topics in advanced algorithms using large language models like OpenAI API and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study competitive programming for topics in advanced algorithms using large language models like OpenAI API and open-sourced ones like code llama.\n\n(b) Development component\nDevelop a software as a service",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0435",
    "title": "Competitive programming for topics in Operations Research using large language models",
    "summary": "This project will study competitive programming for topics in Operations Research and Mathematical Decision Making using large language models like OpenAI API and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study competitive programming for topics in Operations Research and Mathematical Decision Making  using large language models like OpenAI API and open-sourced ones like code llama and DeepSeek.\n\n(b) Development component\nDevelop software as a service",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cloud Computing",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0436",
    "title": "Competitive programming for advanced algorithms using large language models",
    "summary": "This project will study competitive programming for topics in advanced algorithms using large language models like OpenAI API and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study competitive programming for topics in advanced algorithms using large language models like OpenAI API and open-sourced ones like code llama.\n\n(b) Development component\nDevelop a software as a service",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0437",
    "title": "Competitive programming for topics in graph algorithms using large language models",
    "summary": "This project will study competitive programming for topics in graph algorithms using large language models like OpenAI API and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study competitive programming for topics in graph algorithms using large language models like OpenAI API and open-sourced ones like code llama.\n\n(b) Development component\nDevelop software as a service.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0438",
    "title": "AI Pair Programming Technologies for Apple Xcode with Cloud-based and Local Language Models",
    "summary": "This project will study the AI pair programming paradigm and cloud computing technologies to support both local language models, e.g., Apple Intelligence as well as Cloud-based large language models like Github Copilot and open-sourced ones like code llama and DeepSeek.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study the AI pair programming paradigm and cloud computing technologies to support both local language models, e.g., Apple Intelligence as well as Cloud-based large language models like Github Copilot and open-sourced ones like code llama and DeepSeek.\n\n(b) Development component\nDevelop software as a service",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Artificial Intelligence",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0439",
    "title": "GPU computing technologies for Nvidia DGX Cloud",
    "summary": "This project will study the GPU computing technologies such as CUDA to support Nvidia DGX Cloud  for computation with large language models like OpenAI API and open-sourced ones like code llama and DeepSeek.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study the GPU computing technologies such as CUDA to support Nvidia DGX Cloud  for computation with large language models like OpenAI API and open-sourced ones like code llama and DeepSeek.\n\n(b) Development component\nDevelop a cloud software system",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Cloud Computing",
      "Artificial Intelligence",
      "High-Performance Computing",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0440",
    "title": "Next-Gen Generative Search Engine for Healthcare Applications",
    "summary": "This project aims to develop an AI-powered search engine for healthcare applications by leveraging Large Language Models (LLMs) like ChatGPT. The system will search and analyze open-source digital health resources from databases such as the WHO website and Ministry of Health portals, providing intelligent retrieval, evaluation, and recommendation of relevant healthcare applications. By integrating AI-driven chatbot capabilities, it will enhance access to critical health information for pandemic response and future healthcare challenges. Students should have strong machine learning, mathematical, and full-stack development skills (Node.js).\n\nSpecific details:\n(a) Design Component\nThe project will develop an AI-powered generative search engine for source code, integrating the Web Search API and LLMs for retrieval, evaluation, and ranking. It features a web-based frontend, an LLM-driven backend, a database for indexed code, and an evaluation engine assessing quality, security, and efficiency. Search combines keyword-based queries with semantic search using code embeddings, while ranking prioritizes readability, performance, and best practices.\n\n(b) Implementation Component\nThe system will use React.js for the frontend, Node.js with Express.js for the backend, PostgreSQL/MongoDB for storage, and Elasticsearch/FAISS for indexing. The GitHub API fetches code, and LLMs like GPT-4 or CodeBERT provide analysis. Implementation includes data collection, search engine development, AI-based evaluation, UI design, testing, and cloud deployment, improving AI-driven code discovery and assessment.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Software and Applications",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0441",
    "title": "Next-Gen Generative Search Engine for Code Base",
    "summary": "This project explores the theory and algorithm design of AI-native Large Language Models (LLMs) like ChatGPT to develop a next-generation generative search engine for source code. By leveraging the GitHub API and LLMs for automated evaluation, the system aims to enhance code discovery, analysis, and recommendation. Applications include AI-assisted software development, debugging, and optimization. Students should have strong skills in machine learning, mathematics, and full-stack development (Node.js).\n\nSpecific details:\n(a) Design Component\nThe project will develop an AI-powered generative search engine for source code, integrating the GitHub API and LLMs for retrieval, evaluation, and ranking. It features a web-based frontend, an LLM-driven backend, a database for indexed code, and an evaluation engine assessing quality, security, and efficiency. Search combines keyword-based queries with semantic search using code embeddings, while ranking prioritizes readability, performance, and best practices.\n\n(b) Implementation Component\nThe system will use React.js for the frontend, Node.js with Express.js for the backend, PostgreSQL/MongoDB for storage, and Elasticsearch/FAISS for indexing. The GitHub API fetches code, and LLMs like GPT-4 or CodeBERT provide analysis. Implementation includes data collection, search engine development, AI-based evaluation, UI design, testing, and cloud deployment, improving AI-driven code discovery and assessment.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Cloud Computing",
      "Machine Learning",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0442",
    "title": "A Simulation Platform for Auction-based Federated Learning",
    "summary": "Building a simulation platform for studying auction-based federated learning. It consists of a configurable back-end simulation system and a web-based interactive user interface, allowing end users and researchers to visualize the auction-based trading market involving data providers and data consumers and the federated learning process.  The student can explore incorporating LLM agents into the project if interested. But this is not a hard requirement.\n\nThe web-based interactive user interface shows three main tasks: 1) configuration, 2) auction market, and 3) training results. The configuration allows users to setup auctions, including setting the number of data consumers as well as data providers, setting the bidding strategies of data consumers, setting the bid price of each data consumer and so on. 2) The auction market page shows the auction result, including the winner, the winning price and so on. This page provides readers with insights into the auction process. The result page shows the training process of the federated learning paradigm.\n\nSpecific details:\n(a) Design component\nFederated auctioning mechanism\n\n(b) Implementation component\nFederated auction-based data trading platform\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Yu Han",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0443",
    "title": "AI-empowered Stock Trading Decision Support System",
    "summary": "In this project, you will work on developing an AI-empowered stock trading decision support system. You will focus on development of data visualization front end and implementing the AI-based price analysis and trading decision-making modules.\n\nSpecific details:\n(a) Design component\nData visualization interactivity design (mobile and/or PC).\n\n(b) Implementation component\nAI-based trading logics.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Yu Han",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0444",
    "title": "Fairness-Aware Federated Learning Platform Development",
    "summary": "Federated learning (FL) is a new machine learning (ML) solution for collaboratively training models across multiple edge devices (e.g., mobile phones, laptops, etc.) without sharing training data. FL reduces the possibility of personal data breaches. In FL, all the data is kept in local storage, and only model parameters are exchanged between the server and devices. In each training session, the central server selects a subset of devices and transmits the model parameters to them. Then, the selected clients train the model locally and send back the updated parameters for aggregation.   \n\nIn this project, students will develop a PC/mobile platform with a dashboard to visualize the device selection process and present the training results. This project may involve techniques like web development, android development, and socket programming. \n\nSpecific details:\n(a) Design component\nThe system architecture\n\n(b) Implementation component\nA PC/mobile platform with a dashboard to visualize the device selection process and present the training results.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Yu Han",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0445",
    "title": "Crowd-based Federated Learning Network",
    "summary": "In open collaborative federated learning (FL) taking place within a network of participants, anyone can initiate an FL model training task. Participants can either bid to join an FL task, or help refer others in their own networks. Currently, there is a lack of simulation and benchmarking tools to support research in this domain. In this research, we built Hierarchical Auctioning in Crowd-based Federated Learning (HACFL), a benchmark platform which enables simulations of FL networks with any given topology and reputation-aware hierarchical auction-based FL team formation to support research in this domain. It consists of a configurable back-end simulation system and a web-based interactive user interface, allowing end users and researchers to visualize trust-based open collaborative FL training processes. Results show that leveraging such an ecosystem of FL participants not only improves model performance, but also improves social welfare.\n\nhttps://hacfl.federated-learning.org/\n\nSpecific details:\n(a) Design component\n1.\tTo enhance the current user interface of the HACFL system which is developed using React.\n\n(b) Implementation component\n2.\tImplement various algorithms on the basis of the HACFL system using Python under the guidance of a graduate student.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Yu Han",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0446",
    "title": "Intelligent Payment System for Horizontal Federated Learning",
    "summary": "In Federated Learning, convincing different participants to form a federation is an important step. One key component to ensure this is federation can fairly calculate each participants� contribution. There exist available tools from Game theory like Shapley Value can be applied to achieve this desired fairness. However, Shapley Value requires exponential number of training procedure with regarding to all combinations of participants. The past research on accelerating the calculation been focusing on randomly sampling subset of all combinations in order to approximate the results. The problem is that the convergence rate is slowed down due to the randomness. This project aims to utilize Multi-Armed Bandit to guide the combination sampling process. Balancing between exploration and exploitation, a faster convergence rate is expected.\n\nSpecific details:\n(a) Design component\nDesign the user interaction and algorithmic engine of the prototype system under the guidance of a research fellow.\n\n(b) Implementation component\nImplement the said prototype system.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Yu Han",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Web-based Applications",
      "Human Computer Interaction",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0447",
    "title": "OZ Wizard: a Communication Tool to Empower Human Computer Interaction User Studies",
    "summary": "User study is the cornerstone of Human Computer Interaction (HCI). However, there is a pain point in engaging users in the studies because of sample size, time requirements, and monetary costs. Crowdsourcing provides a practical paradigm to engage a large number of participants for low time and monetary costs. \n\nWizard of OZ is a classic experiment approach in human computer interaction which helps the researchers to understand the users during communications. It is widely used in testing the proposed natural language dialogue systems, assessing the effectiveness of persuasive systems, and understanding ethical opinions in specific scenarios. In this method, a researcher plays the role of �Wizard� to simulate the system�s intelligence and interacts through a computer interface. He needs to input the messages under his proposed model or guideline and record the communication context manually. An automatic OZ Wizard system can solve this problem. It should contain the following functions: 1. A dashboard to collect the demographic information of the users. 2. An interface for the Wizard to communicate with the users. 3. A toolkit helps the researcher to embed his pre-designed dialogue guides and default replies. 4. An automatic dialogue record and export system.\n\nThis OZ Wizard should provide a user friendly interface for the researchers with less coding experience to change the theme or backstage communication guidelines to do their HCI experiments. You will have a chance to learn and practice HCI innovation design and artificial intelligence technique related to crowdsourcing through this project. You will receive detailed guidance and support from a PhD student who is part of this overall project.\n\nSpecific details:\n(a) Design component\nThe user interactions for the OZ Wizard software tool\n\n(b) Implementation component\nThe implementation of the OZ Wizard software tool\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Yu Han",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Artificial Intelligence",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0448",
    "title": "Next-Gen Generative Search Engine for Code Base",
    "summary": "This project explores the theory and algorithm design of AI-native Large Language Models (LLMs) like ChatGPT to develop a next-generation generative search engine for source code. By leveraging the GitHub API and LLMs for automated evaluation, the system aims to enhance code discovery, analysis, and recommendation. Applications include AI-assisted software development, debugging, and optimization. Students should have strong skills in machine learning, mathematics, and full-stack development (Node.js).\n\nSpecific details:\n(a) Design Component\nThe project will develop an AI-powered generative search engine for source code, integrating the GitHub API and LLMs for retrieval, evaluation, and ranking. It features a web-based frontend, an LLM-driven backend, a database for indexed code, and an evaluation engine assessing quality, security, and efficiency. Search combines keyword-based queries with semantic search using code embeddings, while ranking prioritizes readability, performance, and best practices.\n\n(b) Implementation Component\nThe system will use React.js for the frontend, Node.js with Express.js for the backend, PostgreSQL/MongoDB for storage, and Elasticsearch/FAISS for indexing. The GitHub API fetches code, and LLMs like GPT-4 or CodeBERT provide analysis. Implementation includes data collection, search engine development, AI-based evaluation, UI design, testing, and cloud deployment, improving AI-driven code discovery and assessment.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Cloud Computing",
      "Machine Learning",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0449",
    "title": "AI Pair Programmer Technologies with Github Copilot and Large Language Models",
    "summary": "This project will study the AI pair programming paradigm and cloud computing technologies to support Cloud-based large language models like Github Copilot and open-sourced ones like code llama.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThis project will study the pair programming paradigm technologies to support Github Copilot Cloud  for large language models like  OpenAI GPT and open-sourced ones like code llama and DeepSeek.\n\n(b) Development component\nDevelop software as a service",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cloud Computing",
      "Artificial Intelligence",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0450",
    "title": "Next-Gen Generative Search Engine for Future Internet",
    "summary": "This project aims to develop an AI-powered search engine for Internet by leveraging Large Language Models (LLMs) like Perplexity AI and SearchGPT. The system will search and analyze online resources from databases such as the current Internet, providing intelligent retrieval, evaluation, and recommendation of relevant applications. By integrating AI-driven chatbot capabilities with traditional search engine algorithms, it will lead to next-generation search engine for the Internet. Students should have strong machine learning, mathematical, and full-stack development skills (Node.js).\n\nSpecific details:\n(a) Design Component\nThe project will develop an AI-powered generative search engine for Internet, integrating the Web Search API and LLMs for retrieval, evaluation, and ranking. It features a web-based frontend, an LLM-driven backend, a database for indexed code, and an evaluation engine assessing quality, security, and efficiency. Search combines keyword-based queries with semantic search using code embeddings, while ranking prioritizes readability, performance, and best practices.\n\n(b) Implementation Component\nThe system will use React.js for the frontend, Node.js with Express.js for the backend, PostgreSQL/MongoDB for storage, and Elasticsearch/FAISS for indexing. The GitHub API fetches code, and LLMs like GPT-4 or CodeBERT provide analysis. Implementation includes data collection, search engine development, AI-based evaluation, UI design, testing, and cloud deployment, improving AI-driven code discovery and assessment.",
    "supervisor": "A/P Chee Wei Tan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Software and Applications",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0451",
    "title": "Exergame Companion",
    "summary": "This project explores how the camera of a mobile phone can be used to encourage a user to do his exercise (e.g. building up arm strength using a set of dumbbells) and monitor how well the user is compiling with the exercise routine and pace featured on the mobile screen.\n\nSpecific details:\n(a) Design component - Design the computer vision algorithm to monitor compliance to a certain exercise regime\n\n(b) Implementation component � Build a mobile application for exercise\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Goh Wooi Boon",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Smartphone Systems and Applications",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0452",
    "title": "Right Angle � A dual tablet game",
    "summary": "This project explores how two tablet computers place at right angles to each other can be used to design an engaging tablet-based game where interactive game elements and features can move smoothly and seamlessly across two different physical tablet computers.\n\nSpecific details:\n(a) Design component � A touch-based tablet game that supports real-time inter-device communication.\n\n(b) Implementation component � Build a game app that runs seamlessly over two tablet computers\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Goh Wooi Boon",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Gamification"
    ]
  },
  {
    "projectNo": "CCDS25-0453",
    "title": "Fish Counting",
    "summary": "This project investigates how numerous live and swimming fishes in a single bag filled with water can be counted accurately using a mobile phone.  This may require the user to use the smart phone camera to scan across the who bag filled with fishes and track, isolate and count the different fish swimming around and occluding each other. \n\nSpecific details:\n(a) Design component � Real-time vision algorithm to track and segment out multiple moving objects.\n\n(b) Implementation component � Build a mobile app to help count the swimming fishes.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Goh Wooi Boon",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Video/Audio/Speech Processing",
      "Smartphone Systems and Applications",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0454",
    "title": "Climate-change related disaster monitoring and visualisation",
    "summary": "This project requires the student to investigate how climate change related disasters can be automatically monitored by regularly scanning news articles on website over an ongoing basis. The disasters like flooding, drought, bush fires, etc are then visualised on a geospatial map to give users a easy way to see the effects climate change is having on various places in the world. \n\nSpecific details:\n(a) Design component � Algorithm to parse news article and detect recently occurring climate change events and their geographical localities.\n\n(b) Implementation component � A robot crawler and interactive visualisation application.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Goh Wooi Boon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Visual Computing",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0455",
    "title": "A Mobile Navigator for the Blind",
    "summary": "This project investigates how a mobile phone, with its camera, can be used to help navigate a blind user around NTU North Spine.  The camera of the phone will have to act as the eyes for the blind user. \n\nSpecific details:\n\n(a) Design component � Vision algorithms that can recognise locations and passage ways for user to navigate through.\n\n(b) Implementation component � Build a mobile app.  \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Goh Wooi Boon",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Video/Audio/Speech Processing",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0456",
    "title": "Teambuilding using a Mobile Device",
    "summary": "This project explores how a mobile device like a tablet or smartphone can be incorporated into a teambuilding activity that helps several users learn how to cooperate and work together to achieve a specified objective. The activity designed should use the mobile device to give audio-visual feedback. It should also consider using sensors on the mobile device like microphone, accelerometer, gyro, etc.  The goal is to make this team-based activity entertaining and facilitate co-located cooperation between players.  \n\nSpecific details:\n(a) Design component - Design game play\n\n(b) Implementation component � A mobile app that processes and recognises real-time sensor inputs from the mobile device and coordinates it with the game play.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Goh Wooi Boon",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Serious Games",
      "Mobile Applications",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0457",
    "title": "Using generative AI on brain functional imaging data for multimodal synthesis",
    "summary": "One exciting area of research within the intersection of AI and Neuroscience is natural scene reconstruction (i.e. from brain imaging data, generate images / video / text that the person was looking at during the brain scan). Existing works have used diffusion models to produce high resolution reconstructions and demonstrated the feasibility of such an approach. However, most of such existing works are focused on generating a single data modality from a limited brain area (e.g. only vision-related brain areas for video generation tasks). \n\nThe goal of this project is to extend these brain decoding studies to the multimodal setting, including natural scene reconstruction and semantic reconstruction of continuous language from movie watching task-fMRI data. You should be familiar with Python and deep learning libraries such as PyTorch and have prior experience training generative models. \n\nhttps://github.com/jqin4749/MindVideo\nhttps://github.com/HuthLab/semantic-decoding\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on functional MRI image processing and generative AI techniques\n\n\n(b) Development component\nStudent will develop gen AI and fMRI analysis techniques by using Python and Pytorch/Tensorflow libraries",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0458",
    "title": "Exploring the use of generative AI techniques for brain decoding in brain disorders",
    "summary": "Brain decoding involves the interpretation of neural activity patterns, with the goal of understanding how information is represented in our brains. In the context of brain disorders, such representations are likely different due to disruptions to typical brain function. \n\nTraditionally, research on brain disorders involves training machine learning models on brain imaging datasets to classify between healthy and disorder states and identify potential imaging-based biomarkers. Recently, Generative AI tools have demonstrated the potential of widening the scope of brain decoding by incorporating additional modalities such as perception information (i.e. images, video, text, audio). This involves training generative models to reconstruct information shown to the person during the brain scan (e.g. snippets of video or audio from a movie). However, most of these recent advancements are limited to scans of healthy subjects.\n\nIn this project, we aim to explore the feasibility of using generative AI techniques to elucidate disorder-specific insights from movie watching task-fMRI data. You should be familiar with Python and deep learning libraries such as PyTorch and have prior experience training generative models. \n\nhttps://github.com/littlepure2333/mindbridge\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on Gen AI techniques and functional MR brain image analysis\n\n(b) Development component\nStudent will develop necessary techniques and routines in Python using framework such as Pytorch/Tensorflow",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0459",
    "title": "Models for Privacy-preserving Image Super-resolution.",
    "summary": "Learning based models are known to be susceptible to adversarial attacks, in which adding small perturbations in the clean input image will lead a classifier to make wrong predictions. Adversarial images usually bring threats to practical deep learning applications such as autonomous driving, safety surveillance, and intelligent healthcare. However, it has positive value in privacy-preserving applications, such as the application of photo sharing in social media toward cyber security.\n\nIn this project, we will explore generative models to generate adversarial examples for Image super-resolution tasks. Generated adversarial images can attack malicious recognition systems yet preserve the information of the original low-resolution input image. Recently, diffusion models have been explored for image super-resolution tasks without considering privacy-preserving (https://openaccess.thecvf.com/content/CVPR2023/html/Gao_Implicit_Diffusion_Models_for_Continuous_Super-Resolution_CVPR_2023_paper.html), and in this project, we will explore new methods to preserve privacy for image super-resolution.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n-to explore relevant existing models\n\n-to develop generative models for adversarial examples for Image super-resolution\n\n(b) Development component\n\n-to implement relevant existing models\n\n-to benchmark the proposed method",
    "supervisor": "Prof Lin Weisi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Video/Audio/Speech Processing",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0460",
    "title": "Resource- and Energy-efficient Deep Learning Models for 3D Data Analysis",
    "summary": "Deep learning with 3D data is vital for a wide range of emerging applications such as autonomous driving, robot perception, VR/AR, UAV inspection, and 3D metrology. However, due to the unique characteristics of 3D data, as well as the hard constraints from real-world applications, the research and adoption of 3D deep learning are currently facing many technical challenges such as high storage &amp; computation costs, high power consumption, high latency, etc. This proposal aims to develop fundamental 3D deep learning data analysis techniques, specifically developing resource-efficient and energy-efficient 3D deep learning models to tackle the challenges occurred in current 3D models, such as huge memory &amp; computation costs and huge power consumption, to make 3D deep learning more realistic for real-world applications. \n\nObjective: The primary goal of this research is to design novel compression algorithms (quantization, pruning, entropy coding, etc.) for state-of-the-art 3D deep learning models. The proposed approach should be able to significantly reduce the size of 3D models, reduce the computation operations, and lower the power consumption, without hurting the accuracy. The proposed method will be evaluated on mainstream 3D detection models (Voxel-RCNN, F-PointNet) at public benchmark datasets (Kitti, Nuscene). \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nData Collection and Preprocessing: Gather and preprocess a tiny dataset for ablation study. Explore techniques for data reduction, quantization, and feature engineering to minimize data requirements.\n\nFinetuning: Finetune (retrain) compressed models using a tiny dataset (or even without using any data). Finetune the models to achieve high accuracy while using as less training data as possible.\n\n(b) Development component\n\nLiterature Review: Conduct a comprehensive review of 3D data analysis models (3D detection models, 3D point clouds, etc.) and model compression techniques (post-train quantization, structured pruning, etc.). Identify relevant methodologies and best practices for designing compression algorithm for 3D models.\n\nBenchmarking and Evaluation: Conduct rigorous benchmarking and evaluation of the accuracy of compressed models after finetuning. Report the results on standard public datasets and compare with state-of-the-arts",
    "supervisor": "Prof Lin Weisi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Visual Computing",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0461",
    "title": "Video quality assessment (VQA) modelling",
    "summary": "Recently, there has been tremendous growth in social media with a huge amount of videos being created and shared on media platforms such as YouTube, Facebook, and TikTok. It has been estimated that there are over 4 billion video views per day on Facebook and above 500 hours of videos uploaded per minute on YouTube. However, these videos may have low quality due to some factors such as motion blur, noise, distortion, focus issues, and shakiness. It would be of great value in studying video quality assessment (VQA) that predicts the perceived quality of the video as humans do, which could be used to eliminate low-quality videos or improve them during the acquisition and enhancement process. Due to the highly redundant nature of video content, proper feature extraction will speed up the VQA while maintaining accuracy. In addition, learning based on important features will also help to further improve the accuracy of a VQA model. VQA is a challenging task that requires a multidisciplinary approach and ongoing research and development to address the challenges and to provide effective solutions for evaluating video quality.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDue to the highly redundant nature of video content, proper feature extraction will speed up the VQA while maintaining accuracy. In addition, learning based on important features will also help to further improve the accuracy of a VQA model. VQA is a challenging task that requires a multidisciplinary approach and ongoing research and development to address the challenges and to provide effective solutions for evaluating video quality.\n\n(b) Development component\n\nimplementation of existing algorithms for benchmarking.",
    "supervisor": "Prof Lin Weisi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0462",
    "title": "Perceptual Image Quality Assessment for Generative Images",
    "summary": "Traditional Image Quality Assessment (IQA) metrics were developed to quantitatively evaluating the image degradation caused by restoring, transformation or enhancing algorithms. Recently, the generative models such as Generative Adversarial Networks (GANs) and Diffusion Models have generated images with impressive results, but not all the generated results are good enough from human perceptual point of view.  A few quantitative metrics based on distribution statistics such as Freshet Inception Distance (FID) have recently been proposed to evaluate the image quality for generative images. How to quantitatively evaluate the Perceptual Image Quality of a single generated image is a still open question. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nthis project aims to explore the latest research ideas and designing quantitative Image Quality Assessment metrics to evaluate the images generated by generative models, such as GANs and Diffusion Models. \n\n(b) Development component\n\nStudents will adopt/implement existing relevant techniques to evaluate the image quality generated from generative models including but not limited to GANs and Diffusion Models.",
    "supervisor": "Prof Lin Weisi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0463",
    "title": "3D Point Cloud  Augmentation for Quality Assessment Modelling",
    "summary": "3D data analysis, the accuracy and reliability of quality assessments for both point cloud and mesh data are significant. Our investigation aims to demonstrate how augmentation techniques, ranging from transformations like rotations and translations to noise injections and synthetic data synthesis, can significantly enhance the quality assessment process. Augmentation not only amplifies dataset size but also introduces essential variations, empowering quality assessment models to better adapt to real-world scenarios and anomalies. This proposal outlines a comprehensive strategy for researching and harnessing the power of 3D data augmentation, tailored to both point cloud and mesh data. We will delve into the augmentation techniques, considering the unique attributes of each data type. Additionally, we will explore effective strategies for selecting and fine-tuning augmentations, accounting for the specific requirements and challenges of quality assessment tasks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nTo test a  strategy for researching and harnessing the power of 3D data augmentation\n\nTo delve into the augmentation techniques, considering the unique attributes of each data type\n\n(b) Development component\n\nTo investigate the existing datasets of 3D point cloud and 3D mesh, and implement and benchmark the relevant existing methods",
    "supervisor": "Prof Lin Weisi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "High-Performance Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0464",
    "title": "Text-Guided Generative Models for Facial Image Privacy Protection",
    "summary": "Deep learning models are known to be susceptible to adversarial attacks, in which adding small perturbations in the clean input image will lead a classifier to make wrong prediction. Adversarial images usually bring threats to practical deep learning applications such as autonomous driving, safety surveillance, and intelligent healthcare. However, it has positive value in privacy-preserving applications, such as the application of face photo sharing in social media toward cyber security. In this project, we will explore generative models to generate adversarial examples by considering the text prompts to guide the model to generate the desired style in the generation process. Generated adversarial images can attack malicious face recognition systems yet preserve the information of the original input image.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nthis project aims to explore the latest research ideas and design text-guided generative models (e.g., stable diffusion) to protect the privacy of facial images.\n\n(b) Development component\n\nstudents will adopt/implement relevant advanced techniques to generate privacy-preserving face images using generative models including but not being limited to GANs and Diffusion Models.",
    "supervisor": "Prof Lin Weisi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0465",
    "title": "Balanced Chain-of-Thought Distillation",
    "summary": "Chain-of-Thought (CoT) methodologies enhance interpretability and reasoning depth in neural network models by exposing intermediate inference steps. However, CoT output often increases inference latency and resource consumption�an issue especially critical in data science applications that demand scalable, real-time analytics. This proposal presents a research plan to develop and evaluate an adaptive CoT distillation framework, enabling models to dynamically adjust the length and granularity of their reasoning steps. We aim to minimize computational overhead while retaining high-level interpretability.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDynamic CoT Generation and Metrics;\n\nReinforcement Learning for Adaptive Distillation\n\n(b) Development component\n\nIntegration and Evaluation",
    "supervisor": "Prof Lin Weisi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Security",
      "Visual Computing",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0466",
    "title": "Applications of Continuous-Time Neural Networks (1)",
    "summary": "This project will explore one application of continuous-time neural networks (CT-NNs). Recently, the design of closed-form continuous-time neural network makes CT-NNs more practical for real-world applications. Our group has prior research on CT-NNs and the FYP candidate on this project will use our codebase to explore a new application.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nIdentify a new application case.\n\n(b) Development component\n\nDevelop the code for the identified application.",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0467",
    "title": "Applications of Continuous-Time Neural Networks (2)",
    "summary": "This project will explore one application of continuous-time neural networks (CT-NNs). Recently, the design of closed-form continuous-time neural network makes CT-NNs more practical for real-world applications. Our group has prior research on CT-NNs and the FYP candidate on this project will use our codebase to explore a new application.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nIdentify a new application of CT-NNs.\n\n(b) Development component\n\nDevelop code for the identified application.",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0468",
    "title": "Build a Scalable Neural Model with Neural ODEs (1)",
    "summary": "A recent work developed a practical continuous-time neural network (https://www.nature.com/articles/s42256-022-00556-7). A later work built a foundation model (https://aimresearch.co/market-industry/from-worm-brains-to-a-2-billion-ai-unicorn-liquid-ai-defies-conventional-ai-limits). This FYP will study this topic and try to reproduce the foundation model. This FYP will also collaborate with another FYP to build foundation models based on neural stochastic differential equation networks.\n\nThis project requires a relatively high math knowledge and stills.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nUnderstand how the foundation model based on neural ODE works.\n\n(b) Development component\n\nDevelop the code.",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0469",
    "title": "Build a Scalable Neural Model with Neural ODEs (2)",
    "summary": "A recent work developed a practical continuous-time neural network (https://www.nature.com/articles/s42256-022-00556-7). A later work built a foundation model (https://aimresearch.co/market-industry/from-worm-brains-to-a-2-billion-ai-unicorn-liquid-ai-defies-conventional-ai-limits). This FYP will study this topic and try to reproduce the foundation model. This FYP will also collaborate with another FYP to build foundation models based on neural stochastic differential equation networks.\n\nThis project requires a relatively high math knowledge and stills.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nUnderstand how the foundation model based on neural ODE works.\n\n(b) Development component\n\nDevelop the code.",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0470",
    "title": "Comparison between adversarial examples against LiDAR-based and mmWave radar-based object detection",
    "summary": "LiDAR and mmWave radar have been increasingly adopted by autonomous vehicles. Deep neural networks are often used to process LiDAR and mmWave radar data in the form of point clouds to detect objects. However, these deep neural networks are known vulnerable to adversarial perturbations. This project will compare the susceptibility of the neural networks for processing LiDAR and mmWave radar data, in the presence of object-based perturbations.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nStudy of susceptibility of neural networks to object-based perturbations.\n\n(b) Development component",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0471",
    "title": "Adversarial perturbations against stereo depth estimation",
    "summary": "Stereo depth estimation uses multiple cameras to estimate the depth information of each pixel in the images captured by the cameras. This project will learn the prevailing stereo depth estimation algorithms, with a focus on the deep learning-based ones. In addition, the project will study how to introduce adversarial perturbations to the images captured by the cameras to mislead the depth estimation.\n\nThis project requires more independent investigation by a capable student.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nAdversarial perturbations to mislead stereo depth estimation\n\n(b) Development component",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0472",
    "title": "Small model versus large model in time series prediction",
    "summary": "There are two ongoing streams of research in time series prediction -- small model and large foundation model. Our recent research (https://tanrui.github.io/pub/FedCFC.pdf) shows that small model can be efficient. This project will perform extensive study and comparison on small model and large model on time series prediction. Code bases for both are available:\n1. Latest small model: https://github.com/raminmh/CfC\n\n2. Latest Google's large foundation model: https://github.com/google-research/timesfm\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nExtensive comparison of small and large models\n\n(b) Development component",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0473",
    "title": "Impact of sensor-induced domain shifts on large models for automated speech recognition",
    "summary": "Recent research (https://arxiv.org/pdf/2104.01160.pdf) developed physics-guided data argumentation approach to address sensor-induced domain shifts in speech recognition tasks. More recently, large models for speech recognition are available, such as OpenAI's whisper model (https://github.com/openai/whisper). This project will study whether the problem of sensor-induced domain shifts still exists for large models. It will also study how to mitigate the impacts in the context of large models.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nStudy the impact\n\n(b) Development component\n\nDevelop new approaches to mitigate the impact",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0474",
    "title": "Federated Deep Learning for Edge Computing and Its Carbon Emission Analysis",
    "summary": "Federated learning receives increasing research attention and has been adopted by Google's product. This collaborative learning approach enables many parties to build a common machine learning model together and also respect each party's privacy in that each party doesn't need to upload the training data. In this project, we will investigate the computation and communication overhead of federated learning on edge computing platforms such as Nvidia's Jetson and Google's EdgeTPU.  A life-cycle carbon analysis will be conducted as well.\n\nSpecific details:\n(a) Design component\n\nDesign of a federated learning system for an example application.\n\n\n(b) Implementation component\n\nImplement a simple prototype.\n\n(a) Research component\n\nPerform measurements on the computation and communication overhead.\n\n(b) Development component\n\nNone.",
    "supervisor": "A/P Tan Rui",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Sensor Networks",
      "Ubiquitous/ Pervasive Computing",
      "Computer Networks",
      "Information Retrieval/ Processing",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0475",
    "title": "Performance Enhancements for a Web-based Automated Programming Grading System",
    "summary": "This project aims to develop techniques for enhancing the performance of a Web-based system for automated programming grading (APAS), which was developed in CCDS. APAS is currently running as a tool for students for submitting programming assignments with automatic grading. Currently, the APAS system encounters a few technical issues including security, database, and performance bottlenecks when supporting multiple users online. Therefore, this project aims to looking into implementation techniques to enhance the performance of the APAS system. The student is required to work on system implementation using Python and Django.\n\nSpecific details:\n(a) Design component\nThere are mainly three issues to look at: (1) security - a sandbox environment should be investigated for protecting the system from hacking; (2) database - a more effective databases architecture should be investigated to replace the current small DBMS system; (3) performance - techniques to improve the current system to support multiple users should be investigated.\n\n(b) Implementation component\nThe student will need to investigate the techniques based on the three technical issues discussed in the design. Performance of the enhanced system will be evaluated with performance results.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Database Systems",
      "System Security",
      "Computer Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0476",
    "title": "Building a Food Recognition and Classification Model to Count Calories",
    "summary": "This project uses computer vision to enable individuals to track and manage their diets effectively. This image classification system uses deep neural network to estimate calories in food through image processing. An image of food serves as the model's input. The food calorie value is calculated using the proposed Convolutional Neural Networks algorithm. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0477",
    "title": "Detecting Fake Online Reviews",
    "summary": "This project looks at detecting fake online reviews. More and more customers� purchasing decisions are based on the reviews of the product. Consequently, online sellers are faking reviews to gain more profits. Fake reviews detection poses significant challenges in the e-commerce platforms, consequently eroding consumer trust. The objective of this project is to build a fake review detection system.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0478",
    "title": "Friendly Chatbot for Senior Companion",
    "summary": "This project looks at building a friendly chatbot to communicate with seniors. The chatbot provides easy access to health information, reminders, and social engagement. The objective of the project is to build a chatbot using natural language processing (NLP) to understand and respond to user inquiries in a conversational manner\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0479",
    "title": "Building an Emotion-based Music Recommender System",
    "summary": "This project looks at the development of a recommendation system. Music creates a unique emotional bond with people. An emotional-based recommender system enables individuals to create their personalized playlists based on their emotional status, thus promoting relaxation and mental well-being.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0480",
    "title": "Defending Against Phishing Attacks",
    "summary": "This project investigates the use of classification algorithms to identify phishing websites. Phishing is known as an online fraud and is a major threat on the internet. Victims are re-directed to fraudulent websites which mimic legitimate websites. Scammers use social engineering techniques to perform phishing attacks to steal people�s personal and financial information. This objective of this project is to build classifiers to determine whether a website is legitimate or fraudulent. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review is needed to analyze independent factors.  \nMachine learning algorithms are used as Research Methods\n\n(b) Development component\nThe study's findings can be used to explore or examine the major gaps for future research.",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cyber Security",
      "Data Mining",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0481",
    "title": "Building Detection Techniques to Identify Deepfakes",
    "summary": "This project looks at deepfakes detection using machine learning algorithms. There is a growing concern of deepfake contents which are becoming more accessible and sophisticated. The objective of this project is to build classifiers for deepfakes identification.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review is needed to analyze independent factors.  \nMachine learning algorithms are used as Research Methods\n\n(b) Development component\n\nThe study's findings can be used to explore or examine the major gaps for future research.",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0482",
    "title": "Clustering Analysis and Visualization for Biomedical Databases",
    "summary": "This project aims to investigate different clustering analysis techniques (e.g. hierarchical clustering) for a biomedical database (pathogen data) and develop a user interface to visualize the biomedical data in the clusters. Pathogen database contains biomedical data on isolates that causes diseases. Clustering methods such as Agglomerative Hierarchical Clustering, k-means, etc. will be investigated, and implemented to support the biomedical database. In addition, the student is also required to implement a visualization technique to display the clustered data. Python is used for the implementation of the proposed work.\n\nSpecific details:\n(a) Design component\nThe student is required to investigate different clustering techniques to visualize the biomedical database. Techniques such as AHC, DBSCAN, k-means could be investigated and study their suitability for the biomedical database. Open source visualization tools should be investigated for implementing the proposed work.\n\n(b) Implementation component\nThe student will implement the techniques for the proposed work and evaluate the performance of the proposed work. The programming language for this project is Python.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Bioinformatics",
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0483",
    "title": "Building a Fake News Detection Classifier",
    "summary": "The objective of this project is to build a classifier that can distinguish between real and fake news articles. Fake news has become a significant issue, spreading misinformation across social media and news platforms. The classifier can accurately identify fake news articles by applying various classification algorithms. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review is needed .\n\n(b) Development component\nThe study's findings can be used to explore or examine the major gaps for future research.",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0484",
    "title": "QR Code Scam Detection System",
    "summary": "This project focuses on developing a system to detect and prevent QR code-based scams. QR codes are often used in various applications such as payments and promotions, but they can sometimes lead to phishing websites designed to steal personal information. The objective  of this project is to scan QR codes and extract the embedded URLs to check whether the links are safe or potentially harmful. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review is needed. Machine learning algorithms are used as Research Methods\n\n(b) Development component\nThe study's findings can be used to explore or examine the major gaps for future research.",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0486",
    "title": "Predictive Model for Temperature and Rainfall Prediction",
    "summary": "This project aims to predict the future trends of climate change by analyzing historical weather data, including temperature, rainfall, and humidity. The objective of the project is to build a predictive model that forecasts key climate factors, such as temperature rise and rainfall patterns, and helps to assess potential impacts on various sectors like agriculture, energy consumption, and air quality.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review is needed. Machine learning algorithms are used as Research Methods\n\n(b) Development component\nThe study's findings can be used to explore or examine the major gaps for future research.",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0487",
    "title": "Basic Sentiment Analysis Dashboard for Mental Health on Social Media",
    "summary": "This objective of this project is to create a real-time sentiment analysis dashboard that monitors social media posts related to mental health. The dashboard can track how users are discussing mental health topics on social media platforms and analyze their sentiments to better understand public opinion and emotional trends.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nLiterature Review is needed. Machine learning algorithms are used as Research Methods\n\n(b) Development component\nThe study's findings can be used to explore or examine the major gaps for future research.",
    "supervisor": "Dr Josephine Chong Leng Leng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0488",
    "title": "Cattle face recognition",
    "summary": "Traditionally, RFID tags have been used for cattle recognition. However, problems associated with it include the limited recognition distance, collisions, and the existence of\ntag duplication, forgery and loss. With advances in computer vision, non-invasive techniques such as recognizing cattle from videos has gained traction. In this project, we explore a neural network approach to cattle recognition. In particular, we aim to design CNNs for applications in low-power devices so that they can be deployed in the field.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading a research paper on cattle face recognition and implementing the CNN described in the paper with the objective of replicating the results obtained in the paper. The second part will involve suggesting modifications to the architecture to improve results. Code can be implemented using Pytorch.\n\n(b) Development component\nWrite programme to implement the architecture of the CNN described in the research paper and then implement the modifications suggested to improve results.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0489",
    "title": "Superpixel generation",
    "summary": "Superpixel segmentation groups pixels with similar features and\nreplaces the pixel grid in an image. It is usually used as a\npreprocessing step in many computer vision tasks, such as image\nclassification. There have been several methods for super pixel generation.  This project will explore one particular method which involves clustering pixels and defining a distance between a pixel and a super pixel seed. It builds on other existing clustering methods such as DBSCAN and SCBP.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading a research paper on superpixel generation and implement the algorithm described therein in order to replicate the results of the paper. The second part of the project will involve suggesting modifications to the algorithm in order to improve the performance of superpixel generation.\n\n(b) Development component\nSee above.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0490",
    "title": "Ship recognition in SAR images",
    "summary": "Ship detection is often used in ocean monitoring and military surveillance.  Deep learning solutions for ship detection often suffer from the problems of complex scenarios, large \nobject scale differences and imperfect fine-grained classification. In this project, we explore a YOLO based deep learning method that tries to overcome the above problems. Furthermore, the objective is to design a lightweight architecture that can be deployed on edge devices instead of needing several GPUs to process the data.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading a research paper on ship detection and implementing the deep learning architecture described in order to replicate the results of the paper. The second part of the project will involve suggesting modifications to the architecture to improve the results.\n\n(b) Development component\nSee above.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0491",
    "title": "Lightweight Deep Learning for Portrait Segmentation",
    "summary": "Portrait segmentation is commonly used in real-world applications such as background editing, security checks, and face resolution enhancement, giving rise to the need for fast and robust segmentation models. In this project, we will explore a lightweight deep learning architecture for portrait segmentation. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading and understanding a research paper that discuss a lightweight architecture for portrait segmentation. Further, you are expected to implement the architecture in Pytorch in order to replicate the results in the paper. The second part of the project involves suggesting modifications to the architecture so that improved results can be obtained.\n\n(b) Development component\nSee above.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0492",
    "title": "Lightweight deep learning for face recognition",
    "summary": "The development of deep learning-based biometric models that can be deployed on devices with constrained memory and computational resources has proven to be a significant challenge.  The introduction of Ghost modules represents a major innovation in the area of feature map redunancy. Ghost modules use a series of inexpensive linear transformations to extract additional feature maps from a set of intrinsic features, allowing for a more comprehensive representation of the underlying information. In this project, we will implement GhostFaceNets for face recognition.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading and understanding a research paper on   lightweight face recognition    and implementing the architecture described therein in order to replicate the results of the paper. The second part of the project will involve suggesting modifications to the architecture and implementing those modifications to check if there is an improvement in the results.\n\n(b) Development component\nSee above.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0493",
    "title": "Extraction of Pathogen Assay Information from Biomedical Literatures using LLMs",
    "summary": "This project aims to extract pathogen information from biomedical (PubMed) literatures. The extraction process mainly consists of two main processes, namely automated web scraping and information extraction. The automated web scraping process involves downloading both the contents of scientific articles at scheduled intervals (e.g., weekly, bi-weekly, monthly, etc.). Then, the relevant scientific articles which contain information on related pathogens of interest (e.g., E. Coli, Salmonella, and Campylobacter) are filtered. The semi-structured texts from the articles (e.g., abstract, main body, tables, etc.) and structured texts from the metadata are extracted as �raw� data for processing. This information extraction process extracts pathogen assay information from the textual contents of the scientific literature. This involves extracting specific terms for a set of specialized microbiology categories (i.e., MLST, MIC (in SIR), Plasmid, Resistance Genes, SPI, Virulence Genes, and SNP info), from the semi-structured contents including free-formed texts (sentences), and tables.  In this project, Large Language Models such as ChatGPT will be investigated for the extraction. Typical techniques such as Chain of Thought (COT) and Retrieval Augmented Generation (RAG) will be investigated for the extraction.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nAdvance AI techniques such as Large Language Models (LLMs) or Pre-trained Language Models PLMs) for the assay information extraction will be investigated to acquire the attributes from the scientific literature to construct the pathogen profiles. \n\n(b) Development component\nThe student will implement the techniques such as COI and RAG with different LLMs and conduct performance evaluation based on biomedical literatures. Python is used for the development work.",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0494",
    "title": "Information Retrieval and Visualization for a Web-based Pathogen Tracking System",
    "summary": "This project aims to develop retrieval techniques for retrieving information from a pathogen tracking system. A pathogen database is generated from downloading the contents of scientific articles at scheduled intervals (e.g., weekly, bi-weekly, monthly, etc.). Then, the relevant scientific articles which contain information on related pathogens of interest (e.g., E. Coli, Salmonella, and Campylobacter) are filtered and extracted. Then, the extracted pathogen assay information and meta-data are stored in a pathogen database.  Assay information includes a set of specialized microbiology categories (i.e., MLST, MIC (in SIR), Plasmid, Resistance Genes, SPI, Virulence Genes, and SNP info) and meta-data information includes Isolate ID, Isolation date, Host, Geographical location, Latitude, Longitude, Taxonomy, Genus, Serovar, Subspecies, Host Healthy State, Bio-project, Sample Accession, Run Accession, PubMed ID and Organization Name.  In this project, we aim to develop retrieval techniques for knowledge discovery from the pathogen database under different criteria, and the visualization of the retrieved data.\n\nSpecific details:\n(a) Design component\nIn this project, the student will investigate the development of retrieval techniques and visualization techniques for knowledge discovery for a pathogen database curated from biomedical literatures.\n\n(b) Implementation component\nThe student is required to implement the proposed methods and conduct performance evaluation of the techniques. We will use Django and Python for the development of the system.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Bioinformatics",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0495",
    "title": "Extraction of Pathogen Meta-Data Information from Biomedical Literatures using LLMs",
    "summary": "This project aims to extract pathogen meta-data information from biomedical (PubMed) literatures. The extraction process mainly consists of two main processes, namely automated web scraping and information extraction. The automated web scraping process involves downloading both the contents of scientific articles at scheduled intervals (e.g., weekly, bi-weekly, monthly, etc.). Then, the relevant scientific articles which contain information on related pathogens of interest (e.g., E. Coli, Salmonella, and Campylobacter) are filtered. The semi-structured texts from the articles (e.g., abstract, main body, tables, etc.) and structured texts from the metadata are extracted as �raw� data for processing. The meta-data information extraction process extracts the supplementary information from the corresponding meta-data (i.e., Isolate ID, Isolation date, Host, Geographical location, Latitude, Longitude, Taxonomy, Genus, Serovar, Subspecies, Host Healthy State, Bio-project, Sample Accession, Run Accession, PubMed ID and Organization Name). In this project, Large Language Models such as ChatGPT will be investigated for the extraction. Typical techniques such as Chain of Thought (COT) and Retrieval Augmented Generation (RAG) will be investigated for the extraction.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nAdvance AI techniques such as Large Language Models (LLMs) or Pre-trained Language Models PLMs) for the meta-data information extraction will be investigated to acquire the attributes from the scientific literature to construct the pathogen profiles. \n\n(b) Development component\nThe student will implement the techniques such as COI and RAG with different LLMs and conduct performance evaluation based on biomedical literatures. Python is used for the development work.",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0496",
    "title": "Urgency Classification from Customer Feedback using LLMs",
    "summary": "Singapore Food Agency (SFA) receives hundreds of\nfeedback reports regarding Singapore�s food safety every week, which can be time-consuming and costly to manage them. In addition, prompt response to urgent feedback is crucial in cases of food poisoning outbreaks. Automating the task of urgency classification can help SFA officers to prioritise feedback efficiently and effectively, so that they can respond quickly to urgent cases. In this project, we investigate Large Language Models (LLMs) for the task of urgency classification from feedback reports. In addition, we will also investigate a system architecture to automate the annotation of unlabelled user feedback data, using a mix of Zero-shot Text Classification, Rule-based Approaches and Decision Trees. Pretrained language models such as BERT model and LLMs such as ChatGPT will be investigated. \n\nSpecific details:\n(a) Design component\nThe student will investigate LLMs for the urgency classification task. Pre-trained language models such as BERT and LLMs such as ChatGPT will be investigated for the task.\n\n(b) Implementation component\nThe student is required to implement the proposed technique, evaluate the performance based on the dataset and incorporate the proposed techniques into a Web-based system. The web-based system will be developed based on Django and Python.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0497",
    "title": "Detection of Food Safety Events from News Articles using LLMs",
    "summary": "Nowadays more and more foodborne disease cases happening around the world and there are tons of news articles reporting them. Event detection techniques\ncan help food data researchers automatically extract useful information and filter out negative news. This can improve the efficiency of research by reducing the amount of time spent on manually reviewing data. In this project, we will investigate event detection methods for food safety from news articles  and  predict the type of event occurred in each news article. This will help us to better understand potential food safety risks and take steps to mitigate them so that we would constantly monitor food safety news to give food alerts. In particular, we investigate Large Language Models (LLMs) models for food safety event detection from news articles. Additionally, based on the best model and configuration, a web-based UI system will be implemented to demonstrate how the proposed event extraction model is used in a practical environment.\n\nSpecific details:\n(a) Design component\nThe student will investigate PLMs (such as BERT) and LLMs (such as ChatGPT) for food safety events from news articles. \n\n(b) Implementation component\nThe proposed methods will be implemented and evaluated based on a dataset collected from news articles. The proposed techniques will also be incorporated into a web-based system for demonstration.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0498",
    "title": "Monitoring Customer Feedback for Food Safety using LLMs",
    "summary": "The customer feedback dataset usually contains a collection of customer feedback reports. With hundreds of feedback reports received on a weekly basis, it becomes challenging for the users to manually curate and classify the urgency of these reports, which can lead to delayed operational response. To alleviate manual efforts and improve the scalability for customer feedback monitoring, this project aims to automate the extraction of important attributes from the feedback textual description using Large Language Models (LLMs). The customer feedback data will be based on incident reports on food safety from customers. The extracted\nfeedback attributes include Number of people affected, Name of symptoms, Frequency of symptoms, Are there any one hospitalized?, Are there anyone admitted to ICU?. \nIn addition, the student is also required to develop a web-based system for food safety feedback monitoring based on the customer feedback reports. \n\nSpecific details:\n(a) Design component\nThe student will design the attribute extraction techniques using LLMs such as ChatGPT. NLP techniques will also be needed to preprocess the customer feedback dataset before attribute extraction. In addition, a monitoring system should also be developed to demonstrate the proposed techniques.\n\n(b) Implementation component\nThe student should implement the proposed techniques and evaluate the performance accordingly. The system will be implemented using Django and Python.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Hui Siu Cheung",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0499",
    "title": "Lightweight Deep Learning for Pose Estimation",
    "summary": "Multi-person pose estimation is an important task and may be used in different domains, such as action recognition, motion capture, sports, etc. The task is to predict a pose skeleton for every person in an image. The skeleton consists of keypoints (or joints, e.g., ankles, knees, hips, elbows, etc. The objective of this project is to explore lightweight deep learning methods or pose estimation that can be run on CPUs instead of more  compute heavy architectures that need GPUs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading and understanding a research paper on  lightweight pose estimation      and implementing the architecture described therein in order to replicate the results of the paper. The second part of the project will involve suggesting modifications to the architecture and implementing those modifications to check if there is an improvement in the results. The implementation can be in Pytorch.\n\n(b) Development component\nSee above",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0500",
    "title": "Lightweight Deep Learning for Generating Super-resolution  Images (1)",
    "summary": "Super-resolution means generating high resolution images from multiple low resolution images. Recently, there have been attempts to generate super resolution images from a single image. In this project, we will explore how lightweight deep learning architectures can be used for super-resolution. With the widespread use of mobile phones for taking and retouching photos, there is a need for such lightweight architectures for the deployment of DL-SR models on mobile devices.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading and understanding a research paper on   super resolution generation using lightweight architectures and implementing the architecture described therein in order to replicate the results of the paper. The second part of the project will involve suggesting modifications to the architecture and implementing those modifications to check if there is an improvement in the results. The implementation can be done in Pytorch.\n\n(b) Development component\nSee above\nSee above.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0501",
    "title": "Lightweight Deep Learning for Generating Super-resolution  Images (2)",
    "summary": "Super-resolution means generating high resolution images from multiple low resolution images. Recently, there have been attempts to generate super resolution images from a single image. In this project, we will explore how lightweight deep learning architectures can be used for super-resolution. With the widespread use of mobile phones for taking and retouching photos, there is a need for such lightweight architectures for the deployment of DL-SR models on mobile devices.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading and understanding a research paper on   super resolution generation using lightweight architectures and implementing the architecture described therein in order to replicate the results of the paper. The second part of the project will involve suggesting modifications to the architecture and implementing those modifications to check if there is an improvement in the results. The implementation can be done in Pytorch.\n\n(b) Development component\nSee above\nSee above.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0502",
    "title": "Multimodal sensor fusion for object detection in adverse weather",
    "summary": "The fusion of multimodal sensor streams, such as cam-\nera, lidar, and radar measurements, plays a critical role in\nobject detection for autonomous vehicles, which base their\ndecision making on these inputs. While existing methods, and the autonomous systems that perform decision making on their outputs perform well under normal imaging conditions, they fail in adverse weather and imaging conditions. This is because existing training datasets are biased towards clear weather conditions, and detector architectures are designed to rely only on the redundant information in the undistorted sensory streams.  In this project, we will explore lightweight deep learning architectures  for sensor fusion for object recognition in the presence of fog.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe first part of the project will involve reading and understanding a research paper on  lightweight deep learning architecture for object recognition under foggy conditions,      and implementing the architecture described therein in order to replicate the results of the paper. The second part of the project will involve suggesting modifications to the architecture and implementing those modifications to check if there is an improvement in the results. The implementation can be done in Pytorch.\n\n(b) Development component\nSee above",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0504",
    "title": "Single cell foundation models for cell-cell interaction prediction",
    "summary": "Recent advances in single cell and spatial transcriptomics technologies have made it possible to study how individual cells interact with each other in complex tissues, such as tumours. Understanding these cell-cell interactions (CCI) is essential for uncovering disease mechanisms and developing new treatments. This project aims to investigate the use of foundation models trained on large-scale single-cell data to improve the prediction of CCIs.\nStudents will work with pretrained single-cell foundation models such as GeneFormer and NicheFormer, adapting them to predict CCIs using gene expression and spatial context from a publicly available mouse brain dataset. The project involves using PyTorch and related Python libraries to fine-tune these models for interaction prediction between different cell types. This project is ideal for students interested in applying LLM concepts outside of text and language, especially in the fast-growing field of computational biology.\n\nReferences\nGeneFormer - https://www.biorxiv.org/content/10.1101/2024.08.16.608180v1\nNicheFormer - https://github.com/theislab/nicheformer\nMouse brain dataset - https://www.nature.com/articles/s41586-023-06808-9\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on foundation models and cell-cell interactions on tissues\n\n(b) Development component\nStudent will develop necessary techniques in Python and Pytorch",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0505",
    "title": "Graph diffusion models for cell-cell interaction prediction",
    "summary": "Cell-cell interactions (CCI) play a key role in understanding the function and organization of tissues, particularly in complex systems like the brain. With the rise of spatial transcriptomics data, it has become possible to represent cells as nodes in a graph, where edges capture spatial or functional relationships. This project explores the use of graph diffusion models to learn node embeddings that better represent the biological and spatial context of each cell, with the goal of improving CCI prediction.\n\nStudents will develop graph diffusion models on a high resolution mouse brain spatial transcriptomics dataset. The project involves constructing cell graphs from spatial and gene expression data, implementing or adapting diffusion-based models using PyTorch Geometric, and training classifiers to predict interactions between cells. This project is ideal for students interested in graph machine learning and its applications in biology.\n\nReferences\nntkien1904/DMNS: Diffusion-based Negative Sampling on Graphs for Link Prediction\nDiffusion Improves Graph Learning\nMouse brain dataset - Molecularly defined and spatially resolved cell atlas of the whole mouse brain | Nature\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on graph diffusion models and cell-cell interactions in tissues\n\n(b) Development component\nStudent will develop techniques and routines in Python using  Pytorch libraries",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computational Biology",
      "Machine Learning",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0506",
    "title": "Tries and Patricia Tries and Applications (1)",
    "summary": "When you type a few words in google search, you are shown a list of longer phrases that extend from what you have typed.  How is this done?  In this project, we study the data structures Tries and Patricia Tries, implement them and examine their applications.  \n\nSpecific details:\n(a) Design component\nDesign the data structures in an application\n\n(b) Implementation component\nImplement the data structures and operations to manipulate them\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0507",
    "title": "Tries and Patricia Tries and Applications (2)",
    "summary": "When you type a few words in google search, you are shown a list of longer phrases that extend from what you have typed.  How is this done?  In this project, we study the data structures Tries and Patricia Tries, implement them and examine their applications.  \n\nSpecific details:\n(a) Design component\nDesign the data structures in an application\n\n(b) Implementation component\nImplement the data structures and operations to manipulate them\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0508",
    "title": "Suffix Trees and Applications (1)",
    "summary": "Cancers often have repeated copies of the same genes.  Given a cancer genome, how do we find the longest repeated DNA sequence?  In this project, we study the data structure Suffix Trees, implement them and examine their applications.  \n\nSpecific details:\n(a) Design component\nDesign the data structures in an application\n\n(b) Implementation component\nImplement the data structures and operations to manipulate them\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0509",
    "title": "Suffix Trees and Applications (2)",
    "summary": "Cancers often have repeated copies of the same genes.  Given a cancer genome, how do we find the longest repeated DNA sequence?  In this project, we study the data structure Suffix Trees, implement them and examine their applications.  \n\nSpecific details:\n(a) Design component\nDesign the data structures in an application\n\n(b) Implementation component\nImplement the data structures and operations to manipulate them\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0510",
    "title": "Image dehazing (2)",
    "summary": "The images captured during adverse weather conditions often appear to be of low quality due to the presence of various atmospheric particles, which results in the haze, fog etc. This results in downstream tasks such as object recognition producing poor results in terms of accuracy. In this project, the objective is to design and implement algorithms and models that take a hazy image as input and outputs a clear image.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nRead relevant literature in image dehazing\nUnderstand the paper that describes the selected algorithm or model for image dehazing\nSuggest modifications to the model to improve accuracy.\n\n(b) Development component\nImplement the selected algorithm or model for image dehazing along with the suggested modifications.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0511",
    "title": "Image dehazing (1)",
    "summary": "The images captured during adverse weather conditions often appear to be of low quality due to the presence of various atmospheric particles, which results in the haze, fog etc. This results in downstream tasks such as object recognition producing poor results in terms of accuracy. In this project, the objective is to design and implement algorithms and models that take a hazy image as input and outputs a clear image.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nRead relevant literature in image dehazing\nUnderstand the paper that describes the selected algorithm or model for image dehazing\nSuggest modifications to the model to improve accuracy.\n\n(b) Development component\nImplement the selected algorithm or model for image dehazing along with the suggested modifications.",
    "supervisor": "A/P Deepu Rajan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0512",
    "title": "RAW-based Image Enhancement",
    "summary": "This final year project focuses on the development and implementation of a novel RAW-based image enhancement approach using deep learning techniques, specifically designed for low-light enhancement and denoising. By processing RAW images directly, the proposed model aims to preserve the maximum amount of information and minimize artifacts introduced during image processing.\n\nThe deep learning model is designed to adaptively enhance and denoise RAW images captured in various lighting conditions and environments, resulting in high-quality, visually appealing photographs. An essential component of the project is the reimplementation of existing baseline methods and the collection of a diverse dataset, enabling a thorough evaluation and comparison of the developed model's performance. Proficiency in Python programming and familiarity with image processing concepts are required to execute these tasks effectively.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Research and develop deep learning methods for RAW-based Image Enhancement\n\n(b) Development component\nNA",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0513",
    "title": "Real-Time Deep Learning-Based Image Matting for Mobile Devices",
    "summary": "This final year project focuses on developing a real-time, deep learning-based solution for image matting on mobile devices. The primary goal is to create an efficient algorithm capable of performing high-quality matting tasks in real-time on resource-constrained environments. Students will need a strong foundation in deep learning, specifically in techniques optimized for mobile platforms, and proficiency in Python programming. Knowledge of mobile computing and experience with optimization techniques for deep learning models, such as quantization and pruning, are crucial. The project will involve the design, implementation, and optimization of a neural network capable of handling the computational limitations of mobile devices while providing precise image matting results, thereby enabling advanced photo-editing capabilities directly from smartphones.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\na) Research Component: Investigate current deep learning-based image matting techniques and their performance on desktop environments. Identify the challenges and limitations when adapting these methods for mobile devices.\nb) Development Component: Develop a lightweight, efficient deep learning model tailored for mobile platforms. This involves designing the architecture, optimizing the model for real-time performance on mobile devices, and implementing the solution in a mobile-friendly programming environment. The final product should deliver real-time image matting with minimal loss in quality.",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0514",
    "title": "Real-Time Monocular Depth Estimation on Mobile Devices Using Deep Learning",
    "summary": "This final year project aims to develop a robust, deep learning-based solution capable of estimating depth from monocular images in real time, specifically tailored for mobile devices. The challenge lies in achieving high accuracy and speed on devices with limited computational resources. Students must have a solid background in deep learning, computer vision, and proficiency in Python programming. Familiarity with mobile development frameworks and optimization techniques for deep learning models, such as model quantization and lightweight architecture design, is essential. The project entails designing, implementing, and optimizing a neural network that can efficiently perform depth estimation from single images on mobile platforms, enhancing applications in areas like augmented reality, photography, and navigation.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\na) Research Component: Examine existing deep learning methodologies for depth estimation from monocular images, focusing on their adaptability and efficiency on mobile devices. Identify gaps and opportunities for improvement in real-time performance and accuracy.\nb) Development Component: Create and optimize a deep learning model suitable for mobile devices, prioritizing speed and efficiency without significantly compromising depth estimation accuracy. Implement the solution in a mobile application framework, ensuring it operates in real time and integrates seamlessly with mobile camera inputs.",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0515",
    "title": "Automatic Image Colorization",
    "summary": "Image colorization is a widely studied computer vision task that aims to add natural colors to grayscale images, recreating the lost chromatic information. This final year project presents the development and implementation of a novel automatic image colorization approach based on a diffusion model, with the main objective of delivering high-quality, visually coherent results. The proposed method leverages the power of deep learning techniques and the inherent properties of diffusion models to generate vibrant, realistic colorized images from grayscale inputs.\n\nThe diffusion model offers robust performance by incorporating local and global image features, ensuring seamless color propagation and accurate color reproduction. The project also focuses on the integration of the developed approach into a user-friendly web platform, allowing users to upload and colorize grayscale images effortlessly. This web platform serves as a practical demonstration of the model's effectiveness and accessibility to a broad audience.\n\nThe student needs to have strong programming skills in Python. Motivated and independent.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Research and develop deep learning methods for image colorization\n\n(b) Development component\n- Develop the needed frontend and backend code to integrate with an existing web platform",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0516",
    "title": "Exploiting the Image Prior in CLIP for Super-Resolution",
    "summary": "Contrastive models like CLIP have achieved impressive success in learning image presentations supervised by natural language. It has been shown that the extracted image presentations are beneficial to the downstream vision tasks. In this project, we exploit how to harness the image knowledge in CLIP as prior to solve the task of image super-resolution. Specifically, a light network is designed to gradually fuse the features of the image encoder in CLIP and map them to the desirable high-quality image.  During training, we tune the parameters in this network while fixing the image encoder of CLIP. In this way, it is capable of sufficiently leveraging the image prior of CLIP to facilitate the task of image super-resolution.\n\n\nThe student needs to have strong programming skills in Python. Motivated and independent.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Research and develop deep learning methods for image super-resolution\n\n(b) Development component\n- NA",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0517",
    "title": "Scene Image Style Translation using Diffusion Models",
    "summary": "The project will focus on an image-to-image translation framework, aimed at achieving automatic high-quality rendering of anime scenes from complex real-world images. The task of rendering anime scenes from real-world images is a significant practical value but presents numerous challenges, including the complexity of the scenes, unique features of anime style, and the lack of high-quality datasets to bridge the domain gap. Despite promising attempts, previous efforts have been incompetent in achieving satisfactory results with consistent semantic preservation, evident stylization, and fine details. The student will explore diffusion models for this task. Strong programming skills and good knowledge in deep learning are required.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Research and develop deep learning methods for image-to-image translation\n\n(b) Development component\nNA",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0518",
    "title": "Deep Image Inpainting with Reference Images",
    "summary": "Inpainting is the process of reconstructing lost or deteriorated parts of images and videos. Image inpainting can be used to build image editing tools for users to remove unwanted region in images. In this project, you will develop image processing and machine learning algorithms to recover the missing regions of a natural image with visually plausible image structures and textures. You will explore the use of generative adversarial network for this task and design a way to take reference images for guiding the reconstruction process. \n\nThe student needs to have good knowledge in computer vision or image processing. Experience in Python programming and PyTorch is a plus.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Research and develop deep learning methods for the task of image inpainting\n\n(b) Development component\n- Develop a web interface that allows a user to upload an image, introduce a mask, and perform image inpainting",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0519",
    "title": "Deep Image Enhancement",
    "summary": "Many photos are often captured under suboptimal lighting conditions due to inevitable environmental and/or technical constraints. These include inadequate and unbalanced lighting conditions in the environment, incorrect placement of objects against extreme back light, and under-exposure during image capturing. Such low-light photos suffer from compromised aesthetic quality and unsatisfactory transmission of information. The former affects viewers� experience while the latter leads to wrong message being communicated, such as inaccurate object/face recognition.\n\nIn this project, you will formulate deep learning techniques for low-light image enhancement. It should be able to cope with diverse lighting conditions including nonuniform and poor lighting cases. Instead of performing image-to-image mapping, you will need to reformulate the task as an image-specific curve estimation problem. In particular, the proposed method takes\na low-light image as input and produces high-order curves as its output. These curves are then used for pixel-wise adjustment on the dynamic range of the input to obtain an enhanced image. \n\nThe student needs to have good knowledge in computer vision or image processing. Experience in Python programming and PyTorch is a plus.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Research and develop deep learning methods for the task of image enhancement\n\n(b) Development component\n- Develop a prototype for deep image enhancement",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0520",
    "title": "Lane Detection by Convolutional Neural Networks",
    "summary": "An important component of autonomous driving is lane keeping. Lane detection is the most critical component that allows a car to properly position itself within the road lanes, which is also crucial for any subsequent lane departure or trajectory planning decision in fully autonomous cars. In this project, you will design an effective deep convolutional network that can detect lanes in highway and urban streets. The algorithm must be able to cope with occlusion caused by other vehicles and pedestrian co-exist in the scene and also deal with different weather and lighting conditions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Research and develop effective deep learning methods that can perform lane detection end-to-end. The algorithm may perform additional tasks apart from lane detection, including but not limited to drivable area segmentation and lane counting.\n\n(b) Development component\n- Develop a prototype with the lane detection capability. The method should produce a segmentation mask for each lane in an image. The method should run in real-time on a GPU.",
    "supervisor": "Prof Chen Change Loy",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0521",
    "title": "WebAssembly Performance Evaluation: Garbage Collection Focus (1)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nWebAssembly currently aims to support compilation from Java and Kotlin object-oriented languages using an experimental \"Garbage-Collected Types\" feature. This project will evaluate the performance of this approach through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly's unusual compilation scheme from object-oriented languages.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for performance of object-oriented languages.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0522",
    "title": "WebAssembly Performance Evaluation: Memory Focus (1)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nWebAssembly supports heap memory access purely through a bounds-checked byte buffer. These bounds checks improve security but may be inefficent. This project will evaluate the performance of this approach through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly's bounds-checked byte buffers.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for memory safety.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0523",
    "title": "WebAssembly Performance Evaluation: JavaScript Interaction Focus (1)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nSome functionality of compiled WebAssembly code is implemented by interfacing with external JavaScript programs. This project will evaluate the performance of this approach through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly's JavaScript interface.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for language interoperation.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0524",
    "title": "WebAssembly Performance Evaluation: Algorithmic Focus (1)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nHigh-performance code written in C/C++, when compiled to WebAssembly, may regress in performance for a variety of reasons. This project will evaluate the causes of this regression through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly in the context of high-performance code.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for performance.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0525",
    "title": "WebAssembly Performance Evaluation: Memory Focus (2)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nWebAssembly supports heap memory access purely through a bounds-checked byte buffer. These bounds checks improve security but may be inefficent. This project will evaluate the performance of this approach through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly's bounds-checked byte buffers.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for memory safety.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0526",
    "title": "WebAssembly Performance Evaluation: Algorithmic Focus (2)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nHigh-performance code written in C/C++, when compiled to WebAssembly, may regress in performance for a variety of reasons. This project will evaluate the causes of this regression through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly in the context of high-performance code.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for performance.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0527",
    "title": "WebAssembly Performance Evaluation: JavaScript Interaction Focus (2)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nSome functionality of compiled WebAssembly code is implemented by interfacing with external JavaScript programs. This project will evaluate the performance of this approach through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly's JavaScript interface.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for language interoperation.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0528",
    "title": "WebAssembly Performance Evaluation: Concurrency Focus (2)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nWebAssembly currently aims to support compilation from C/C++ concurrency (threads and atomics) by re-using the existing features of JavaScript Web workers. This project will evaluate the performance of this approach through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly's unusual compilation scheme from C/C++ concurrency.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for performance through concurrency.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0529",
    "title": "WebAssembly Performance Evaluation: Concurrency Focus (1)",
    "summary": "WebAssembly is the first new language to be introduced to the Web since JavaScript. It is intended to be a universal compilation target for the Web, enabling a variety of languages to be executed in Web sites.\n\nWebAssembly currently aims to support compilation from C/C++ concurrency (threads and atomics) by re-using the existing features of JavaScript Web workers. This project will evaluate the performance of this approach through benchmarking.\n\nSpecific details:\n\n\n(a) Research component\nMore clearly understand the performance characteristics of WebAssembly's unusual compilation scheme from C/C++ concurrency.\n\n(b) Development component\nDevelop an enhanced understanding of modern Web technologies, and modern approaches for performance through concurrency.",
    "supervisor": "Ast/P Conrad Watt",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0530",
    "title": "Multi-Modal K-Nearest Neighbor (KNN) Algorithm",
    "summary": "This project investigates a straightforward approach to K-Nearest Neighbor (KNN) classification for multi-modal data, focusing on scenarios where features come from different sensors or media. The emphasis lies on combining various modalities�such as images, text, or numerical signals�into a unified classification framework by aligning or normalizing feature representations. The implementation, carried out in MATLAB, involves selecting suitable distance metrics, testing different weighting strategies across modalities, and evaluating parameter choices like the neighborhood size K. Benchmark datasets with multiple feature types may be employed to examine the algorithm�s classification accuracy, runtime, and resilience to noise. The project�s outcomes are expected to highlight practical guidelines for integrating heterogeneous data sources under the KNN paradigm, offering a balance between simplicity of design and reasonable performance. Ultimately, the research seeks to provide a hands-on experience with a fundamental machine learning method while revealing its adaptability to various real-world, multi-modal tasks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign KNN algorithms\n\n\n(b) Development component\n\nImplement baselines and proposed algorithms",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0531",
    "title": "Multi-Modal Fuzzy C-Means (FCM) Clustering Approach",
    "summary": "This project explores a multi-modal extension of the Fuzzy C-Means (FCM) clustering algorithm, aiming to handle data drawn from diverse sources such as text, images, or sensor readings. Implemented in MATLAB, the approach centers on two main aspects: data preprocessing to unify features from different modalities, and the application of fuzzy clustering concepts that assign partial memberships instead of hard labels. Specific tasks include determining optimal cluster numbers, experimenting with different distance functions, and testing normalization techniques to fairly weight each modality. Quantitative metrics like clustering compactness and qualitative assessments of group consistency serve to evaluate the algorithm�s effectiveness. The project intends to illustrate how combining fuzzy clustering principles with multi-modal data processing can reveal hidden structures in complex datasets. By maintaining a relatively simple implementation, the study aims to familiarize students with core clustering methods while demonstrating their versatility in handling heterogeneous information sources.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign new algorithms\n\n(b) Development component\n\nImplement baselines and proposed algorithm",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0532",
    "title": "Deep learning for facial action unit recognition",
    "summary": "Facial action unit (AU) recognition from images is an important process in computer vision and has a lot of applications. However, this process is a challenging task since subtle changes of local facial muscles are difficult to thoroughly capture. This project studies how to develop a machine learning model using 2D and 3D information conveyed in images for AU recognition.  The student is expected to implement and evaluate some existing methods. Further research on possible improvement is highly encouraged.\n\nSpecific details:\ndesign some CNN models for AU recognition, which leverage 2D and 3D information conveyed in images \n\nresearch on how to improve existing AU recognition methods",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Visual Computing",
      "Machine Learning",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0533",
    "title": "Personality and emotion estimation in human-human interaction",
    "summary": "Estimating personality and emotion of a person through\nvisual or multimodal signals has attracted increasing attention in cognitive multimodal interfaces and human factors in XR. This project aims to investigate deep learning techniques for estimating personality and emotion of a person from visual or audio information in human-human interaction. The student is expected to survey, implement and evaluate some existing methods.  Further research on improvement, especially using large language models,  is highly encouraged.\n\nSpecific details:\ndesign and implement methods for data processing\n\ndesign and implement deep learning methods for personality and emotion estimation\n\nexplore how to improve some existing methods",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Video/Audio/Speech Processing",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0534",
    "title": "3D model generation from text",
    "summary": "Generating 3D content from text is challenging. Recently, a technique called DreamFusion [1] was proposed to perform text-to-3D synthesis. It was built on text-to-image synthesis that was driven by diffusion models trained on image-text pairs. DreamFusion does no require 3D training data or modifications to the image diffusion model.\n\nThe aim of the project is to evaluate DreamFusion and explore possible improvement or extension.\n\n[1] Poole, B., Jain, A., Barron, J.T. and Mildenhall, B., 2022. Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988.\n\nSpecific details:\n1) implement and evaluate DreamFusion\n2) explore possible extension\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0535",
    "title": "Efficient generation of radiance fields for 3D scenes",
    "summary": "Reconstructing 3D scenes to support high quality new view synthesis is an important task for computer vision and graphics applications in various real world scenarios. In 2019, a neural representation called NeRF was developed, which models a scene as a radiance field and shows great success in photo-realistic rendering of scenes with complex geometry and view-dependent appearance. This representation was then quickly extended in different ways and applied in generative models, appearance acquisition, surface reconstruction, appearance editing, etc. While the original NeRF is based on MLP and requires small memory, it takea a long time to train. Many improvements have been proposed. In this project, we will examine two of such improvements that leverage a voxel grid of features in radiance field modeling [1,2]. The main tasks of the project include:\n\n1) test and evaluate the algorithms proposed in [1,2].\n2) propose and implement some further improvement.\n\n\nReferences:\n\n[1]. Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, Angjoo Kanazawa: \"PlenOctrees for Real-time Rendering of Neural Radiance Fields\". ICCV 2021: 5732-5741\n[2]. Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong Chen, Benjamin Recht, Angjoo Kanazawa: \"Plenoxels: Radiance Fields without Neural Networks\". CVPR 2022: 5491-5500\n\nSpecific details:\nImplement and evaluate PlenOctrees &amp; Penoxels\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Visual Computing",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0536",
    "title": "Graph CNN for 3D meshes",
    "summary": "MeshCNN is a convolutional neural network with an edge, which was developed for analyzing triangular mesh models and published in 2019 in ACM Transactions on Graphics. Triangular meshes provide an efficient representation for 3D shapes and have gained wide applications in computer games, animation, AR/VR, etc. MeshCNN generalizes classic CNNs to triangular meshes by leveraging the intrinsic features of triangular meshes and designing specialized convolution and pooling layers that operate on the mesh edges, and provides a powerful plug-and-play framework for various tasks.\n\nThis project aims to evaluate MeshCNN's performance in different aspects and explore general graph CNN for 3D triangular meshes.\n\nSpecific details:\nImplement MeshCNN and explore its generalization\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0537",
    "title": "Efficient generation of radiance fields for 3D scenes",
    "summary": "Reconstructing 3D scenes to support high quality new view synthesis is an important task for computer vision and graphics applications in various real world scenarios. In 2019, a neural representation called NeRF was developed, which models a scene as a radiance field and shows great success in photo-realistic rendering of scenes with complex geometry and view-dependent appearance. This representation was then quickly extended in different ways and applied in generative models, appearance acquisition, surface reconstruction, appearance editing, etc. While the original NeRF is based on MLP and requires small memory, it takea a long time to train. Many improvements have been proposed. In this project, we will examine two of such improvements that leverage a voxel grid of features in radiance field modeling [1,2]. The main tasks of the project include:\n\n1) test and evaluate the algorithms proposed in [1,2].\n2) propose and implement some further improvement.\n\n\nReferences:\n\n[1]. Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, Angjoo Kanazawa: \"PlenOctrees for Real-time Rendering of Neural Radiance Fields\". ICCV 2021: 5732-5741\n[2]. Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong Chen, Benjamin Recht, Angjoo Kanazawa: \"Plenoxels: Radiance Fields without Neural Networks\". CVPR 2022: 5491-5500\n\nSpecific details:\nImplement and evaluate PlenOctrees &amp; Penoxels\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Visual Computing",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0538",
    "title": "Point cloud analysis for surface defect detection",
    "summary": "Automatic inspection and defect detection using visual data is currently an active research topic in machine vision. Particularly, three-dimensional surface defect inspection is a promising and also challenging problem. This project explores vision-based surface inspection techniques using point clouds. The goal is to identify and extract the information about the undesired defects such as dents, protrusions or scratches on the surface of the part by analyzing 3D point clouds collected from the object with a 3D scanner. The project can start with the approach proposed in ref [1]. The use of machine learning methods for point cloud analysis is highly encouraged.\n\n\nReferences\n[1] Jovančević, I., Pham, HH., Orteu, JJ. et al. 3D Point Cloud Analysis for Detection and Characterization of Defects on Airplane Exterior Surface. J Nondestruct Eval 36, 74 (2017). https://doi.org/10.1007/s10921-017-0453-1.\n\n[2] Ben Abdallah H, Jovančević I, Orteu J-J, Br�thes L. Automatic Inspection of Aeronautical Mechanical Assemblies by Matching the 3D CAD Model and Real 2D Images. Journal of Imaging. 2019; 5(10):81. https://doi.org/10.3390/jimaging5100081\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nthe use point cloud analysis for surface defect detection\n\nthe use of machine learning for point cloud analysis\n\n(b) Development component\n\ndevelop a prototype for surface defect detection from point clouds",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Visual Computing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0539",
    "title": "Geometry symmetry detection for 3D models",
    "summary": "Geometry symmetry can be found in many real world objects. It exhibits some advantages such as aesthetics, functional optimality principles and manufacturing efficiency. This project aims to investigate computational methods for partial and approximate detection for 3D objects represented by point clouds or meshes. The objectives include surveying recent work in this topic, implementing a few algorithms, and evaluating them. \n\nReferences:\n\n1. MITRA, N. J., GUIBAS, L. J., AND PAULY, M., \"Partial and approximate symmetry detection for 3d geometry\". ACM Transactions on Graphics 25, 3 (July), 2006, 560�568.\n\n2. MITRA, N. J., PAULY, M., WAND, M., AND CEYLAN, D., \"Symmetry in 3d geometry: Extraction and applications\". In EUROGRAPHICS2012\nState-of-the-art Report, Eurographics Association, 2012.\n\n3. BERNER, A., BOKELOH, M., WAND, M., SCHILLING, A., AND SEIDEL, H.-P., \"A graph-based approach to symmetry detection\". In Symposium on Volume and Point-Based Graphics, Eurographics Association, 2008.\n\nSpecific details:\nDesign and implement a few symmetry detection algorithms\n\ncompare and evaluate the existing symmetry detection algorithms;\n\nexplore the possibility of improving the existing symmetry detection algorithms.",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Visual Computing",
      "Theory &amp; Algorithms",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0540",
    "title": "Software development for digital Chinese medicine tongue diagnosis",
    "summary": "Tongue diagnosis is a common skill in Chinese medicine. To become proficient in the art of tongue diagnosis, the practitioner must be able to recognize and identify the pathological characteristics of the tongue as it relates to disease. \n\nThis project aims to use advanced media technology to develop a software tool that makes process of tongue diagnosis digital and automatic. In particular, we investigate software framework in a mobile environment for a digital tongue diagnosis system and develop a prototype, which takes a user's picture of tongue, performs diagnosis analysis, and gives a diagnosis report. This is useful for self-checking or  training the practitioners. The student is expected to have good programming skills in developing mobile applications.\n\nSpecific details:\ndesign a mobile application that takes a user's picture of tongue, performs diagnosis analysis and outputs a report",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Mobile Applications",
      "Image Analysis &amp; Processing",
      "Visual Computing",
      "Human Computer Interaction",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0541",
    "title": "Surface defect detection based on MobileNet-SSD",
    "summary": "Automatic inspection and defect detection using visual data such as images and videos is currently an active research topic in machine vision. The technique is widely adopted in industries, for example, for surface defect detection. The basic idea is to examine visual patterns from images of the manufactured surfaces to detect the flaws. This has advantages of overcoming the limitations of the traditional inspection approaches that depend heavily on humans and improving the efficiency and performance of inspection.\n\nThis project aims to implement a deep-learning method for real-time and accurate surface defect detection, which was proposed in ref [1], and evaluate its performance. Particularly, the research tasks include: (1) implementing  the MobileNet-SSD, which adopts the Single Shot MultiBox Detector (SSD) network as the meta structure and combines it with the convolution neural network MobileNet; and (2) developing a detection method for surface defects based on the MobileNet-SSD. It would be highly appreciated if further improvements could be made. \n\n\nReferences\n[1] Y. Li, H.Huang, Q.Xie, L. Yao, andn Q. Chen. Research on a Surface Defect Detection Algorithm Based on MobileNet-SSD. Appl. Sci. 2018, 8, 1678. https://doi.org/10.3390/app8091678\n\n[2] Ren, Z., Fang, F., Yan, N. et al. State of the Art in Defect Detection Based on Machine Vision. Int. J. of Precis. Eng. and Manuf.-Green Tech. (2021). https://doi.org/10.1007/s40684-021-00343-6\n\n[3] Daniel Weimer, Bernd Scholz-Reiter, Moshe Shpitalni. Design of deep convolutional neural network architectures for automated feature extraction in industrial inspection. CIRP Annals, Volume 65, Issue 1, 2016, Pages 417-420, ISSN 0007-8506, https://doi.org/10.1016/j.cirp.2016.04.072.\n\nSpecific details:\n(a) Design component\n\na prototype for surface defect detection\n\n(b) Implementation component\n\nimplementing  the MobileNet-SSD and a detection method for surface defects based on the MobileNet-SSD\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0542",
    "title": "Converting images into 3D models for 3D printing",
    "summary": "The intensity in an image may be viewed as shape information. In this perspective, an image defines a 3D shape. Creating a physical model for an image is interesting. 3D printing techniques provide a solution to this. \n\nThe proposed fyp project aims to develop a software tool which accepts an image as the input and outputs a 3D mesh model for 3D printing. The project involves 3D mesh construction, feature preserving mesh simplification, and stl file generation. The project requires the student to have good programming skills.\n\nSpecific details:",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Human Computer Interaction",
      "Visual Computing",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0543",
    "title": "Salience guided 3D model simplification",
    "summary": "Many 3D games involve complicated 3D models and scenes. To provide excellent rendering effects in real time, it is often required that the models should be simplified. This FYP project aims to implement and develop efficient algorithms to simplify 3D triangular mesh models. Such models are common in various graphics applications. We will explore how to incorporate visual saliency into the process. Particularly, we are interested in examining and choosing appropriate saliency models for our application. The project requires the student to have passion in 3D graphics and good programming skills.\n\nSpecific details:\ndesign and implement mesh simplification algorithms guided by saliency\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Computer Animation/ Games",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0544",
    "title": "Deep learning for part inspection and defect detection",
    "summary": "Automatic inspection and defect detection using visual data such as images and videos is currently an active research topic in machine vision. The technique is now widely adopted in industries, for example, for quality control in production systems. The basic idea is to examine visual patterns from images and videos of the manufactured surfaces to detect the flaws. This has advantages of overcoming the limitations of the traditional inspection approaches that depend heavily on humans and improving the efficiency and performance of inspection.\n\nThis project explores the use of deep learning techniques for detecting and/or further classifying the defects of manufactured parts from the images of their surfaces. The research tasks include developing an automatic inspection pipeline, implementing an appropriate deep learning model, and building a prototype for parts inspection and defect detection using images.\n\n\nReferences:\n\n1. S. Satorres Mart�nez, C. Ortega V�zquez, J. G�mez Garc�a and J. G�mez Ortega. Quality inspection of machined metal parts using an image fusion technique. Measurement.2017;111(Supplement C): 374�383. \n \n2. C. Jian, J. Gao annd Y. Ao. Automatic surface defect detection for mobile phone screen glass based on machine vision. Applied Soft Computing, vol.52; 2017. p.348�358. \n\n3. O. Essid, H. Laga and C. Samir. Automatic detection and classification of manufacturing defects in metal boxes using deep neural networks. PLoS ONE 13(11): e0203192. 2018. https://doi.org/10.1371/journal.pone.0203192. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\ndeep learning techniques for detecting and/or further classifying the defects of manufactured parts from the images of their surfaces. \n\n(b) Development component\n\ndevelop an automatic inspection pipeline, implement an appropriate deep learning model, and build a prototype for parts inspection and defect detection using images.",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0545",
    "title": "Human perception guided model simplification for game applications",
    "summary": "Nowadays many 3D games involve complicated 3D models and scenes. To provide excellent rendering effects in real time, it is often required that the models should be simplified. This FYP project aims to implement and develop efficient algorithms to simplify 3D triangular mesh models with textures. Such models are common in various graphics applications. Particularly, we will explore how to incorporate human perception about shapes into the process. While human perception of quality is difficult to quantify, we are interested in building a computational model for visual quality metric and examining the effectiveness of visual quality metrics in the context of level-of-detail (LOD) generation. The project requires the student to have passion in 3D graphics and good programming skills.\n\nSpecific details:\ndesign and implement mesh simplification algorithms\n\nexplore visual quality metrics and human perception guided mesh simplification algorithms.",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Computer Animation/ Games",
      "Artificial Intelligence",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0546",
    "title": "Intelligent 3D Modelling",
    "summary": "Due to rapid development of graphics, data analytics, machine learning and HCI, and availability of a large number of existing 3D models, recent research on geometric modelling is shifting from conventional manipulation on points, edges or faces towards high level explorative modelling, example driven synthesis and creative modelling. They provide new ways for design, which the designer is familiar with. This project aims to investigate novel modelling techniques using AI algorithms. In particular, evolution algorithms mimic the biological evolution in nature and exhibit stochastic characteristics intrinsically. \n\nSpecific details:\nimplement a few algorithms\n\ndevelop a prototype\n\ncreate a 3D model dataset \n\nexplore the evolution based algorithms for intelligent 3D modeling",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Visual Computing",
      "Theory &amp; Algorithms",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0547",
    "title": "Modeling of 3D neuronal networks",
    "summary": "Understanding the human brain is a great\nchallenge for science. 3D modeling and visualization provides a useful tool for analysing the complicated  features and behavior of dense neural networks. This project investigates techniques for modeling the point-and-diameter based neuronal morphology descriptions defined in neuronal morphology files. In particular, modelling using PovRay and mesh reconstruction will be researched. The student is expected to have strong interest in the project and good programming skills.\n\nSpecific details:\nTo design a PovRay based visualizer for rendering the point-and-diameter based neuronal morphology\n\n\n \n\nTo research how to convert the point-and-diameter based description into a watertight mesh representation",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Graphics",
      "Virtual Reality",
      "Visual Computing",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0548",
    "title": "Image-based virtual try-on",
    "summary": "Virtual try-on refers to techniques that render garments onto a picture or video of a person in a virtual environment, allowing him/her to see what a piece of clothing will look like on him/her without physically trying on anything. Virtually try-on technology has been available for some time, and usually requires complicated computations. This FYP aims to create a lightweight program that allows the user to take a picture of a garment and fits it onto a picture of himself/herself, which thus brings virtual try-on to a more accessible space. In particular, the project focuses on 2D image processing techniques.\n\nThe student will be guided in developing the main algorithms for the project. The student should have good programming skills.  \n\nSpecific details:\ndesign and implement algorithms for image processing algorithms such as contour extraction, shape matching and morphing.",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Computer Animation/ Games",
      "Computer Graphics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0549",
    "title": "Augmented Reality Application for Virtual Glasses Try-On",
    "summary": "Augmented reality (AR) is a technology that superimposes computer-generated images on top of real world objects. AR extends a variety of experiences and provides useful information to users.\n\nThis project uses available AR SDK and/or tools such as Apple's ARKit or Google's ARcore to create a mobile augmented application for product preview and explores techniques to improve the manipulation and visualization of AR applications. The student taking this project is required to have strong programming skills and have some experience with Unity3D.\n\nSpecific details:\nimplement an AR-based APP, which involves 3D modeling, visualization, software design, etc.\n\nexplore new algorithms for enhancement of AR applications.",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Virtual Reality",
      "Mobile Applications",
      "Visual Computing",
      "Mixed Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0550",
    "title": "Image processing algorithms for digital Chinese medicine tongue diagnosis",
    "summary": "Tongue diagnosis is a common skill in Chinese medicine. To become proficient in the art of tongue diagnosis, the practitioner must be able to recognize and identify the pathological characteristics of the tongue as it relates to disease. \n\nThis project aims to use advanced media technology to make the process of tongue diagnosis digital and automatic. In particular, we investigate image processing algorithms for analyzing pictures of tongues and develop new methods for comparing an input picture of tongue with the pictures stored in the database, by which the diagnosis can be done automatically or by user himself. This project requires the student to have good programming skills.\n\nSpecific details:\ndesign a prototype for processing images of tongues\n\nresearch algorithms for processing and analyzing pictures of tongues",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Mobile Applications",
      "Medical Informatics",
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0551",
    "title": "Gaussian splatting and view interpolation",
    "summary": "3D Gaussian splatting is a recently-developed technique based on radiance field rendering. It can be used to create high-quality novel-view scenes by taking multi-view images as input. View interpolation is an old technique for the similar purpose. This project aims to compare both methods and explore how to improve these methods, especially with the help of large vision models. \n\nSpecific details:\nimplement both Gaussian splatting and view interpolation methods;\n\nevaluate both methods ;\n\nexplore how to improve the methods.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Zheng Jianmin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Visual Computing",
      "Computer Graphics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0552",
    "title": "Securing the Software Supply Chain: Detecting and Mitigating Risks in the Software Development Lifecycle",
    "summary": "As software systems become more complex and rely heavily on third-party components, ensuring the security of the software supply chain has become a critical challenge. This project focuses on identifying vulnerabilities and mitigating risks in the software supply chain, from the development of source code to the distribution and deployment of software products. Undergraduate students will explore the key security threats in the software supply chain, including dependency vulnerabilities, malicious code injections, and compromised updates. The project will involve building systems or utilizing existing tools to monitor and secure each stage of the software development lifecycle. Students will implement methods for verifying the integrity of software components, detecting potential threats in open-source libraries, and ensuring secure updates and patching mechanisms. Through hands-on work, students will gain practical skills in securing the software supply chain, addressing both technical and procedural risks that impact modern software development practices.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0553",
    "title": "Autonomous Agents for Software Engineering: Automating Code Development and Maintenance",
    "summary": "Autonomous agents are increasingly being applied to software engineering, transforming how code is written, tested, and maintained. This project explores the development and use of intelligent agents to automate various tasks within the software engineering lifecycle, such as code generation, bug detection, refactoring, and testing. Undergraduate students will learn how these agents can assist in optimizing workflows, improving code quality, and reducing manual effort in complex software projects. The project will involve building or leveraging AI-driven tools that automatically generate code based on specifications, identify and fix vulnerabilities, and continuously test and improve software systems. Students will also investigate the challenges and limitations of using agents in software engineering, such as ensuring code security, handling complex dependencies, and maintaining human oversight. Through this project, students will gain hands-on experience in developing autonomous agents for software engineering, contributing to more efficient, scalable, and error-resistant software development practices.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Software and Applications",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0554",
    "title": "Autonomous Agents for Security: Developing Intelligent Defense Systems",
    "summary": "The integration of autonomous agents into security applications has the potential to revolutionize how organizations protect their systems and data from evolving cyber threats. This project focuses on designing and implementing intelligent agents capable of autonomously detecting, responding to, and mitigating security breaches in real-time. Undergraduate students will explore the role of autonomous agents in cybersecurity, learning about threat detection, automated incident response, and adaptive defense strategies. The project will involve developing or utilizing existing AI-powered agents to monitor network traffic, detect anomalies, and respond to simulated attacks. Students will also address the challenges of creating secure and resilient agents, including preventing adversarial manipulation and ensuring reliable decision-making under uncertainty. By participating in this project, students will gain practical experience in applying autonomous agents to enhance security infrastructure, positioning them at the forefront of future defense technologies.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0555",
    "title": "Enhancing Scientific Discovery with Autonomous Agents: Challenges and Opportunities",
    "summary": "Autonomous agents are increasingly being used to accelerate scientific discovery across various fields, from data analysis to experimental design. This project explores the use of autonomous agents in science, focusing on their potential to assist researchers in complex tasks such as hypothesis generation, data collection, and simulation. Undergraduate students will study how these agents can be designed to autonomously conduct scientific experiments, analyze vast amounts of data, and propose new research directions. The project will involve building or utilizing existing AI agents, training them in specific scientific domains, and assessing their performance in solving real-world scientific problems. Students will also explore the ethical and technical challenges in deploying autonomous agents in science, including issues related to bias, reliability, and interpretability of agent-driven discoveries. By working on this project, students will gain hands-on experience in developing and applying autonomous agents to support and enhance scientific research, ultimately contributing to more efficient and innovative approaches in various scientific disciplines.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0556",
    "title": "Securing Autonomous Agents: Defense Strategies Against Adversarial Manipulation",
    "summary": "With the growing deployment of autonomous agents in various industries, from robotics to virtual assistants, ensuring the security of these systems is crucial to prevent adversarial manipulation. This project focuses on exploring the security vulnerabilities in autonomous agents, particularly how malicious users can manipulate agent behavior through adversarial inputs or environmental changes. Undergraduate students will study the basic architecture of autonomous agents, the types of security risks they face, and develop strategies to enhance their robustness. The project will involve designing and implementing adversarial attack scenarios and creating defense mechanisms, such as anomaly detection, reinforcement learning-based defenses, and robustness testing under corrupt inputs. By participating in this project, students will gain a deep understanding of agent security challenges and acquire practical skills in developing secure, resilient autonomous systems capable of withstanding adversarial interventions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0557",
    "title": "Strengthening LLM Security: Defending Against Jailbreaking Attacks in Large Language Models",
    "summary": "As Large Language Models (LLMs) like GPT and other advanced AI systems become increasingly powerful, ensuring their security is critical, especially in preventing users from exploiting vulnerabilities through jailbreaking techniques. Jailbreaking attacks involve users intentionally manipulating prompts to bypass safety filters or unlock unintended behaviors, posing significant risks to the ethical and responsible use of AI. This project will introduce undergraduate students to the concept of jailbreaking in LLMs, exploring common strategies used in such attacks and developing defensive mechanisms to counteract them. Students will study existing LLM safety protocols, design and test various prompt-hardening techniques, and implement systems to detect and mitigate jailbreaking attempts. By simulating attack scenarios and building robust defenses, students will gain hands-on experience in LLM security, understanding both the vulnerabilities of modern AI models and the methods required to safeguard them from adversarial manipulation.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0558",
    "title": "Smart Contract Vulnerability Repair Based on Large Language Model",
    "summary": "Smart contracts have emerged as revolutionary tools in the blockchain domain, enabling automated, trustless transactions over decentralized networks. However, the dynamic nature of these contracts often makes them susceptible to vulnerabilities, which can have severe financial and trust implications. This research presents a unique methodology that synergizes the capabilities of large language models (LLMs) with traditional static and dynamic analysis technologies to promote the repair of smart contract vulnerabilities. Our approach delves into the root causes of these vulnerabilities by leveraging the analytical prowess of LLMs like GPT-4. The LLMs dissect and interpret the inherent logic and structure of smart contracts, pinpointing potential weaknesses. These identified vulnerabilities are then further scrutinized using traditional static analysis for code anomalies and dynamic analysis for runtime behavior deviations. This multi-faceted approach ensures a thorough evaluation of the smart contract's safety.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0559",
    "title": "Scenario generation methods for functional safety testing of automated driving systems",
    "summary": "Scenario-based methods are both essential and effective when evaluating the functional safety of automated driving systems (ADSs). With the help of high-fidelity 3D simulators, almost all scenario types, e.g., normal urban driving, traffic jams, or extreme situations, can be constructed and simulated. However, with great flexibility comes infinitely large scenario search space. How to effectively search for relevant scenarios towards high diversity coverage and low redundancy has been a hot research topic in academia. \n \nIn this project, we aim to apply and evaluate the performance of existing state-of-the-art (SOTA) scenario-based functional safety testing methods in Desay�s context, identify the limitations of the existing techniques concerning Desay�s requirements, and propose new efficient ways to generate critical scenarios.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Cyber Security",
      "Robotics",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0560",
    "title": "Solving real world security problems: hacking and protection (2)",
    "summary": "This project will aim at studying cybersecurity attacks and understand the behaviors of malware and APT. Based on these understanding, the student will work on the both side of the security: generate new attack and hacking into the system and protecting the system by recognize the attacks. The student should have strong capability in programming, like c and even assembly code. The knowledge about the operating systems and hardware is also helpful. The student will work with hackers, security experts, researchers to work on real-world applications and attacks, e.g., adobe pdf reader, flash player, UAV. The student can be rewarded up to 15000 USD for each 0day vulnerability found.\n\nThis project requires strong programming skills and strong interests in real-world security.\nPlease send me (yangliu@ntu.edu.sg) your CV first before choosing this project.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nDesign the general signature of the vulnerability.\nModel the vulnerability exploits.\n\n(b) Development component\nImplementing binary analysis tools for vulnerability and exploits detection.",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cyber Security",
      "System Security",
      "Data Mining",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0561",
    "title": "Finding Instrumentable Locations for Fuzzing via Static Binary Analysis",
    "summary": "Fuzz testing, or fuzzing, has been quite an effective approach to revealing vulnerabilities in programs. During fuzzing, we typically would like to instrument some coverage relevant information on certain locations of the programs. Detecting instrumentable locations for binaries is a key part that will affect the overall efficiency and effectiveness of the fuzzing procedure. In this project, the participated students are required to use static binary analysis approaches to find the instrumentable locations, where the results will be fed to an existing binary fuzzing framework. The expected outcome is that with these discovered locations, the fuzzer will be able to instrument the binaries smartly and therefore can help to reveal the vulnerabilities more effectively.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cyber Security",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0562",
    "title": "Finding Real World Software Vulnerabilities using ChatGPT (2)",
    "summary": "In this project, you will have an overview of the methods for finding the 0-day vulnerabilities inside modern software using ChatGPT, learn the tools for vulnerability hunting, and analyze their root causes or even exploit the vulnerabilities.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0563",
    "title": "ChatGPT for Security Analysis for Smart Contract  (1)",
    "summary": "A smart Contract is a trading law encoded by one certain program. Once it is deployed, it is not possible to modify it. Therefore, it is very important to test it before we deploy it. In this study, we want to invent a new method using ChatGPT to alarm the developers by ranking real vulnerable codes. We expect the proposed method can precisely help developers exclude high-risk vulnerability from the collected vulnerability datasets. During the study, we focus on how to recommend the real risky code to the developer from the real vulnerability dataset according to similarity.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "System Security",
      "Blockchain"
    ]
  },
  {
    "projectNo": "CCDS25-0564",
    "title": "Evading detectors for diffusion-based images via image reconstruction",
    "summary": "Diffusion has become a prominent technique for generating high-fidelity fake images. In response to the potential harm posed by these fake images, recent efforts have focused on developing methods to detect them. Our work aims to assess the vulnerability of existing detection systems to understand how they can be enhanced further.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0565",
    "title": "Generate Vulnerable Transaction Sequences for Smart Contract using Large Language Models",
    "summary": "In practice, we've observed that triggering vulnerabilities in smart contracts often requires arranging specific transactions in a particular order. Forming these precise transaction sequences through random seed cross-mutation can be a challenging task. To address this, we propose harnessing the code intelligence capabilities of large models to generate transaction sequence templates that are suitable for exploiting vulnerabilities of different types. Subsequently, we can employ automated testing technology to evaluate smart contracts using these templates, significantly enhancing the efficiency of vulnerability exploiting.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Blockchain"
    ]
  },
  {
    "projectNo": "CCDS25-0566",
    "title": "LLM-enabled static analysis of decompiled code",
    "summary": ": The standard approach to find bugs is to use source code static analysis tools, such as CodeQL. However, the source code may not be available for legacy software, third-party libraries or malware. Decompilers are typically used to convert binary code into a pseudo-C form for analysis. In order to perform static analysis on decompiled code however, the code has to be first translated into a form that is compilable. In this project, we would like to explore using LLMs to translate decompiled code to its equivalent compilable form, so as to use CodeQL to find bugs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "JIP",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0567",
    "title": "Preserving Model Integrity: Addressing Security Challenges in Fine-Tuned LLMs",
    "summary": "The advent of  LLMs, particularly those fine-tuned for downstream tasks, has significantly advanced the capabilities of artificial intelligence in many domains. However, this fine-tuning process often leads to a loss of safety alignment, posing potential risks to security. The issue arises because LLMs, when adapted to specific tasks, may unintentionally drift away from their originally aligned protocols, making them vulnerable to adversarial prompting. This research addresses the challenge of maintaining robust safety alignment of LLMs after they undergo downstream task-specific fine-tuning. Our proposed solution is a novel post-training alignment strategy designed to resist the effects of downstream fine-tuning, focusing on identifying and safeguarding those model parameters that are crucial for security but often irrelevant to general task performance. By isolating and preserving these parameters, we aim to enhance the model�s ability to resist potential security threats without compromising its performance on downstream tasks. This study contributes to the field of AI safety by developing a strategy that helps ensure LLMs remain aligned with safety objectives, even in the face of domain-specific fine-tuning challenges.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cyber Security",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0568",
    "title": "Assessing Vulnerabilities in Reasoning-Driven LLMs: Attacks, Challenges, and Defensive Strategies",
    "summary": "Reasoning-driven language models have emerged as a pivotal advancement in AI, demonstrating the ability to tackle complex tasks once considered beyond the reach of machine intelligence. As these models gain prominence, they are increasingly entrusted with critical decision-making processes, from high-stakes scientific analysis to strategic business planning. However, this growing reliance on reasoning LLMs also exposes them to a novel class of threats. Malicious actors can exploit the reasoning chain within these models, introducing subtle logical inconsistencies, propagating fabricated justifications, or manipulating intermediate thought processes to compromise outcomes. Such attacks may lead to erroneous conclusions, biased inferences, or hidden backdoors that undermine user trust. Moreover, the complexity of reasoning pipelines makes it challenging for end-users and developers to detect and mitigate these manipulations effectively. In this study, we investigate the susceptibility of reasoning-driven LLMs to attacks targeting their logical chains, exploring the factors that make them vulnerable and examining the implications of compromised reasoning on downstream tasks. We propose an evaluation framework designed to benchmark diverse attack vectors, encompassing targeted logic disruptions, adversarial prompts, and stealthy manipulations. Additionally, we introduce and assess various defensive strategies, such as robust training protocols, enhanced verification layers, and multi-agent cross-checking mechanisms. By addressing these challenges, our research offers critical insights into safeguarding reasoning LLMs, emphasizing the importance of trustworthy logical processes and laying the groundwork for future innovations in secure and transparent AI systems.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0569",
    "title": "Towards safe and explainable post-training quantization in large language models",
    "summary": "The release of high-performance open-source large language models (LLMs) such as Deepseek R1 and QwQ sparks a surge in individual users deploying local LLMs, but the high computational resource requirement is still a crucial problem for users. Thus, post-training quantization (PTQ) gains unprecedented attention due to its ability to significantly reduce computational and storage costs while almost maintaining model performance. However, PTQ may lead to accuracy loss in weights and a decline in robustness, unintentionally harming the safety alignment of models. To address this issue, we propose a novel quantization method. By incorporating safety and accuracy evaluation mechanisms, we achieve real-time evaluation of the model's alignment performance throughout the quantization process. Based on the evaluation results, our method dynamically adjusts quantization parameters and calibration dataset, achieving safety optimization through adversary. Additionally, our approach advances the explainability of PTQ safety by exposing and analyzing changes in the safety alignment during the quantization process. This research aims to contribute to the exploration and optimization of safety in PTQ.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0570",
    "title": "Automated Test Scenario Generation for Embodied AI Systems",
    "summary": "Ensuring the safety and robustness of embodied AI systems necessitates diverse and systematic testing across a wide range of scenarios. This project aims to develop an automated test scenario generation framework to comprehensively evaluate the performance of embodied AI in diverse and complex environments. By leveraging search-based testing, we will design scalable methods to generate test cases that effectively uncover potential failures in embodied perception, interaction, and control. The outcomes of this project will enhance the reliability of embodied AI systems, facilitating their safe and robust deployment across various real-world applications.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Cyber Security",
      "Robotics",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0571",
    "title": "Building LLM-Based Agents for Testing Embodied AI",
    "summary": "Embodied AI systems, such as robots and autonomous vehicles, are increasingly deployed in real-world applications. However, the uncertainty and complexity of interactive environments continue to pose significant safety risks, potentially leading to system failures with catastrophic consequences. This project aims to develop an LLM-based multi-agent framework for the automated testing of embodied AI. The framework will consist of specialized agents for test case generation, test execution, and result evaluation, working collaboratively to enhance the efficiency and scalability of the testing process. The project seeks to enhance the efficiency and reliability of testing methodologies for embodied AI.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Liu Yang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0572",
    "title": "AI Agents for Automated Medical Image Analysis",
    "summary": "This research project explores the development and application of Artificial Intelligence (AI) agents in automating medical image analysis workflows. The goal is to leverage state-of-the-art LLM agents, for example GPT, DeepSeek and Llama, to coordinate complex tasks involved in the medical image analysis pipeline, such as data preprocessing, model selection and training, as well as inference testing. \n\nBy investigating the potential of AI agents in this domain, students will have the opportunity to contribute to the advancement of healthcare technology and gain hands-on experience with cutting-edge machine learning techniques and medical imaging datasets. A brief introduction about multi-agent orchestration can be found here: https://blog.futuresmart.ai/openai-swarm-a-hands-on-introduction\n\nThe student will develop algorithms by using Python and Pytorch\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on AI agents and their applications in medical image analysis\n\n(b) Development component\nThe student will develop necessary routines in Python with Pytorch/Tensorflow libraries",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Medical Informatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0573",
    "title": "Using Synthetic Data to Improve Medical AI Models",
    "summary": "This research project explores the use of synthetic data to improve medical Artificial Intelligence (AI) models. Training accurate AI models requires large amounts of high-quality data, but expert-annotated medical data is expensive and time-consuming to obtain. Synthetic data offers a promising solution to address this data scarcity issue. \n\nBy investigating the use of synthetic data, students will examine different methods for data synthesis and how they can be incorporated into AI models development to maximize their impact. This project will delve into the challenges and opportunities of using synthetic data in medical AI, with the goal of developing more efficient and accurate medical AI systems.\n\nThe student will develop algorithms by using Python and Pytorch\n\nhttps://hirokatsukataoka16.github.io/Pretraining-without-Natural-Images/\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on generating synthetic data and medical AI systems\n\n(b) Development component\nThe student will develop algorithms by using Python and Pytorch",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Medical Informatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0574",
    "title": "Modeling Physics into AI models for Medical Image Analysis",
    "summary": "This research project focuses on incorporating physical models of medical image acquisition and formation into Artificial Intelligence (AI) models for image analysis. By integrating physics-based modeling into AI frameworks, students will investigate how this approach can enhance the explainability and robustness of medical image analysis. This hybrid approach has the potential to reduce the need for large amounts of training data, as the physical models can provide additional constraints and prior knowledge to guide the learning process. \n\nBy modeling the underlying physics of medical imaging modalities, such as X-ray, MRI, or CT scans, AI models can better capture the complex relationships between image features and underlying anatomy, leading to improved accuracy and reliability in medical diagnosis. This project will explore the intersection of physics-based modeling and deep learning, with applications in medical image analysis and beyond.\n\nThe student will develop algorithms by using Python and Pytorch\n\nhttps://arxiv.org/abs/2202.10847\nhttps://proceedings.mlr.press/v227/wysocki24a/wysocki24a.pdf\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on how physics of image generation can be incorporated into AI models for medical image analysis\n\n(b) Development component\nThe student will develop algorithms by using Python and Pytorch",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0575",
    "title": "Optimizing Medical AI Models with Fixed and Limited Annotation Budget",
    "summary": "This research project addresses the challenge of optimizing medical Artificial Intelligence (AI) models with a fixed, limited annotation budget. In the medical field, expert-annotated data is expensive and scarce, making it essential to maximize the use of available resources. With a fixed budget for data annotation, the goal is to develop strategies that can train the best-performing AI model possible. \n\nStudents will investigate how to optimize the allocation of annotation resources and selecting the most informative samples to minimize the need for extensive labeling. By exploring methods such as sample selection and weak supervision, this project aims to identify effective approaches for training accurate medical AI models under budget constraints, ultimately improving the efficiency and effectiveness of medical AI development.\n\nThe student will develop algorithms by using Python and Pytorch\n\nhttps://arxiv.org/pdf/2412.08081v1\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on how to optimize medical AI models with fixed and limited annotation budgets\n\n(b) Development component\nThe student will develop algorithms by using Python and Pytorch",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Medical Informatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0576",
    "title": "Cell-Type Specific Gene-Brain Graphs for Regional Mapping",
    "summary": "Mapping gene expression across brain regions is critical for understanding functional organization. However, current approaches often lack cellular resolution. In this project, we develop a graph-based framework that integrates BICCN single-cell transcriptomics with spatial histological annotations to map genes to specific brain areas. By leveraging cell-type-specific information, we aim to enhance the accuracy of gene-to-region assignments. We will implement graph neural networks (GNNs) to infer spatial expression patterns and validate our findings against existing spatial transcriptomics datasets. The resulting framework will help identify key molecular signatures underlying regional brain function. \n\nThe student will develop algorithms using Python and PyTorch, with tools such as SCANPY and PyG (PyTorch Geometric). \n\nhttps://www.nature.com/articles/s41586-021-03950-0\nhttps://github.com/BayraktarLab/cell2location\nhttps://github.com/satijalab/sctransform\nhttps://atlas.brain-map.org/\nhttps://github.com/OmicsML/dance\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on cell-type specific gene-brain graphs  for mapping brain regions to genes\n\n(b) Development component\nThe student will develop algorithms using Python and PyTorch, with tools such as SCANPY and PyG (PyTorch Geometric).",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0577",
    "title": "Temporal Evolution of Gene Expression in Brain Development",
    "summary": "Neurodevelopment is shaped by dynamic changes in gene expression, yet many studies focus on static snapshots of the brain. In this project, we analyse BICCN transcriptomics and BrainSpan time-series datasets to uncover gene regulatory shifts during human brain maturation.\n  \nWe will apply RNA velocity analysis to predict developmental trajectories and use pseudotime inference to identify genes driving key neurodevelopmental transitions. Our results will provide insights into how molecular programs change over time.  \n\nThe student will develop algorithms using Python and PyTorch, with Monocle3 and scVelo for trajectory modelling. \n\nhttps://github.com/cole-trapnell-lab/monocle3\nhttps://github.com/theislab/scvelo_notebooks\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on gene expression analysis in the brain development\n\n(b) Development component\nThe student will develop algorithms using Python and PyTorch, with Monocle3 and scVelo for trajectory modelling.",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Data Analytics",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0578",
    "title": "Predicting Brain Network Heritability from fMRI and Genetics",
    "summary": "Understanding the genetic basis of functional brain connectivity is crucial for uncovering how inherited traits shape neural dynamics. In this project, we will develop graph-based predictive models to estimate brain network heritability from functional MRI (fMRI) and genetic data. Using data from the Human Connectome Project (HCP), we will integrate functional connectomes with genomic profiles (e.g., polygenic scores, gene expression data) to predict the heritability of large-scale brain networks.\n\nWe will leverage graph neural networks (GNNs), structural equation modelling (SEM), and genome-wide association study (GWAS) embeddings to establish relationships between genetic variations and dynamic functional connectivity patterns. Validation will be conducted using heritability estimation methods such as ACE models and twin-based comparisons. Additionally, explainability techniques (e.g., SHAP, attention mechanisms) will be employed to highlight the genetic markers most relevant to brain network organization.\n\nThe student will develop algorithms using Python, PyTorch Geometric, HCP Workbench, and PLINK for genomic analysis.\n\nhttps://www.humanconnectome.org/\nhttps://academic.oup.com/cercor/article/31/1/77/5892625?login=false\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on combining functional brain images and genetic data to predict brain network heritability\n\n(b) Development component\nThe student will develop algorithms using Python, PyTorch Geometric, HCP Workbench, and PLINK for genomic analysis.",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Image Analysis &amp; Processing",
      "Computational Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0579",
    "title": "Bias Detection in Machine Learning Models",
    "summary": "Bias in machine learning models is a major concern in AI deployment, affecting hiring systems, financial lending, and law enforcement. This project aims to develop a tool that identifies and mitigates biases in datasets and AI models. Students will use fairness-aware machine learning techniques to evaluate datasets for gender, racial, and socioeconomic biases. They will implement bias detection techniques such as disparate impact analysis and fairness metrics like demographic parity and equal opportunity. Additionally, the project will test bias mitigation techniques like reweighting, adversarial debiasing, and data augmentation to improve fairness. The project can be applied to real-world datasets, such as hiring data, facial recognition, or credit scoring, to assess and mitigate AI bias effectively.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nFinding appropriate datasets and fairness aware tools to evaluate algorithms\n\n(b) Development component\nImplementing fairness detection techniques",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0580",
    "title": "Energy Consumption Forecasting Using Machine Learning",
    "summary": "As energy demand increases, accurate forecasting models are essential for optimizing energy distribution and consumption. This project aims to develop a predictive model using machine learning to forecast household or industrial energy consumption based on historical data. Students will use time-series forecasting methods such as ARIMA, LSTMs, and Prophet to analyze patterns in energy consumption. The system can help utility providers balance load distribution and recommend energy-saving strategies. Additionally, students can explore the impact of external factors such as weather conditions and economic trends on energy demand.\n\nSpecific details:\n(a) Design component\nfind appropriate datasets\n\n(b) Implementation component\nTesting time series forecast methods \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0581",
    "title": "AI for Detecting Deepfake Videos",
    "summary": "Deepfake technology enables the creation of realistic fake videos, posing serious risks in misinformation, fraud, and identity theft. This project involves developing a deep learning model that detects deepfake videos using convolutional neural networks (CNNs) and recurrent neural networks (RNNs). Students will analyze the differences between real and deepfake videos using feature extraction techniques and build a classifier that flags manipulated content. This project has applications in media verification, cybersecurity, and law enforcement.\n\nSpecific details:\n(a) Design component\nCollecting Dataset of real and deepfake content\n\n(b) Implementation component\nUsing Deep Learning to build a classifier for real vs deepfake content\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0582",
    "title": "Multi-stakeholder Ethical Decision Framework for AI Systems",
    "summary": "Design a platform that helps organizations evaluate AI applications against multiple ethical frameworks, regulatory requirements, and stakeholder values. This platform can be in the form of a methodological framework such as the agile methodology. The system would capture different perspectives and help identify potential conflicts or harms before deployment. \n\nSpecific details:\n(a) Design component\nDesigning an ethical AI framework\n\n(b) Implementation component\nTesting the framework against real world AI deployments\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0583",
    "title": "Efficient Fine-Tuning of Diffusion Models for Diverse Datasets and Applications",
    "summary": "Diffusion models have proven to be powerful generative models capable of producing high-quality images and data. Despite their potential, their wider applicability is hindered by slow inference times and high computational costs during training. This project aims to address these challenges by exploring the latest advancements in fine-tuning diffusion models. The goal is to develop a computationally efficient approach that adapts diffusion models to new datasets and problem settings without compromising performance. By leveraging state-of-the-art techniques, this project seeks to enhance the practicality and efficiency of diffusion models in various applications.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThis project will involve a comprehensive review of current fine-tuning methods, followed by the design and implementation of an optimized fine-tuning strategy. The effectiveness of the proposed approach will be evaluated on multiple datasets to ensure its robustness and efficiency.",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining",
      "Machine Learning",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0584",
    "title": "protein design via constrained denoising diffusion probabilistic models",
    "summary": "The proposed research aims to develop a framework for constrained protein design using diffusion probabilistic models, to provide effective targets for potential applications such as therapeutics and protein engineering. Denoising diffusion probabilistic models (DDPM) are emerging as a powerful class of generative models in areas such as image and text to image synthesis (DALL-E 2, IMAGEN) [1, 2]. Recently, DDPM have been used to design protein backbones, as they allow effective sampling of novel protein folds [3],[4]. Although valuable, these methods contain several limitations, particularly in the applicability of the generated protein structures to real world scenarios, as such proteins do not meet the functional constraints, or chemical characteristics that pass the screen of applicable consideration.\n\nSpecific details:\nTo propose a framework that addresses the issue of incorporating functional constraints in an integrated way. The framework will also develop a library of constraints (site-specific mutation information and predicted docking energies) that can serve as special bias for protein design. This study builds upon our previous work incorporating prior knowledge of mutations of Influenza genomic sequence to build a predictive model [5].\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0585",
    "title": "Attention-based Generative Model for Antibody Sequence-Structure Co-design",
    "summary": "To accelerate the computational process for antibody discovery, antibody-antigen binding affinity is significant and associated with the design of antibodies. A contrastive self-supervised learning model will be adapted for discovering (monoclonal) antibodies with high-binding affinity and specificity for the target antigen. \n\nSpecific details:\no achieve antibody diversity and conduct rational design of antibodies, we will be applying a cross-attention network model to study pairing preferences between the antibody variable domain of light chain (VL) and variable domain of heavy chain (VH). Adopting rational instead of de novo antibody design reduces cost and at the same time improves computational efficiency and scalability. Last but not least, we will evaluate the generated or predicted structures with molecular dynamics (MD) simulations and experimentally validate or identify high potential candidates suitable for further clinical applications.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Data Mining",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0586",
    "title": "Graph-Based Antibody Design",
    "summary": "Objective: Develop a graph-based generative model for designing complementarity-determining regions (CDRs) of antibodies with enhanced binding specificity or neutralization capabilities.\n\nSpecific details:\n○\tApproach:\n■\tRepresent CDRs as graphs, capturing sequence and 3D structural information.\n■\tIteratively refine CDR sequences while predicting their global structures.\n■\tModel conditional dependence between residues inside and outside CDRs.\n○\tExpected Outcome: Improved antibody designs for neutralizing viral proteins.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Computational Biology",
      "Graph Theory",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0587",
    "title": "Attention-Based Model for Predicting Drug-Target Interactions",
    "summary": "Utilizing Attention Mechanisms for Enhanced Prediction of Drug-Target Interactions.\n\nThis project aims to develop a deep learning model using attention mechanisms to improve the prediction of drug-target interactions, which is crucial for identifying potential therapeutic compounds. \n\nSpecific details:\nBy focusing on the interactions between small molecule drugs and protein targets, students will explore the use of self-supervised learning techniques to overcome challenges related to the scarcity of labeled datasets in this domain. The project will involve training models to understand and predict how drugs interact with their protein targets, which can significantly accelerate the early stages of drug discovery. This will provide practical experience in handling biochemical data and applying advanced machine learning techniques to a critical problem in pharmacology.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0588",
    "title": "Predictive Model for Protein-Ligand Interactions Using Constrained DDPM",
    "summary": "Create a predictive model for protein-ligand interactions by combining DDPM with ligand-specific constraints for Functional Constraints-Driven Protein Design for Therapeutics\n\nSpecific details:\n○\tMethodology:\n■\tGather data on protein-ligand complexes (e.g., PDB structures).\n■\tExtract ligand-binding sites and interaction patterns.\n■\tDevelop a constrained DDPM that generates protein conformations compatible with ligand binding.\n■\tValidate the model's predictions against experimental binding affinities.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Machine Learning",
      "Systems Biology"
    ]
  },
  {
    "projectNo": "CCDS25-0590",
    "title": "Machine Learning Prediction of Antibody Heavy and Light Chain Pairs Using Cross-Attention",
    "summary": "Objective: Develop a machine learning model to predict pairing of antibody heavy and light chains from sequence data to accelerate antibody discovery using computational methods.\n\nSpecific details:\n○\tApproach:\n■\tUse weighted nearest neighbor or random forest methods.\n■\tEvaluate on a dataset of antibodies interacting with antigens.\n○\tExpected Outcome: Predictive tool for antibody-antigen interactions.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0591",
    "title": "Improve protein generation by taking functional constraints (binding free energies) into account using diffusion models",
    "summary": "Improve protein generation by taking functional constraints (binding free energies) into account using diffusion models, focusing on the binding of proteins to ligands\n\nSpecific details:\n○\tApproach:\n■\tTrain on millions of protein sequences to generate diverse antibody sequences.\n■\tFocus on variable-length spans of antibody sequences.\n○\tExpected Outcome: A tool for rapid antibody sequence generation.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0592",
    "title": "Efficient Fine-Tuning of Diffusion Models for Diverse Datasets and Applications",
    "summary": "Diffusion models have proven to be powerful generative models capable of producing high-quality images and data. Despite their potential, their wider applicability is hindered by slow inference times and high computational costs during training. This project aims to address these challenges by exploring the latest advancements in fine-tuning diffusion models. The goal is to develop a computationally efficient approach that adapts diffusion models to new datasets and problem settings without compromising performance. By leveraging state-of-the-art techniques, this project seeks to enhance the practicality and efficiency of diffusion models in various applications.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThis project will involve a comprehensive review of current fine-tuning methods, followed by the design and implementation of an optimized fine-tuning strategy. The effectiveness of the proposed approach will be evaluated on multiple datasets to ensure its robustness and efficiency.",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining",
      "Machine Learning",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0593",
    "title": "Attention-based Generative Model for Antibody Sequence-Structure Co-design",
    "summary": "To accelerate the computational process for antibody discovery, antibody-antigen binding affinity is significant and associated with the design of antibodies. A contrastive self-supervised learning model will be adapted for discovering (monoclonal) antibodies with high-binding affinity and specificity for the target antigen. \n\nSpecific details:\no achieve antibody diversity and conduct rational design of antibodies, we will be applying a cross-attention network model to study pairing preferences between the antibody variable domain of light chain (VL) and variable domain of heavy chain (VH). Adopting rational instead of de novo antibody design reduces cost and at the same time improves computational efficiency and scalability. Last but not least, we will evaluate the generated or predicted structures with molecular dynamics (MD) simulations and experimentally validate or identify high potential candidates suitable for further clinical applications.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Data Mining",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0594",
    "title": "Leaf Localization and Boundary Segmentation Using Deep Learning in Multimodal Plant Imagery",
    "summary": "Requied to travel and work on site. \nTo develop a robust deep learning framework for the automatic detection, localization, and segmentation of individual leaves in leafy vegetable crops using multimodal data, including RGB and Hyperspectral Imaging (HSI).\n\nSpecific details:\n1.\tData Preparation and Preprocessing\no\tUse the provided RGB, Hyperspectral (HSI), and 3D data of plants for analysis.\no\tExplore domain-specific preprocessing techniques for HSI (e.g., band selection, noise reduction).\no\tAddress challenges such as uneven lighting, leaf occlusion, and shadow effects.\n2.\tDeep Learning Model Development\no\tDesign and train state-of-the-art deep learning models like Mask R-CNN, DeepLabv3+, or U-Net to perform leaf localization and boundary segmentation in RGB images.\no\tExtend the segmentation framework to integrate hyperspectral data by using spectral attention mechanisms or combining RGB and HSI data via multimodal fusion techniques.\n3.\tIntegration of 3D Point Cloud Data\no\tFuse RGB and 3D point cloud data to enhance segmentation and improve leaf numbering accuracy.\no\tImplement geometric-based corrections using 3D data for shadowed or overlapping leaves.\n4.\tEvaluation and Optimization\no\tCompare model performance with metrics like Intersection over Union (IoU), Dice Score, and leaf count accuracy.\no\tBenchmark against traditional segmentation methods (e.g., watershed algorithm, thresholding).\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Data Analytics",
      "Data Mining",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0595",
    "title": "Multimodal Leaf Counting and Classification Using Transformer Architectures",
    "summary": "Rerquired to travel and work on site.\n\nTo implement and evaluate transformer-based architectures for leaf counting, classification, and numbering from multimodal data (RGB, HSI, and 3D).\n\nSpecific details:\n1.\tExploration of Multimodal Data\no\tInvestigate how transformer-based architectures can process heterogeneous data, combining RGB (spatial features), HSI (spectral features), and 3D point clouds (geometric features).\n2.\tModel Development\no\tBuild a Vision Transformer (ViT) or hybrid model integrating convolutional layers for initial feature extraction from RGB/HSI data.\no\tExtend to Multimodal Transformer for cross-modal attention and feature fusion (RGB + HSI + 3D).\n3.\tLeaf Numbering\no\tUse transformer-based sequence prediction (e.g., Transformer-XL or BERT-like architecture) to predict the sequence of leaf numbers from top to bottom.\no\tCombine RGB and 3D laser height profiler data to improve positional accuracy.\n4.\tAddressing Challenges\no\tImplement data augmentation techniques to tackle shadowing, occlusion, and size variability.\no\tDevelop custom loss functions to handle imbalanced data (e.g., smaller leaves vs larger ones).\n5.\tEvaluation and Benchmarking\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Data Mining",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0596",
    "title": "Plant Health Monitoring and Stress Detection Using Multimodal Data",
    "summary": "required to travel and work on site.\n\nTo design a deep learning framework for assessing plant health and detecting stress conditions (e.g., water deficiency, nutrient imbalance) by integrating RGB, HSI, and thermal imaging data.\n\nSpecific details:\n1.\tFeature Extraction from Multimodal Data\no\tUse RGB data to identify structural and color-related stress markers (e.g., wilting, discoloration).\no\tAnalyze HSI to detect spectral signatures associated with plant stress (e.g., chlorophyll absorption bands).\no\tIncorporate thermal imaging to measure plant temperature for detecting heat and water stress.\n2.\tDeep Learning for Stress Detection\no\tTrain a convolutional neural network (CNN) or transformer-based model to classify plant stress levels.\no\tIntegrate data from all modalities using multimodal fusion techniques, such as concatenation or attention-based fusion.\n3.\tVisualization and Interpretability\no\tImplement Grad-CAM or SHAP to visualize stress-related features, helping researchers identify specific stress indicators.\n4.\tValidation and Benchmarking\no\tValidate model predictions with ground-truth stress labels based on manual assessment or physiological measurements.\no\tCompare with existing stress detection models, focusing on accuracy, sensitivity, and specificity.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Kwoh Chee Keong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Data Analytics",
      "Data Mining",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0602",
    "title": "Low-Cost Cyber-Physical AV Test Bed",
    "summary": "In order to aid in the demonstration and characterization of OOD techniques for cyber-physical systems, a test bed should be constructed that allows for multiple autonomous or manually controlled agents to navigate a mock urban or highway environment and encounter various obstacles.  To accomplish this, we need several extensions to the existing Duckietown framework.  Firstly, we need a navigation algorithm for the Duckiebot that mimics actual driving and respects stop signs, lanes, and other vehicles.  Furthermore, we would like the ability to augment our Duckiebots with additional sensors such as multiple cameras or IR range finders.  Lastly, modifications should be made to the Duckietown framework itself to allow the usage of ROS 2, to enable the usage of real time scheduling.\n\nSpecific details:\nKey Tasks\n\nNavigation that respects lanes, cornering, traffic signs (stop signs, etc.), and other road traffic\nFitting existing Duckiebots with IR sensors; software library for using these sensors in research projects\nDuckietown framework running with ROS 2 instead or ROS 1\n\nSkills Required\n\nProficient in Python, C++\nExcellent understanding of OS fundamentals, particularly RTOS\nExperience developing in a POSIX environment\nExperience with embedded systems or cyber physical systems\nExperience working with ROS or some other robotics framework\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Arvind Easwaran",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0605",
    "title": "Low-power Wireless Network with Real-Time Guarantees for Edge-Cloud Applications",
    "summary": "In this project we will investigate the use of low-power wireless networks such as LoRa for use in real-time (deadline constrained) applications under the edge-cloud computing paradigm. The focus will be on the design and development of solutions specific to LoRa to enable it to be used in such settings.\n\nSpecific details:\nWe will explore literature on the use of LoRa for real-time workloads in general. We will then develop a concrete strategy for deploying LoRa in edge-cloud applications, considering both practical (LoRa specific) and deadline constraints. Finally, we will implement our solutions in a real testbed comprising several LoRa nodes, LoRa gateway devices and a backend edge-cloud infrastructure. We will also test our solutions in deployment in a real energy management case study deployed in one of the lecture theatres in NTU.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Arvind Easwaran",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Wireless and Mobile Networks",
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0607",
    "title": "Wireless Network with Real-Time Guarantees for Data-Intensive Edge-Cloud Applications",
    "summary": "In this project we will investigate the use of wireless networks such as 5G and WiFi for use in real-time (deadline constrained) applications under the edge-cloud computing paradigm. The focus will be on the design and development of solutions specific to data-intensive applications in such settings.\n\nSpecific details:\nWe will explore literature on the use of 5G/WiFi for real-time workloads in general. We will then develop a concrete strategy for deploying these protocols in edge-cloud applications, considering both practical (protocol specific) and deadline constraints. Ability to handle high data rates would be a strong requirement. Finally, we will implement our solutions in a simulation environment.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Arvind Easwaran",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Wireless and Mobile Networks",
      "Cloud Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0608",
    "title": "AI-based assisting tool to accommodate special needs of students.",
    "summary": "AI based personalised learning approach can be particularly beneficial for students with special needs, who often require a more individualized approach to learning. AI-powered tools like intelligent tutoring systems can provide personalized instruction and feedback, helping students to progress at their own pace.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component\nAim is to develop AI based tool to accomodate special needs of the students",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0609",
    "title": "AI-based Chatbot",
    "summary": "AI chatbots are programs that simulate human-like conversations using natural language processing (NLP). AI chatbots are becoming increasingly valuable to organizations for automating business processes such as customer service, sales, and human resources. AI chatbot responds to questions posed to it in natural language as if it were a real person. It responds using a combination of pre-programmed scripts and machine learning algorithms. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component\nTo develop and implement an AI chatbot which can allow site visitors to lead the conversation, voicing their intent in their own words.",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0610",
    "title": "AI based classification of Atrial Fibrillation ED",
    "summary": "This is a collaboration between NTU and Sing Health - Health Services Research Center (HSRC).  The student will have the opportunity to work with some Duke-NUS Professors/Doctors during this FYP. More details about the project will be released to the student once Non-Disclosure Agreement is signed. Till then, the details are confidential.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component\nThis will be decided on the later stage - as mentioned in the project summary",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0611",
    "title": "Chronic obstructive pulmonary disease (COPD) / Asthma Registry",
    "summary": "This is a collaboration between NTU and Sing Health - Health Services Research Center (HSRC).  The student will have the opportunity to work with some Duke-NUS Professors/Doctors during this FYP. More details about the project will be released to the student once Non-Disclosure Agreement is signed. Till then, the details are confidential.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component\nThis will be decided on the later stage - as mentioned in the project summary",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0612",
    "title": "Automated External Defibrillator (AED) optimization/demand forecasting model with Drones and OHCA demands",
    "summary": "This is a collaboration between NTU and Sing Health - Health Services Research Center (HSRC).  The student will have the opportunity to work with some Duke-NUS Professors/Doctors during this FYP. More details about the project will be released to the student once Non-Disclosure Agreement is signed. Till then, the details are confidential.\nPlease note: project do not involve any design or development of Drones. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component\nThis will be decided on the later stage - as mentioned in the project summary",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0613",
    "title": "OHCA CAC Risk Scores � Developing a risk score for the triaging of Out of Hospital Cardiac Arrest (OHCA) patients in the field.",
    "summary": "This is a collaboration between NTU and Sing Health - Health Services Research Center (HSRC).  The student will have the opportunity to work with some Duke-NUS Professors/Doctors during this FYP. More details about the project will be released to the student once Non-Disclosure Agreement is signed. Till then, the details are confidential.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component\n\nThis will be decided on the later stage - as mentioned in the project summary",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0614",
    "title": "Text Data Mining Approach for Mental Health Prediction",
    "summary": "Social media has recently become a persuasive tool to inspect the mental health and mental state of the users, particularly the youth. It also provides anonymous contributions in numerous online platforms to leave room for open dialog regarding socially defamed topics and motivate users to fight against mental health problems. In addition, patients can share their ideas about the recent common health problems. Several systems based on machine learning and social media platforms have recently been introduced to identify health-related problems such as the detection of depression and anxiety.  However, the data published on social networking sites on mental-health-related problems contain unstructured, unpredictable data, thus need a smart approach that is capable of retrieving the most valuable data to detect mental health status.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nto conduct a research on the methods available on text mining which can be applied to social media, websites, news blogs.\n\n(b) Development component\nto develop an algorithm which can perform the text features extraction to identify the possible metal status using AI techniques.",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Natural Language Processing/ Text Mining",
      "Data Mining",
      "Data Analytics",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0615",
    "title": "Impact of post COVID digital orientation on student's learning",
    "summary": "Students' inclination to digital usage became severe during COVID time and now the post COVID, students are more dependent in digital tools for each stage of their learning. Impact of these digital orientation has affected severely in student's learning in many angles. The question still remains - how much is the impact? which needs to be studied. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nIn this study, a survey and qualitative/quantitative analysis need to be conducted to find out the way digital orientation has affected student's learning - in terms of - impact on their handwriting and critical thinking ability.\n(b) Development component",
    "supervisor": "Dr Vidya Sudarshan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0616",
    "title": "LLM-Powered Resume Analyzer",
    "summary": "Develop an LLM-based resume analyzer that evaluates resumes and provides feedback on structure, skills, and keywords for better job matching. The system will leverage LLM models like LLAMA  or GPT to assess resumes against job descriptions, and help job seekers to improve their resumes\n\nSpecific details:\n(a) Design component\ngathering dataset of resumes\n\n(b) Implementation component\nselecting suitable LLMs to finetune to task of resume evaluation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0617",
    "title": "Explainable AI for Credit Scoring",
    "summary": "Credit scoring models are often criticized for their lack of transparency, leading to concerns about fairness and discrimination in lending. This project focuses on building an interpretable AI model for credit scoring using Explainable AI (XAI) techniques. Students will analyze traditional credit scoring models and integrate tools like SHAP (SHapley Additive Explanations) and LIME (Local Interpretable Model-Agnostic Explanations) to explain how AI models determine creditworthiness. They will also explore bias mitigation techniques to ensure fair lending practices. The final system should allow financial institutions to understand and justify their credit approval decisions while ensuring compliance with ethical AI principles.\n\nSpecific details:\n(a) Design component\ngathering explainable AI techniques\n\n(b) Implementation component\ntraining explainable AI models for credit scoring\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0618",
    "title": "Bias and Explainability in Facial Recognition Systems",
    "summary": "Facial recognition AI has been criticized for biases against certain ethnicities and genders. This project explores bias in facial recognition models and proposes fairness-enhancing solutions. Students will train and evaluate facial recognition models using fairness-aware datasets (e.g., FairFace) and apply explainability techniques to understand misclassifications. Potential solutions include balanced dataset augmentation and bias-aware loss functions.\n\nSpecific details:\n(a) Design component\nfinding datasets such as fairface\n\n(b) Implementation component\ntrain and evaluate facial recognition algorithms\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0619",
    "title": "Privacy-Preserving AI for Disease Prediction",
    "summary": "Medical AI systems require large datasets but must comply with privacy regulations. This project involves implementing federated learning for healthcare AI, allowing decentralized model training without data sharing. Students will build a privacy-preserving AI model for disease prediction using real-world medical datasets while implementing techniques like differential privacy.\n\nSpecific details:\n(a) Design component\ngathering medical datasets\n\n(b) Implementation component\nimplement privacy preserving algorithms\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0620",
    "title": "Chinese Remainder Theorem (2)",
    "summary": "Study the Chinese Remainder Theorem as the\noriginal theorem dealing with integers. Then, its expansion and application into rings,\nprincipal ideal domains, and Dedekind Domains will be discussed. Finally, we will see how\nthe theorem, as a secret-sharing scheme, takes part in the development of cryptography.\n\nSpecific details:\n(a) Design component\nDesign the system to be used in cryptography.\n\n(b) Implementation component\nImplement and test\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0621",
    "title": "Chinese Remainder Theorem (1)",
    "summary": "Study the Chinese Remainder Theorem as the\noriginal theorem dealing with integers. Then, its expansion and application into rings,\nprincipal ideal domains, and Dedekind Domains will be discussed. Finally, we will see how\nthe theorem, as a secret-sharing scheme, takes part in the development of cryptography.\n\nSpecific details:\n(a) Design component\nDesign the system to be used in cryptography.\n\n(b) Implementation component\nImplement and test\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Cyber Security"
    ]
  },
  {
    "projectNo": "CCDS25-0622",
    "title": "Suffix Arrays and Applications (2)",
    "summary": "Suffix Array is a sorted array of all suffixes of a given (usually long) text string T of length n characters (n can be in order of hundred thousands characters).\n\nSuffix Array is a simple, yet powerful data structure which is used, among others, in full text indices, data compression algorithms, and within the field of bioinformatics.\n\nWe study the use of suffix arrays in applications.\n\nSpecific details:\n(a) Design component\nDesign the data structures in an application\n\n(b) Implementation component\nImplement the data structures and operations to manipulate them\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0623",
    "title": "Suffix Arrays and Applications (1)",
    "summary": "Suffix Array is a sorted array of all suffixes of a given (usually long) text string T of length n characters (n can be in order of hundred thousands characters).\n\nSuffix Array is a simple, yet powerful data structure which is used, among others, in full text indices, data compression algorithms, and within the field of bioinformatics.\n\nWe study the use of suffix arrays in applications.\n\nSpecific details:\n(a) Design component\nDesign the data structures in an application\n\n(b) Implementation component\nImplement the data structures and operations to manipulate them\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0624",
    "title": "AI-Powered Mental Health Chatbot",
    "summary": "Develop a chatbot that uses natural language processing to identify signs of mental health issues in conversation, providing appropriate resources and coping strategies. The system would respect privacy while offering personalized support for common concerns like anxiety and depression based on conversational patterns. Students will implement sentiment analysis, intent recognition, and context-aware responses.\n\nSpecific details:\n(a) Design component\ndesign frontend user facing interface\n\n(b) Implementation component\nfinding suitable LLMs for mental health\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0625",
    "title": "Student proposed project (1)",
    "summary": "The student is free to propose the project work in the area of data structures and algorithms, artificial intelligence, optimization, simulation, applications. \n\nSpecific details:\n(a) Design component\nDesign of data structures and algorithms\n\n(b) Implementation component\nImplementation of the design\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Artificial Intelligence",
      "Programming Languages &amp; Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0626",
    "title": "Student proposed project (2)",
    "summary": "The student is free to propose the project work in the area of data structures and algorithms, artificial intelligence, optimization, simulation, applications. \n\nSpecific details:\n(a) Design component\nDesign of data structures and algorithms\n\n(b) Implementation component\nImplementation of the design\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0627",
    "title": "Student proposed project (3)",
    "summary": "The project tile will be proposed by the student in the area of AI, data structures and algorithms.  The student will need to discuss the project objectives with me and we agree on the project area and title.\n\nSpecific details:\n(a) Design component\nNeed to design something new and useful\n\n(b) Implementation component\nimplenment it and evaluate.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0628",
    "title": "Personalized Healthcare Recommendation System",
    "summary": "Create an AI system that analyzes medical records and lifestyle data to provide personalized health recommendations. The platform would respect privacy while offering evidence-based suggestions for improving health outcomes based on individual risk factors.\n\nSpecific details:\n(a) Design component\ndesigning interface for user \n\n(b) Implementation component\ntraining models for this task\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0629",
    "title": "Gesture-Based Computing Interface for Accessibility",
    "summary": "Design a computer interface that uses computer vision to interpret hand gestures and facial expressions for people with motor disabilities. The system would enable natural interaction with digital devices without traditional input methods.\n\nSpecific details:\n(a) Design component\nDesign a interface\n\n(b) Implementation component\nchoosing CV models\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0630",
    "title": "Shortest Dubins Path for forward moving robots",
    "summary": "We study the problem of computing\noptimal paths through three consecutive points for the\ncurvature-constrained forward moving Dubins vehicle. Given\ninitial and final configurations of the Dubins vehicle, and a\nmidpoint with an unconstrained heading, the objective is to\ncompute the midpoint heading that minimizes the total Dubins\npath length.  The additional constraint to consider is the speed of the robot on the various segments of the path.\n\nSpecific details:\n(a) Design component\nDesign the algorithm to compute the three-point Dubins paths\n\n(b) Implementation component\nCoding and testing by simulation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0631",
    "title": "Federated Data Science for SMEs Collaboration",
    "summary": "Create a platform enabling small and medium enterprises to collaboratively train machine learning models without sharing sensitive business data. The system would help smaller organizations benefit from collective intelligence while maintaining competitive advantages.\n\nSpecific details:\n(a) Design component\nDesigning a federated learning system\n\n(b) Implementation component\nCollaboratively training ML models\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0632",
    "title": "Heuristic algorithm for routing a robotic car that goes both forward and backward",
    "summary": "The path taken by a car with a given minimum turning radius has a lower bound on its radius of curvature at each point, but the path has cusps if the car shifts into or out of reverse gear. What is the shortest such path a car can travel between two points if its starting and ending directions are specified? Instead of finding a shortest path, we design a simple heuristic and fast algorithm algorithm.\n\nSpecific details:\n(a) Design component\nDesign the algorithm to compute the shortest path\n\n(b) Implementation component\nCoding and testing by simulation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0633",
    "title": "Optimal paths for a car that goes both forward and backward",
    "summary": "The path taken by a car with a given minimum turning radius has a lower bound on its radius of curvature at each point, but the path has cusps if the car shifts into or out of reverse gear. What is the shortest such path a car can travel between two points if its starting and ending directions are specified? One need to consider only paths with at most 2 cusps or reversals. We give a set of paths which is sufficient in the sense that it always contains a shortest path and small in the sense that there are at most 68, but usually many fewer paths in the set for any pair of endpoints and directions. We give these paths by explicit formula. Calculating the length of each of these paths and selecting the (not necessarily unique) path with smallest length yields a simple algorithm for a shortest path in each case.\n\nSpecific details:\n(a) Design component\nDesign the algorithm to compute the shortest path\n\n(b) Implementation component\nCoding and testing by simulation\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0634",
    "title": "AI Lifecycle Governance Platform",
    "summary": "Develop a comprehensive system for managing the entire lifecycle of AI applications, from data collection and model development to deployment and monitoring. The platform would enforce ethical guidelines, track model changes, and facilitate regulatory compliance.\n\nSpecific details:\n(a) Design component\nDesign workflow management system\n\n(b) Implementation component\nSoftware Engineering and backend\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0635",
    "title": "Domain-Specific LLM Fine-Tuning Framework",
    "summary": "Develop a systematic framework for efficiently fine-tuning large language models for specialized domains like healthcare, legal, or engineering fields in Singapore's context. The project would optimize techniques for adapting foundation models using minimal domain data while ensuring accuracy and reliability.\n\nSpecific details:\n(a) Design component\ndesigning frameworks\n\n(b) Implementation component\nselecting LLMs for this task\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Others (please describe in project)",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0636",
    "title": "Cross-Modal Reasoning with LLMs and Computer Vision",
    "summary": "Build a system that combines large language models with computer vision to perform complex reasoning tasks across text and visual data, such as detailed scene understanding or visual problem-solving.\n\nSpecific details:\n(a) Design component\ndesign multimodal datasets\n\n(b) Implementation component\nselecting LLM and CV models for this task\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0637",
    "title": "Synthetic Training Data Generation for Specialized Domains",
    "summary": "Build a framework that uses large language models to generate high-quality synthetic training data for domains where real data is scarce, sensitive, or expensive to collect such as rare medical conditions.\n\nSpecific details:\n(a) Design component\nDesign Framework\n\n(b) Implementation component\nFinetuning LLMs to generate data\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Mining",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0638",
    "title": "LLM Agent Collaboration Framework",
    "summary": "Create a system where multiple specialized LLM-based agents collaborate to solve complex problems, combining domain expertise while maintaining coherent reasoning and consistent outputs.\n\nSpecific details:\n(a) Design component\nDesign LLM agents\n\n(b) Implementation component\nTraining multiple agents to collaborate\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Zhang Jiehuang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0639",
    "title": "Topological Sorting",
    "summary": "Given a Directed Acyclic Graph having V vertices and E edges, your task is to find any Topological Sorted order of the graph.\n\nTopological Sorted order: It is a linear ordering of vertices such that for every directed edge u -&gt; v, where vertex u comes before v in the ordering.\n\nThe canonical application of topological sorting is in scheduling a sequence of jobs or tasks based on their dependencies. The jobs are represented by vertices, and there is an edge from x to y if job x must be completed before job y can be started.\n\nWe use the algorithm in applications.\n\nSpecific details:\n(a) Design component\nDesign the code for the sorting in various ways, search for the application\n\n(b) Implementation component\nImplement and evaluate.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0640",
    "title": "Topological Sorting (2)",
    "summary": "Given a Directed Acyclic Graph having V vertices and E edges, your task is to find any Topological Sorted order of the graph.\n\nTopological Sorted order: It is a linear ordering of vertices such that for every directed edge u -&gt; v, where vertex u comes before v in the ordering.\n\nThe canonical application of topological sorting is in scheduling a sequence of jobs or tasks based on their dependencies. The jobs are represented by vertices, and there is an edge from x to y if job x must be completed before job y can be started.\n\nWe use the algorithm in applications.\n\nSpecific details:\n(a) Design component\nDesign the code for the sorting in various ways, search for the application\n\n(b) Implementation component\nImplement and evaluate.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Structure and Algorithms",
      "Distributed Computing Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0641",
    "title": "Bias problems in Large Language Models and how to mitigate them",
    "summary": "Large pre-trained language models (PLMs) such as GPT3 and LLaMA have taken Natural Language Processing (NLP) by storm, achieving significant improvement gains for various NLP applications, with the notable example of ChatGPT. Besides the bright side, recent work has shown PLMs capture social biases from the large amounts of text they are trained on, reflect discriminatory or unfair behaviour toward certain groups or populations based on their inherent characteristics. However, current studies about the bias problem of PLMs have not been investigated thoroughly. In this study, we aim to understand the biases in the PLMs and propose effective approaches to alleviate them\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearch bias problem in LLMs\n\n(b) Development component\nDevelop models for debiasing",
    "supervisor": "Ast/P Luu Anh Tuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0642",
    "title": "Trustworthy of Large Language Models",
    "summary": "The rise of Large Language Models (LLMs) such as GPT, LLaMA , and PaLM has revolutionized the field of natural language processing. They can be used for question answering, chat-bots, text summarization, translation, and even programming. And yet, LLMs can generate plausible text even without any link to reality. This phenomenon is called hallucination. In this project, we will study the hallucination problem of LLMs and how to mitigate and verify them\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudy the trustworthy problem of LLMs\n\n(b) Development component\nDevelop models to increase trustworthy of LLMs",
    "supervisor": "Ast/P Luu Anh Tuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0643",
    "title": "Trustworthy of Large Language Models",
    "summary": "The rise of Large Language Models (LLMs) such as GPT, LLaMA , and PaLM has revolutionized the field of natural language processing. They can be used for question answering, chat-bots, text summarization, translation, and even programming. And yet, LLMs can generate plausible text even without any link to reality. This phenomenon is called hallucination. In this project, we will study the hallucination problem of LLMs and how to mitigate and verify them\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudy the trustworthy problem of LLMs\n\n(b) Development component\nDevelop models to increase trustworthy of LLMs",
    "supervisor": "Ast/P Luu Anh Tuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0644",
    "title": "Bias problems in Large Language Models and how to mitigate them",
    "summary": "Large pre-trained language models (PLMs) such as GPT3 and LLaMA have taken Natural Language Processing (NLP) by storm, achieving significant improvement gains for various NLP applications, with the notable example of ChatGPT. Besides the bright side, recent work has shown PLMs capture social biases from the large amounts of text they are trained on, reflect discriminatory or unfair behaviour toward certain groups or populations based on their inherent characteristics. However, current studies about the bias problem of PLMs have not been investigated thoroughly. In this study, we aim to understand the biases in the PLMs and propose effective approaches to alleviate them\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearch bias problem in LLMs\n\n(b) Development component\nDevelop models for debiasing",
    "supervisor": "Ast/P Luu Anh Tuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0645",
    "title": "Deep Learning Techniques for Hate Speech detection",
    "summary": "In this project, we will investigate the methods for automatic hate speech detection in text. Specifically, we will investigate current available datasets and modern deep learning architectures that can be used to solve the problem.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Datasets\n- Deep learning models\n\n(b) Development component\n- Models to detect hate speech",
    "supervisor": "Ast/P Luu Anh Tuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0646",
    "title": "Deep Learning Techniques for Hate Speech detection",
    "summary": "In this project, we will investigate the methods for automatic hate speech detection in text. Specifically, we will investigate current available datasets and modern deep learning architectures that can be used to solve the problem.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Datasets\n- Deep learning models\n\n(b) Development component\n- Models to detect hate speech",
    "supervisor": "Ast/P Luu Anh Tuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0647",
    "title": "Automated Testing of Cross-Language Communications in RPC Frameworks",
    "summary": "Remote Procedure Call (RPC) is a software communication protocol that one program can use to request a service from a program located in another computer on a network without having to understand the network's details. RPC uses the client-server model. The requesting program is a client, and the service-providing program is the server. The client and server may use different programming languages. Popular open-source RPC frameworks include gRPC and Apache Thrift. In this project, we build on a systematic automated testing platform in order to discover potential implementation bugs in these frameworks, specifically for cross-language communications. \n\nSpecific details:\n(a) Design component\n\nDesign templates for effective test generation.\n\n(b) Implementation component\n\nExtend testing platform to handle different programming languages for both RPC client and server.\n\n(a) Research component\n\n\n\n(b) Development component",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Program Analysis and Optimization",
      "Logic and Formal Methods",
      "Programming Languages &amp; Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0648",
    "title": "Capture the Flag Challenge Design and Implementation",
    "summary": "Capture the flag (CTF) competitions can help improve security skills and identify talents. We often hold such competitions as a part of the software security education. In this project, we plan to look at common approaches for designing CTF challenges and propose novel techniques for generating interesting and challenging CTF problems.\n\nSpecific details:\n(a) Design component\n\nApproaches for generating interesting and challenging CTF problems.\n\n(b) Implementation component\n\nBuild a collection of CTF challenges and toolkits for question generation.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Cyber Security",
      "Software and Applications",
      "System Security",
      "Gamification"
    ]
  },
  {
    "projectNo": "CCDS25-0649",
    "title": "An exploratory study of DeFi protocols",
    "summary": "Decentralized finance (DeFi) has become one of the most\nsuccessful applications of blockchain and smart contracts. \nThe DeFi ecosystem enables a wide range of crypto-financial activities, while the underlying smart contracts often contain bugs, with many vulnerabilities arising from the unforeseen consequences of composing DeFi protocols together.\nIn this project, we perform an exploratory study on the security, fariness, and economics in the DeFi market.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nStudy pressing issues in the DeFi  ecosystem; collect data and analyze with case studies.\n\n(b) Development component\n\nDevelop automated tools to analyze DeFi transactions, finding anomalies and irregular events.",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Blockchain",
      "Cyber Security",
      "Data Analytics",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0650",
    "title": "Code-Documentation Inconsistency Checking for Python Data Science Libraries",
    "summary": "Many machine learning and data science libraries are written in Python, for example, scikit-learn. The APIs in these libraries often have non-trivial usage constraints. Users of these libraries rely heavily on the documentation to be able to use them correctly. But there are often inconsistencies between the library code and the corresponding documentation, which makes the usages of the APIs troublesome. In this project, we would like to automatically discover these inconsistencies by leveraging the power of LLMs and advanced program analysis.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDesign algorithms for doc-code inconsistency checking.\n\n(b) Development component\n\nDevelop  doc-code inconsistency checking pipelines and evaluation on real-world data.",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Software and Applications",
      "Information Retrieval/ Processing",
      "Program Analysis and Optimization"
    ]
  },
  {
    "projectNo": "CCDS25-0651",
    "title": "An Exploratory Study on Smart Legal Contracts",
    "summary": "Smart contracts have shown great potential in revolutionizing the legal environment, by streamlining processes, reducing costs, and increasing transparency and efficiency. A smart contract can be viewed as a self-executing agreement with the terms of the contract written directly into code. When certain conditions are met, the contract automatically executes, ensuring the agreed-upon actions are carried out without the need for intermediaries or manual intervention. One of the prominent attempt on smart legal contract is the Accord Project (https://accordproject.org/). In this project, we would like to perform systematic study on smart legal contracts to better understand the challenges and opportunities in this space.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nStudy how smart legal contracts are used in practice. Understand their limitations.\n\n(b) Development component\n\nDevelop semi-automatic translation from traditional legal agreement to smart legal contracts",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Blockchain",
      "Software and Applications",
      "Logic and Formal Methods"
    ]
  },
  {
    "projectNo": "CCDS25-0653",
    "title": "Virtual Judge System for Nanyang Programming Contests (1)",
    "summary": "This project is to create a virtual judge system for the Nanyang Programming Contests series.\n\nThe system will allow judges to sourse contest problems from various platforms, support clarifications during contests, support customised scoring rules and a number of other features and have a good load balance mechanism.\n\nThis is a team project requiring up to 6 students, preferrably students who are familiar with competitive programming.  It is also preferred that a student has done SC4051 Distributed Systems.\n\nStudents should start the project once allocated and more or less complete it by end of December. So if you are doing MDP in semester 1, it will not be very suitable.\n\nSpecific details:\n(a) Design component\nDesign the system architecture\n\n(b) Implementation component\nImplement various components\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Distributed Computing Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0654",
    "title": "Virtual Judge System for Nanyang Programming Contests (2)",
    "summary": "This project is to create a virtual judge system for the Nanyang Programming Contests series.\n\nThe system will allow judges to sourse contest problems from various platforms, support clarifications during contests, support customised scoring rules and a number of other features and have a good load balance mechanism.\n\nThis is a team project requiring up to 6 students, preferrably students who are familiar with competitive programming.  It is also preferred that a student has done SC4051 Distributed Systems.\n\nStudents should start the project once allocated and more or less complete it by end of December. So if you are doing MDP in semester 1, it will not be very suitable.\n\nSpecific details:\n(a) Design component\nDesign the system architecture\n\n(b) Implementation component\nImplement various components\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Distributed Computing Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0655",
    "title": "Virtual Judge System for Nanyang Programming Contests (3)",
    "summary": "This project is to create a virtual judge system for the Nanyang Programming Contests series.\n\nThe system will allow judges to sourse contest problems from various platforms, support clarifications during contests, support customised scoring rules and a number of other features and have a good load balance mechanism.\n\nThis is a team project requiring up to 6 students, preferrably students who are familiar with competitive programming.  It is also preferred that a student has done SC4051 Distributed Systems.\n\nStudents should start the project once allocated and more or less complete it by end of December. So if you are doing MDP in semester 1, it will not be very suitable.\n\nSpecific details:\n(a) Design component\nDesign the system architecture\n\n(b) Implementation component\nImplement various components\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Distributed Computing Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0656",
    "title": "Virtual Judge System for Nanyang Programming Contests (4)",
    "summary": "This project is to create a virtual judge system for the Nanyang Programming Contests series.\n\nThe system will allow judges to sourse contest problems from various platforms, support clarifications during contests, support customised scoring rules and a number of other features and have a good load balance mechanism.\n\nThis is a team project requiring up to 6 students, preferrably students who are familiar with competitive programming.  It is also preferred that a student has done SC4051 Distributed Systems.\n\nStudents should start the project once allocated and more or less complete it by end of December. So if you are doing MDP in semester 1, it will not be very suitable.\n\nSpecific details:\n(a) Design component\nDesign the system architecture\n\n(b) Implementation component\nImplement various components\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Distributed Computing Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0657",
    "title": "Virtual Judge System for Nanyang Programming Contests (5)",
    "summary": "This project is to create a virtual judge system for the Nanyang Programming Contests series.\n\nThe system will allow judges to sourse contest problems from various platforms, support clarifications during contests, support customised scoring rules and a number of other features and have a good load balance mechanism.\n\nThis is a team project requiring up to 6 students, preferrably students who are familiar with competitive programming.  It is also preferred that a student has done SC4051 Distributed Systems.\n\nStudents should start the project once allocated and more or less complete it by end of December. So if you are doing MDP in semester 1, it will not be very suitable.\n\nSpecific details:\n(a) Design component\nDesign the system architecture\n\n(b) Implementation component\nImplement various components\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Distributed Computing Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0658",
    "title": "TinyML based computer vision system",
    "summary": "This project is to develop an vision based object detection system using Machine Learning running on small microcontroller - TinyML.\n\nThe project involves the design and implementation of ML based algorithm.\n\nThe project is more suitable for CE student.\n\nSpecific details:\n(a) Design component\nOptimization of ML model for microcontroller\n\n(b) Implementation component\nSystem will run on resource constraint microcontroller to do inference\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Vun Chan Hua, Nicholas",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Machine Learning",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0659",
    "title": "Virtual Judge System for Nanyang Programming Contests (6)",
    "summary": "This project is to create a virtual judge system for the Nanyang Programming Contests series.\n\nThe system will allow judges to sourse contest problems from various platforms, support clarifications during contests, support customised scoring rules and a number of other features and have a good load balance mechanism.\n\nThis is a team project requiring up to 6 students, preferrably students who are familiar with competitive programming.  It is also preferred that a student has done SC4051 Distributed Systems.\n\nStudents should start the project once allocated and more or less complete it by end of December. So if you are doing MDP in semester 1, it will not be very suitable.\n\nSpecific details:\n(a) Design component\nDesign the system architecture\n\n(b) Implementation component\nImplement various components\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Huang Shell Ying",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Distributed Computing Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0660",
    "title": "AI Accelerator on FPGA",
    "summary": "This project is to implement an AI accelerator for embedded processor. The student will first learn about the functions used in typical AI inference operation, and design the system required to efficiently execute the inference operation,\n\nSpecific details:\n(a) Design component\nAI accelerator operating principles and system design\n\n(b) Implementation component\nFPGA board\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Vun Chan Hua, Nicholas",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Design & Implementation",
    "keywords": [
      "Hardware Acceleration",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0661",
    "title": "Prompt Engineering Tool for LLM Agents 1",
    "summary": "This project involves developing a tool to streamline the process of designing, testing, and optimizing prompts for Large Language Model (LLM) agents. The tool will provide features for creating and managing prompts, along with functionality to interact with LLM APIs and evaluate prompt effectiveness. The Key Objectives includes:\n�\tDevelop a library of prompt templates.\n�\tIntegrate with LLM APIs for prompt testing.\n�\tImplement prompt evaluation metrics and version control.\nThis project shall address a crucial aspect of LLM agent development by providing a practical tool to improve prompt engineering workflows.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0662",
    "title": "Web Browser Assessment Testing: Python",
    "summary": "In automated assessment systems (APAS), the user will code their program in a web browser interface and be compiled and evaluated on a centralized server. During the coding, the users may send multiple requests to the server to evaluate their test cases. Hence, there is a user requirement for the response time of the testing. In addition, the demand for highly responsive server-side evaluation will lead to high computational requirements on the server side. To alleviate this workload, a client-side testing tool will be developed to run in the web browser to evaluate the test cases on the client's web browser; only the final assessment will be performed on the server.\n\nSpecific details:\n(a) Design component\n- Identify compiler that can work in the browser (e.g., supported to run in WASM).\n- Identify suitable runtime environment (e.g., need to evaluate under a linux environment)\n\n(b) Implementation component\n- Cross-compile an existing light-weight compiler to run under WASM\n- Setup suitable runtime environment to run the test cases\n- Integrate compiler and runtime environment with a web-based IDE\n- Validate the text results are correct\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Programming Languages &amp; Systems",
      "Program Analysis and Optimization",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0663",
    "title": "Web Browser Assessment Testing: C",
    "summary": "In automated assessment systems (APAS), the user will code their program in a web browser interface and be compiled and evaluated on a centralized server. During the coding, the users may send multiple requests to the server to evaluate their test cases. Hence, there is a user requirement for the response time of the testing. In addition, the demand for highly responsive server-side evaluation will lead to high computational requirements on the server side. To alleviate this workload, a client-side testing tool will be developed to run in the web browser to evaluate the test cases on the client's web browser; only the final assessment will be performed on the server.\n\nSpecific details:\n(a) Design component\n- Identify compiler that can work in the browser (e.g., supported to run in WASM).\n- Identify suitable runtime environment (e.g., need to evaluate under a linux environment)\n\n(b) Implementation component\n- Cross-compile an existing light-weight compiler to run under WASM\n- Setup suitable runtime environment to run the test cases\n- Integrate compiler and runtime environment with a web-based IDE\n- Validate the text results are correct\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Program Analysis and Optimization",
      "Programming Languages &amp; Systems",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0664",
    "title": "Web-browser Assessment Testing: Java",
    "summary": "In automated assessment systems (APAS), the user will code their program in a web browser interface and be compiled and evaluated on a centralized server. During the coding, the users may send multiple requests to the server to evaluate their test cases. Hence, there is a user requirement for the response time of the testing. In addition, the demand for highly responsive server-side evaluation will lead to high computational requirements on the server side. To alleviate this workload, a client-side testing tool will be developed to run in the web browser to evaluate the test cases on the client's web browser; only the final assessment will be performed on the server.\n\nSpecific details:\n(a) Design component\n- Identify compiler that can work in the browser (e.g., supported to run in WASM).\n- Identify suitable runtime environment (e.g., need to evaluate under a linux environment)\n\n\n(b) Implementation component\n- Cross-compile an existing light-weight compiler to run under WASM\n- Setup suitable runtime environment to run the test cases\n- Integrate compiler and runtime environment with a web-based IDE\n- Validate the text results are correct\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Program Analysis and Optimization",
      "Programming Languages &amp; Systems",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0665",
    "title": "Web-browser Assessment Testing: SQL",
    "summary": "In automated assessment systems (APAS), the user will code their program in a web browser interface and be compiled and evaluated on a centralized server. During the coding, the users may send multiple requests to the server to evaluate their test cases. Hence, there is a user requirement for the response time of the testing. In addition, the demand for highly responsive server-side evaluation will lead to high computational requirements on the server side. To alleviate this workload, a client-side testing tool will be developed to run in the web browser to evaluate the test cases on the client's web browser; only the final assessment will be performed on the server.\n\nSpecific details:\n(a) Design component\n- Identify suitable SQL server that can work in the browser (e.g., supported to run in WASM).\n- Identify suitable runtime environment (e.g., need to evaluate under a linux environment)\n\n(b) Implementation component\n- Cross-compile the SQL server to run under WASM\n- Setup suitable runtime environment to run the test cases\n- Integrate SQL server and runtime environment with a web-based IDE\n- Validate the text results are correct\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Program Analysis and Optimization",
      "Programming Languages &amp; Systems",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0666",
    "title": "Exploiting acoustic signals from your smartphones for contact-free hand gesture tracking",
    "summary": "The student will use commonly seen smartphones to generate ultrasound signals that are inaudible to humans. These signals will reflect off the hands, enabling hand gesture tracking.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Know how to generate acoustic signals using smartphones.\n\n(b) Apply basic machine learning algorithms to analyze hand-reflected signals for accurate gesture recognition.",
    "supervisor": "A/P Xiong Jie",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Mobile Applications",
      "Wireless and Mobile Networks",
      "Ubiquitous/ Pervasive Computing",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0667",
    "title": "Exploiting acoustic signals from your smartphones for contact-free heartbeat monitoring",
    "summary": "The student will use commonly seen smartphones to generate ultrasound signals that are inaudible to humans. These signals will reflect off the human chest, enabling heartbeat monitoring. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Know how to generating acoustic signals using smartphones.\n\n(b) Apply basic machine learning algorithms to analyze hand-reflected signals for accurate heartbeat monitoring.",
    "supervisor": "A/P Xiong Jie",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Smartphone Systems and Applications",
      "Mobile Applications",
      "Ubiquitous/ Pervasive Computing",
      "Wireless and Mobile Networks",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0668",
    "title": "3.\tExploiting acoustic signals from your smartphones for contact-free eye blink tracking",
    "summary": "The student will use commonly seen smartphones to generate ultrasound signals that are inaudible to humans. These signals will reflect off the target�s head, enabling eye blink monitoring. The frequency and timing patterns of eye blinks can be analyzed for detecting driver fatigue. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Know how to generating acoustic signals using smartphones.\n\n(b) Apply signal processing techniques to detect eye blink events. Apply signal processing techniques to detect eye blink events. Machine learning techniques may also be used if needed.",
    "supervisor": "A/P Xiong Jie",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Smartphone Systems and Applications",
      "Mobile Applications",
      "Wireless and Mobile Networks",
      "Video/Audio/Speech Processing",
      "Ubiquitous/ Pervasive Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0669",
    "title": "Efficient and Low-bit Neural Network Compression In Computer Vision",
    "summary": "This project is a low-bit neural network compression solution for computers vision application and the goal is to construct and train a low-bit and efficient neural network for computer vision application, e.g. object detection and recognition.  The trained model not only can get the similar performance to the full precision neural network, but also it can facilitate to accelerate the model inference in an edge device.  This study will not only promote the study on neural network compression, but also the developed tools will provide a practical computer vision solution for industry. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nthe project will cover the data processing, algorithm research and development and system design.\n\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Data Analytics",
      "Image Analysis &amp; Processing",
      "Low-power Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0670",
    "title": "Web-browser Assessment Testing: Symbolic Maths",
    "summary": "In automated assessment systems (APAS), the user will code their program in a web browser interface and be compiled and evaluated on a centralized server. During the coding, the users may send multiple requests to the server to evaluate their test cases. Hence, there is a user requirement for the response time of the testing. In addition, the demand for highly responsive server-side evaluation will lead to high computational requirements on the server side. To alleviate this workload, a client-side testing tool will be developed to run in the web browser to evaluate the test cases on the client's web browser; only the final assessment will be performed on the server.\n\nSpecific details:\n(a) Design component\n- Identify tool for symbolic mathematics that can work in the browser (e.g., supported to run in WASM).\n\n(b) Implementation component\n- Cross-compile a tool to run under WASM\n- Integrate tool with a web-based IDE\n- Validate the text results are correct\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Discrete Math",
      "Programming Languages &amp; Systems",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0671",
    "title": "Low-Bit Spiking Neural Network Compression for Efficient Edge AI",
    "summary": "Low-bit neural network compression has emerged as a promising solution by reducing weight and activation precision while maintaining accuracy. Meanwhile, spiking neural networks (SNNs), inspired by biological neurons, offer energy-efficient, event-driven computation. This project proposes integrating low-bit compression techniques with SNNs to enhance their efficiency, reduce computational overhead, and improve deployment feasibility on low-power hardware.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nInvestigate the exisiting work and propose a new approach or a new application or a new problem.\n\n(b) Development component",
    "supervisor": "Dr Loke Yuan Ren",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Low-power Computing",
      "Information Retrieval/ Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0672",
    "title": "Security Testing of Decentralized Applications",
    "summary": "Decentralized applications (dApps) built on blockchain networks are increasingly targeted by security threats. This project aims to develop and evaluate security testing techniques tailored for dApps to identify and mitigate such risks. The project will focus on designing automated vulnerability detection methods for smart contracts. By integrating static and dynamic analysis techniques, the project will provide a comprehensive security assessment framework. Case studies of past dApp security incidents will be examined to enhance threat modeling. The project�s outcome will contribute to improving best practices for secure dApp development and may result in an open-source security testing tool or guidelines for developers.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nInvestigate new security issues and their root causes. Design and evaluate new methods to automatically discover them.\n\n(b) Development component\n\nDevelop tools to realise the proposed methods.",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Blockchain",
      "Cyber Security",
      "Program Analysis and Optimization",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0673",
    "title": "Hardware Emulator on WASM: Arm Cortex",
    "summary": "WASM provides portability across multiple platforms and allows new opportunities for applications to be run in a web browser environment. Hardware emulators are usually used for development where ease of access to the hardware is limited. Porting hardware emulators onto WASM, allows the emulators to be portable and used in an online environment.\n\nSpecific details:\n(a) Design component\n- Identify lightweight hardware emulator that can work in the browser (e.g., supported to run in WASM).\n\n(b) Implementation component\n- Cross-compile an existing light-weight compiler to run under WASM\n- Provide test cases to evaluate the correctness of the emulators\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Architecture",
      "Microprocessor-based Systems",
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0674",
    "title": "Hardware Emulator on WASM: RISC-V",
    "summary": "WASM provides portability across multiple platforms and allows new opportunities for applications to be run in a web browser environment. Hardware emulators are usually used for development where ease of access to the hardware is limited. Porting hardware emulators onto WASM, allows the emulators to be portable and used in an online environment.\n\nSpecific details:\n(a) Design component\n- Identify lightweight hardware emulator that can work in the browser (e.g., supported to run in WASM).\n\n(b) Implementation component\n- Cross-compile an existing light-weight compiler to run under WASM\n- Provide test cases to evaluate the correctness of the emulators\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Architecture",
      "Microprocessor-based Systems",
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0675",
    "title": "Hardware Emulator on WASM: x86",
    "summary": "WASM provides portability across multiple platforms and allows new opportunities for applications to be run in a web browser environment. Hardware emulators are usually used for development where ease of access to the hardware is limited. Porting hardware emulators onto WASM, allows the emulators to be portable and used in an online environment.\n\nSpecific details:\n(a) Design component\n- Identify lightweight hardware emulator that can work in the browser (e.g., supported to run in WASM).\n\n(b) Implementation component\n- Cross-compile an existing light-weight compiler to run under WASM\n- Provide test cases to evaluate the correctness of the emulators\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Architecture",
      "Microprocessor-based Systems",
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0676",
    "title": "FreeRTOS Emulator on WASM",
    "summary": "WASM provides portability across multiple platforms and allows new opportunities for applications to be run in a web browser environment. FreeRTOS is a market-leading embedded system. When access to the embedded hardware is limited, a FreeRTOS emulator provides an alternative to experiment with embedded applications with actual hardware. Porting the emulator onto WASM allows the emulator to be portable and used in an online environment.\n\nSpecific details:\n\n\n(a) Research component\n- Create a hardware layer for FreeRTOS on WASM runtime environment\n\n(b) Development component\n- Cross-compile FreeRTOS to WASM",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Computer Architecture",
      "Microprocessor-based Systems",
      "Real-Time / Embedded Systems",
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0677",
    "title": "Hardware Peripheral Emulator on WASM",
    "summary": "WASM provides portability across multiple platforms and allows new opportunities for applications to be run in a web browser environment. Hardware emulators are usually used for development where ease of access to the hardware is limited. Porting hardware emulators onto WASM, allows the emulators to be portable and used in an online environment.\n\nSpecific details:\n(a) Design component\n- Design common hardware peripheral interface in WASM, e.g., LED, speakers, microphone, camera\n\n(b) Implementation component\n- Implement hardware peripheral interface in WASM\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Architecture",
      "Real-Time / Embedded Systems",
      "Video/Audio/Speech Processing",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0678",
    "title": "Crowd Simulation on Python",
    "summary": "Crowd simulation is the process of simulating the movement (or dynamics) of a large number of entities or characters. It is commonly used to create virtual scenes for visual media like films and video games, and is also used in crisis training, architecture and urban planning, and evacuation simulation. Develop a crowd simulation tool in Python allows the simulation tool to be integrated to common Python-based machine learning tools .\n\nSpecific details:\n(a) Design component\n- Design graphical interface for the simulation tool in Python\n\n(b) Implementation component\n- Port an existing Java-based crowd simulation software to Python\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Animation/ Games",
      "Serious Games",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0679",
    "title": "LLM-Driven Combinatorial Optimization 1",
    "summary": "This project explores the use of Large Language Models (LLMs) as intelligent copilots for both solving combinatorial optimization problems. While existing studies focus on classical tasks like TSP or SOP, this project expands the scope to include new problem domains such as Job Shop Scheduling, Bin Packing, Graph Coloring, and Vehicle Routing Problems. The student will experiment with prompt engineering and reasoning-based strategies (e.g., Chain-of-Thought) to guide LLMs solving combinatorial optimization problems. Performance will be evaluated against traditional solvers (e.g., OR-Tools, metaheuristics), with the goal of building a benchmark suite that highlights the strengths and limitations of LLM-assisted optimization. A visualization dashboard is encouraged.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0680",
    "title": "LLM-Driven Combinatorial Optimization 2",
    "summary": "This project explores the use of Large Language Models (LLMs) as intelligent copilots for both solving combinatorial optimization problems. While existing studies focus on classical tasks like TSP or SOP, this project expands the scope to include new problem domains such as Job Shop Scheduling, Bin Packing, Graph Coloring, and Vehicle Routing Problems. The student will experiment with prompt engineering and reasoning-based strategies (e.g., Chain-of-Thought) to guide LLMs solving combinatorial optimization problems. Performance will be evaluated against traditional solvers (e.g., OR-Tools, metaheuristics), with the goal of building a benchmark suite that highlights the strengths and limitations of LLM-assisted optimization. A visualization dashboard is encouraged.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0681",
    "title": "Query-Efficient Online Black-box Guidance for Diffusion-model Target Generation 1",
    "summary": "Guided diffusion-model generation is a promising direction for customizing the generation process of a pre-trained diffusion-model to address the specific downstream tasks. Existing guided diffusion models either rely on training of the guidance model with pre-collected datasets or require the objective functions to be differentiable. However, for most real-world tasks, the offline datasets are often unavailable, and their objective functions are often not differentiable, such as image generation with human preferences, molecular generation for drug discovery, and material design. This project involves the study on online algorithm capable of collecting data during runtime and supporting a black-box objective function.  See https://openreview.net/forum?id=OmpTdjl7RV\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0682",
    "title": "Query-Efficient Online Black-box Guidance for Diffusion-model Target Generation 2",
    "summary": "Guided diffusion-model generation is a promising direction for customizing the generation process of a pre-trained diffusion-model to address the specific downstream tasks. Existing guided diffusion models either rely on training of the guidance model with pre-collected datasets or require the objective functions to be differentiable. However, for most real-world tasks, the offline datasets are often unavailable, and their objective functions are often not differentiable, such as image generation with human preferences, molecular generation for drug discovery, and material design. This project involves the study on online algorithm capable of collecting data during runtime and supporting a black-box objective function. https://openreview.net/forum?id=OmpTdjl7RV\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0683",
    "title": "Auto-Prompt Optimization of Generative Designs 1",
    "summary": "This project explores the automatic optimization of prompts for Large Language Models (LLMs) in multitask generative design settings. Students will investigate the use of evolutionary algorithms or reinforcement learning to evolve prompt structures that can generalize across different design objectives. The system aims to generate prompts that guide LLMs in producing structured, high-quality inputs for downstream design generation and simulation (e.g., OpenFoam). In addition to evolutionary optimization, the project will incorporate self-reflection prompting, allowing LLMs to critique and revise their own responses, further improving performance. The effectiveness of each prompt variant will be evaluated using simulation-based performance metrics across multiple tasks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0684",
    "title": "Auto-Prompt Optimization of Generative Designs 2",
    "summary": "This project explores the automatic optimization of prompts for Large Language Models (LLMs) in multitask generative design settings. Students will investigate the use of evolutionary algorithms or reinforcement learning to evolve prompt structures that can generalize across different design objectives. The system aims to generate prompts that guide LLMs in producing structured, high-quality inputs for downstream design generation and simulation (e.g., OpenFoam). In addition to evolutionary optimization, the project will incorporate self-reflection prompting, allowing LLMs to critique and revise their own responses, further improving performance. The effectiveness of each prompt variant will be evaluated using simulation-based performance metrics across multiple tasks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0685",
    "title": "LLM-assisted Crowd Simulation Calibration (1)",
    "summary": "For realistic simulations, crowd simulation models and parameters can be calibrated against real-world observations. However, it may be challenging to collect sufficient real-world observations to calibrate the simulation models. Large-Language Models (LLMs) excel at understanding and generating coherent, contextually relevant text.  Research has also found that LLMs can provide a commonsense model of the world in addition to a policy that acts on it. This project seeks to calibrate crowd simulation models using commonsense knowledge generated from LLMs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Design prompt to generate common sense knowledge from LLMs for crowd simulation\n\n(b) Development component\n- Calibrate operational behavior in crowd simulation using common sense knowledge",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Animation/ Games",
      "Serious Games",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0686",
    "title": "Prompt Engineering Tool for LLM Agents 2",
    "summary": "This project involves developing a tool to streamline the process of designing, testing, and optimizing prompts for Large Language Model (LLM) agents. The tool will provide features for creating and managing prompts, along with functionality to interact with LLM APIs and evaluate prompt effectiveness. The Key Objectives includes:\n�\tDevelop a library of prompt templates.\n�\tIntegrate with LLM APIs for prompt testing.\n�\tImplement prompt evaluation metrics and version control.\nThis project shall address a crucial aspect of LLM agent development by providing a practical tool to improve prompt engineering workflows.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Ong Yew Soon",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0687",
    "title": "LLM-assisted Traffic Simulation Calibration",
    "summary": "For realistic simulations, simulation models and parameters can be calibrated against real-world observations. However, it may be challenging to collect sufficient real-world observations to calibrate the simulation models. Large-Language Models (LLMs) excel at understanding and generating coherent, contextually relevant text.  Research has also found that LLMs can provide a commonsense model of the world in addition to a policy that acts on it. This project seeks to calibrate simulation models using commonsense knowledge generated from LLMs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Generate prompt to extract common sense knowledge from LLMs\n\n(b) Development component\n- Calibrate traffic simulator using common sense knowledge",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Animation/ Games",
      "Serious Games",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0688",
    "title": "LLM-assisted Crowd Simulation Calibration (2)",
    "summary": "For realistic simulations, crowd simulation models and parameters can be calibrated against real-world observations. However, it may be challenging to collect sufficient real-world observations to calibrate the simulation models. Large-Language Models (LLMs) excel at understanding and generating coherent, contextually relevant text.  Research has also found that LLMs can provide a commonsense model of the world in addition to a policy that acts on it. This project seeks to calibrate the simulation models using commonsense knowledge generated from LLMs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Design prompt to generate common sense knowledge from LLMs for crowd simulation\n\n(b) Development component\n- Calibrate tactical planning in crowd simulation using common sense knowledge",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Animation/ Games",
      "Serious Games",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0689",
    "title": "LLM-assisted Crowd Simulation Calibration (3)",
    "summary": "For realistic simulations, crowd simulation models and parameters can be calibrated against real-world observations. However, it may be challenging to collect sufficient real-world observations to calibrate the simulation models. Large-Language Models (LLMs) excel at understanding and generating coherent, contextually relevant text.  Research has also found that LLMs can provide a commonsense model of the world in addition to a policy that acts on it. This project seeks to calibrate the simulation models using commonsense knowledge generated from LLMs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Design prompt to generate common sense knowledge from LLMs for crowd simulation\n\n(b) Development component\n- Calibrate strategic planning in crowd simulation using common sense knowledge",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Animation/ Games",
      "Serious Games",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0690",
    "title": "Efficient and effective data management with large language models",
    "summary": "Traditionally, it is effort-consuming to build up a data management application, since it involves rounds of data cleaning, schema design, implementation, and testing. Nowadays, large language models (LLMs) have shown its power for a diverse set of tasks. This project is to develop a data management tool which allows users to build a data management application easily and conveniently with the help of large language models (LLMs). For more details of the project, please refer to a recent paper at https://arxiv.org/pdf/2310.00749.pdf.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0692",
    "title": "Large Language Models for Urban Data Analysis (1)",
    "summary": "Large language models (LLMs) such as ChatGPT have been used in different domains. This project is to explore methods that leverage LLMs for urban data analysis, including but not limited to traffic data prediction. Some explicit tasks of the project includes explore various LLMs including ChatGPT and LLaMA and different ways of prompts for the urban data analysis tasks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0693",
    "title": "Large Language Models for Urban Data Analysis (2)",
    "summary": "Large language models (LLMs) such as ChatGPT have been used in different domains. This project is to explore methods that leverage LLMs for urban data analysis, including but not limited to traffic data prediction. Some explicit tasks of the project includes explore various LLMs including ChatGPT and LLaMA and different ways of prompts for the urban data analysis tasks.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0695",
    "title": "Developing a Demonstration System of Multi-Modal Search",
    "summary": "Multi-modal search involves searching for information across multiple modalities such as text, images, and videos. This problem is becoming increasingly important with the proliferation of multimedia content on the internet. This project aims to develop a demonstration system of multi-modal search that would showcase the performance of different multi-modal search techniques.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0696",
    "title": "Developing an Image Search System for Mobile Devices",
    "summary": "Similar image search is an important problem in computer vision that involves finding images similar to a given query image. This problem has a wide range of applications, such as image retrieval, product recommendation, and visual search. This project aims to develop an application of similar image search that would work for mobile devices. One use case of the project is to allow mobile phone users to search over their photos via keywords, natural language, etc.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0697",
    "title": "Developing a Demonstration System of Similar Image Search",
    "summary": "Similar image search is an important problem in computer vision that involves finding images similar to a given query image. This problem has a wide range of applications, such as image retrieval, product recommendation, and visual search. This project aims to develop a demonstration system of similar image search that would showcase the performance of different image similarity metrics and techniques.\n\nPlease refer to a paper at https://arxiv.org/abs/2303.09855 for more information.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0698",
    "title": "Developing a Demonstration System of Similar Document Search",
    "summary": "Similar document search is a problem in natural language processing that involves finding documents similar to a given query document. This problem has a wide range of applications, such as plagiarism detection, document retrieval, and topic modeling. This project aims to develop a demonstration system of similar document search that would showcase the performance of different document similarity metrics and techniques.\n\nPlease refer to a paper at https://arxiv.org/abs/2303.09855 for more information.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0699",
    "title": "Efficient LLM Inference (1)",
    "summary": "This project is to develop techniques for improving the inference efficiency of LLMs. Potential techniques include but not limited to network quantization, prompt caching, KV cache management, etc. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0700",
    "title": "Efficient LLM Inference (2)",
    "summary": "This project is to develop techniques for improving the inference efficiency of LLMs. Potential techniques include but not limited to network quantization, prompt caching, KV cache management, etc. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Long Cheng",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0701",
    "title": "AI for Neuroscience: Modeling Math Learning Difficulties from Brain Imaging Data",
    "summary": "This project aims to apply advanced deep learning techniques to neuroimaging data in order to investigate the neural correlates of mathematical learning difficulties. For a start, we will leverage on large-scale datasets such as the GUSTO study, the project will involve developing and evaluating predictive models that link brain activity patterns to cognitive performance in mathematics. Resting-state fMRI has been the go-to paradigm for predictive models, in both clinical and educational settings, but the interpretation of the results have been challenging because of its unconstrained nature, and video-evoked fMRI can capture what the brain is doing during learning new content or revising previously learnt content. Part of this project involved working with local fMRI data. The project is well-suited for Computer Science students with strong programming skills, particularly in Python and frameworks such as PyTorch or TensorFlow. Students will gain hands-on experience in working with high-dimensional data, model development, and performance evaluation in an interdisciplinary context bridging AI and neuroscience. The outcomes of this research may contribute to a better understanding of learning disorders and support the design of targeted interventions in education and healthcare.\n\nSpecific details:\n(a) Design Component:\nThe student will design a deep learning pipeline tailored for neuroimaging data analysis. This includes selecting appropriate architectures (e.g., CNNs, RNNs, or transformers), determining input representations of brain imaging data, defining learning objectives, and designing validation strategies to ensure model robustness and generalizability.\n\n(b) Implementation Component:\nThe student will implement the full pipeline using Python and deep learning frameworks such as PyTorch or TensorFlow. This includes data preprocessing, model training, hyperparameter tuning, and performance evaluation. The implementation will be tested on real neuroimaging datasets, with results analyzed to extract interpretable insights related to math learning difficulties.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Cheong Kang Hao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0702",
    "title": "AI for Autism: Multimodal Analysis of Behavioural and Neural Data in Local Children",
    "summary": "This project aims to apply AI techniques to analyze multimodal data�including behavioral observations, EEG signals, and eye-tracking metrics�collected from two groups of students: those with suspected autism and typically developing peers. Using machine learning and deep learning models, the goal is to identify patterns and features that differentiate the two groups, with the broader aim of contributing to early detection and support strategies. Students will work with a small---locally collected dataset and gain experience in preprocessing complex data types, feature extraction, model development, and evaluation. The project offers opportunities for meaningful societal impact through the application of AI.\n\nSpecific details:\n(a) Design Component:\nThe student will design a machine learning pipeline for multimodal data integration, including strategies for synchronizing and extracting features from EEG signals, eye-tracking data, and behavioral metrics. Model architecture and evaluation criteria will be defined based on classification or clustering objectives.\n\n(b) Implementation Component:\nThe student will implement data preprocessing routines, feature extraction methods, and machine learning models using Python-based libraries (e.g., scikit-learn, MNE, PyTorch). The pipeline will be applied to the local dataset to identify distinguishing patterns between the two student groups, with performance metrics and model interpretability assessed.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Cheong Kang Hao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0703",
    "title": "Efficient Modeling of Personalized Virtual Students Based on Real Classroom Data",
    "summary": "This project focuses on building a personalized virtual student agent that reflects consistent behavior and interaction styles based on real teacher-student dialogue data. You will explore core components such as personality modeling, behavioral consistency, dialogue memory, and response strategies. The project allows flexibility in technical approaches, including prompt engineering, retrieval-augmented generation (RAG), or lightweight fine-tuning. Ideal for students with Python experience, basic knowledge of large language models (LLMs), and a strong interest in NLP or AI for education.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research Component:\nThe student will investigate methods for modeling personality and behavioral consistency in dialogue agents, drawing from existing literature on LLMs, conversational AI, and educational technologies. Analysis of real teacher-student dialogues will inform the design of interaction patterns and response strategies.\n\n(b) Development Component:\nThe student will implement a virtual student agent using techniques such as prompt engineering, retrieval-augmented generation (RAG), or fine-tuning. The system will be evaluated for consistency, relevance, and educational value in simulated teacher-student interactions.",
    "supervisor": "A/P Cheong Kang Hao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0704",
    "title": "Multi-Agent Classroom Simulation � Reconstructing Teaching Scenarios and Interactive Learning",
    "summary": "This project aims to simulate real-world classroom scenarios using multi-agent systems to reproduce rich interactions among AI students and an AI teacher. The focus is on modeling structured learning activities such as lectures, group tasks, quizzes, and feedback loops. Agents will be designed with perception, dialogue, and decision-making modules to engage in classroom routines. The platform will serve as a prototype for simulating interactive teaching sessions. It can support the evaluation and testing of virtual student behaviors, teacher strategies, and classroom interventions � providing a controllable environment for iterative platform development in AI-powered teacher training.\n\nSpecific details:\n(a) Design Component:\nThe system features AI teacher and student agents with modules for perception, dialogue, and decision-making. It supports structured classroom activities like lectures, group tasks, and quizzes. Agent behaviors follow rule-based logic, with future extensions for learning-based adaptations.\n\n(b) Implementation Component:\nBuilt using an agent-based framework, the prototype simulates classroom sessions with configurable agent profiles. Activities are scripted, and interactions logged for analysis. The platform enables testing of teaching strategies and student behaviors in a controlled setting.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Cheong Kang Hao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0705",
    "title": "AI-Powered Tutoring Chatbot for Secondary School Support (SSS)",
    "summary": "This project aims to develop an AI-powered tutoring chatbot for secondary school students, leveraging large language models (LLMs) and retrieval-augmented generation (RAG) techniques. The chatbot will deliver subject-specific support through interactive dialogue, scaffolded explanations, and step-by-step reasoning using chain-of-thought (CoT) prompting. The system will be designed to align with key educational theories such as mastery learning and constructivism. Students will gain hands-on experience in prompt engineering, knowledge retrieval, adaptive feedback design, and evaluating the chatbot�s pedagogical effectiveness.\n\nSpecific details:\n(a) Design Component:\nThe student will design a tutoring chatbot framework that integrates LLMs with educational pedagogy. This includes defining dialogue flow, incorporating chain-of-thought prompting, implementing retrieval-augmented generation (RAG) for content support, and aligning interactions with learning theories such as mastery learning and constructivism.\n\n(b) Implementation Component:\nThe student will implement the chatbot using Python and LLM APIs, integrating RAG pipelines for dynamic content retrieval and applying prompt engineering for CoT reasoning. The system will be tested in subject-specific scenarios, with evaluation focused on instructional accuracy and engagement.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Cheong Kang Hao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0706",
    "title": "Convert invisible laser to acoustic signals stealthily for sensing",
    "summary": "The basic idea is to use an invisible laser beam to direct onto a microphone, converting the laser power into vibrations and then into sound. This sound signal can be used for tracking and sensing applications, such as hand gestures recognition.   Due to the low power loss of the laser, the laser source can be positioned tens of meters away from the target microphone.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a)\tKnow how to use a smartphone to control the laser beam intensity.\n\n(b)\tUnderstand the relationship between the laser and the acoustic signals generated and control the laser to generate wanted acoustic signals. \n\n(c)\t Apply signal processing schemes or(and) basic machine learning algorithms to analyze reflected acoustic signals from the human target for sensing.",
    "supervisor": "A/P Xiong Jie",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Video/Audio/Speech Processing",
      "Smartphone Systems and Applications",
      "Mobile Applications",
      "Wireless and Mobile Networks",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0707",
    "title": "Smart Class in Simulation � Modeling AI Student Behavior and Emergent Dynamics",
    "summary": "This project simulates a fully AI-driven classroom to explore how autonomous student agents learn, collaborate, and compete in a social environment. Under the guidance of an AI teacher, agents will develop and evolve behavioral strategies through interaction. The system focuses on emergent group behavior, such as peer influence, knowledge diffusion, and adaptive role switching. Designed as a sandbox for behavior modeling, this simulation will generate reusable behavior policies and dialogue traces. These outputs can support the design of virtual student agents in real-world educational systems, particularly in personalizing behaviors and simulating diverse learning personas in AI-assisted teacher training platforms.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research Component:\nStudy how AI student agents develop learning and social strategies through interaction. Analyze emergent behaviors like peer influence, knowledge diffusion, and adaptive roles to inform virtual student modeling.\n\n(b) Development Component:\nBuild a simulation sandbox with autonomous agents guided by an AI teacher. Generate behavior policies and dialogue logs to support virtual agent design for real-world education systems.",
    "supervisor": "A/P Cheong Kang Hao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0708",
    "title": "Convert invisible laser to acoustic signals stealthily for attacking",
    "summary": "The basic idea is to use an invisible laser beam to direct onto a microphone, converting the laser power into vibrations and then into sound. This sound signal can be used to compromise existing acoustic sensing systems. Due to the low power loss of the laser, the laser source can be positioned tens of meters away from the target microphone and the laser is invisible so this attack can be stealthy. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a)\tKnow how to use a smartphone to control the laser beam intensity.\n\n(b)\tUnderstand the relationship between the laser and the acoustic signals generated and control the laser to generate wanted acoustic signals. \n\n(c)\t Apply signal processing schemes or(and) basic machine learning algorithms to analyze reflected acoustic signals to achieve effective attack.",
    "supervisor": "A/P Xiong Jie",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Mobile Applications",
      "Smartphone Systems and Applications",
      "Wireless and Mobile Networks",
      "Ubiquitous/ Pervasive Computing",
      "System Security"
    ]
  },
  {
    "projectNo": "CCDS25-0709",
    "title": "Project Title: Building an AI-Driven Socratic Research Assistant",
    "summary": "This project proposes the creation of an AI research assistant designed to stimulate critical thinking through Socratic-style questioning. Rather than supplying direct answers like conventional AI tools, the assistant will engage users in reflective dialogue by posing purposeful, context-aware questions. Using natural language processing (NLP) and machine learning, the system will interpret user input and guide exploration through layered inquiry, promoting deeper understanding. It will support multiple domains and adapt to individual users, enabling tailored and interactive research support. The tool is intended to support active learning and analytical reasoning, serving as a resource for students, educators, and researchers seeking more thoughtful engagement with complex topics.\n\nSpecific details:\n(a) Design Component:\nThe system will be designed as a conversational agent that models the Socratic method. It will include modules for intent recognition, context tracking, and question generation. The AI will be structured to avoid giving direct answers, instead prompting users with layered, open-ended questions to promote exploration and reflection.\n\n(b) Implementation Component:\nThe assistant will be built using an NLP framework for language understanding and question generation. A dialogue manager will track context and user responses, adapting the questioning flow accordingly. The front-end interface will allow real-time interaction, with logs for evaluating reasoning depth and engagement.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Cheong Kang Hao",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0710",
    "title": "Cross-technology communication: from LoRa to Wi-Fi",
    "summary": "7.\tEach wireless technology operates independently and follows its own protocol. For example, a Bluetooth transmitter cannot communicate with an LTE or WiFi receiver. The goal of this proposal is to enable different wireless technologies to work together. For instance, if we can enable a Bluetooth receiver to capture and demodulate signals from a LoRa receiver, it could offer significant benefits. While Bluetooth is ubiquitous, its communication range is relatively short. On the other hand, LoRa has a much larger transmission range, but devices equipped with LoRa modules are more limited. If we can combine the two wireless technologies to work together, we can leverage the strengths of both.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a)\tKnow how to use a software define radio (USRP or WARP) or commodity LoRa hardware to generate LoRa signals. \n\n(b)\tUnderstand the physical layer protocols of LoRa and Bluetooth protocols. \n\n(c)\tDesign methods to enable signal reception of LoRa signals at a Bluetooth receiver using a software-defined radio (USRP) or commodity Bluetooth hardware.",
    "supervisor": "A/P Xiong Jie",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Ubiquitous/ Pervasive Computing",
      "Wireless and Mobile Networks"
    ]
  },
  {
    "projectNo": "CCDS25-0711",
    "title": "Using UWB in your smartphone for smart sensing",
    "summary": "8.\tThe UWB (Ultra-Wideband) module is now embedded in many smartphones, including the iPhone 11 and later, Google Pixel 6 and later, and Samsung Galaxy S21 and later. Originally designed for localization, UWB signals can also be used for orientation tracking and fine-grained sensing, such as human respiration monitoring. Orientation tracking plays a critical role in model VR/AR applications. For sensing, the basic principle is that the UWB signal reflects off the target, with the signal changing in response to the target's movements. By analyzing the signal variations, we can extract valuable information about the target's motion. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Learn how to generate UWB signals using smartphones.\n\n(b) Understand how to use UWB signals to measure distance and displacement, and apply signal processing techniques for human respiration sensing.",
    "supervisor": "A/P Xiong Jie",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Smartphone Systems and Applications",
      "Wireless and Mobile Networks",
      "Mobile Applications",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0712",
    "title": "Neurosymbolic AI for Opinion Mining",
    "summary": "This FYP is about applying neurosymbolic AI for opinion mining on a topic of your choice. In particular, you will be using Sentic APIs, a suite of application programming interfaces that perform various sentiment analysis tasks in different languages. All the APIs are based on the sentic computing framework and, hence, leverage an ensemble of symbolic AI (SenticNet) and subsymbolic AI (deep learning). One of the goals of this FYP is also to test functionality, reliability, and performance of Sentic APIs. For more info, please visit https://sentic.net/api or contact Dr Rui Mao (rui.mao@ntu.edu.sg).\n\nSpecific details:\nThe successful completion of this FYP consists of the following steps:\n1. choose a popular topic, e.g., cryptocurrencies, metaverse, or climate change\n2. crawl and label data about such topic from X or Reddit in English or any other language\n3. process the collected data using the APIs\n4. report any encountered issues, e.g., mislabeled tweets\n5. deduce possible reasons of such issues, e.g, missing concept in SenticNet\n6. come up with possible solutions for the encountered issues\n7. visualize and discuss results in your FYP report",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0713",
    "title": "GenAI for Entity Matching",
    "summary": "The aim of this FYP is to build a platform leveraging Gen AI to revolutionize entity engagement across industries. It offers tailored solutions for entity matching, dynamic recommendations, and entity ranking. The platform drives enhanced entity experiences, revenue growth, and competitive advantage, scalable to meet evolving business needs. This project is in collaboration with ASTAR IHPC and is managed by Dr Satapathy Ranjan: contact him (satapathy_ranjan@ihpc.a-star.edu.sg) for more details.\n\nSpecific details:\n�\tLiterature on state-of-the-art Gen AI models.\n�\tBuild a system that takes in questions in human language and gives back answers in the same language.\n�\tDevelop a custom matching and ranking algorithm\n�\tDeployment of Gen AI models on cloud with minimal UI (Streamlit or Gradio)",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0714",
    "title": "GenAI for  Information extraction",
    "summary": "This aim of this FYP is to build a platform leveraging Gen AI to revolutionize entity engagement across industries. It offers tailored solutions for entity matching, dynamic recommendations, and entity ranking. The platform drives enhanced entity experiences, revenue growth, and competitive advantage, scalable to meet evolving business needs. This project is in collaboration with ASTAR IHPC and is managed by Dr Satapathy Ranjan: contact him (satapathy_ranjan@ihpc.a-star.edu.sg) for more details.\n\nSpecific details:\n�\tLiterature on the State-of-the-art Gen AI models.\n�\tBuild a system that takes in questions in natural language, queries the database and gives response back in natural language.\n�\tDevelop a custom matching and ranking algorithm\n�\tDeployment of Gen AI models on cloud with minimal UI (Streamlit or Gradio)",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0715",
    "title": "Evaluating the Accuracy of Uncertainty Quantification in GANs for Financial Time Series Forecasting",
    "summary": "Generative Adversarial Networks (GANs) have become a key tool for forecasting financial time series with uncertainty quantification. These uncertainties are crucial for portfolio optimization and risk management. However, the validity of GAN-derived uncertainty remains unexamined. This FYP aims to develop and implement metrics to evaluate the reliability of uncertainty estimates. In this project, the student will review existing methods for uncertainty quantification in time series forecasting and propose new approaches apt for financial applications. This project is in collaboration with ASTAR IHPC and is managed by Dr Satapathy Ranjan: contact him (satapathy_ranjan@ihpc.a-star.edu.sg) for more details.\n\nSpecific details:\n�\tLiterature review\n�\tAdaptation of existing GAN models as base models  \n�\tDevelop a metric to evaluate the accuracy of uncertainty\n�\tPrepare a final report.",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0716",
    "title": "Robust Multi-Modal Classification for Alzheimer�s Disease: Addressing Missing Data Challenges",
    "summary": "Alzheimer�s disease is a neurodegenerative disorder that requires a multi-modal approach for accurate diagnosis and classification. Multi-modal data�such as neuroimaging (MRI, PET), genetic information, cognitive assessments, and clinical histories�provides a comprehensive view of a patient�s condition. However, in real-world clinical settings, missing data in one or more modalities is common due to factors like cost, patient compliance, or technical limitations. This FYP aims to develop robust methods to handle missing modality data in multi-modal disease classification models specifically for Alzheimer�s disease. By integrating advanced data imputation techniques, deep learning strategies, and domain-specific knowledge, the project seeks to improve the accuracy and reliability of Alzheimer�s disease diagnoses, even when some data modalities are missing. This project is in collaboration with ASTAR IHPC and is managed by Dr Satapathy Ranjan: contact him (satapathy_ranjan@ihpc.a-star.edu.sg) for more details.\n\nSpecific details:\n�\tAnalyze existing techniques for handling missing data in multi-modal datasets\n�\tStudy ADNI data for Alzheimer disease.\n�\tDevelop a baseline multi-modal classification model using complete datasets\n�\tExplore and implement various strategies for handling missing modality data, including:\n�\tData Imputation Techniques (e.g., KNN, matrix completion, GAN-based imputation)\n�\tModality-Agnostic Models (e.g., models that can operate on incomplete data)\n�\tHybrid Approaches (combining imputation with modality-agnostic models)\n�\tEvaluate the performance of the proposed methods using metrics such as accuracy, precision, recall, and F1-score.",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0717",
    "title": "Harnessing Big Data for a Sustainable Tomorrow",
    "summary": "The project focuses on the collection, analysis, and application of extensive datasets to address critical environmental issues such as waste management, energy use, and resource conservation. The project demonstrates how leveraging big data not only helps in making informed decisions but also in influencing policies and behaviors towards achieving a more sustainable future. Through real-time monitoring and predictive analytics, project sets a precedent for how technology and data can come together to craft innovative solutions that combat environmental degradation and promote a healthier planet. This project is in collaboration with ASTAR IHPC and is managed by Dr Satapathy Ranjan: contact him (satapathy_ranjan@ihpc.a-star.edu.sg) for more details.\n\nSpecific details:\n�\tBuild a Data extraction pipeline \n�\tBuild NLP techniques to extract information from data\n�\tShowcase the data on a visualization tool",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0718",
    "title": "Parameterized Simulation Framework for Surface Code Performance Analysis",
    "summary": "Quantum computing's promise is tightly linked to overcoming errors inherent in quantum systems. Surface codes are a leading method for quantum error correction due to their scalability and fault-tolerance. However, their performance is highly sensitive to real-world noise conditions such as varying qubit error rates and measurement inaccuracies.\nIn this project, you will develop a modular simulation framework using Python and quantum simulation tools (such as Qiskit or Cirq) to study how different noise parameters affect surface code performance. By systematically adjusting parameters and analyzing trends in logical error rates, you will assess the effectiveness of the surface code under different conditions. The results will be visualized using standard tools (e.g., Matplotlib) to identify key performance trends. This project will provide hands-on experience with quantum error correction simulations and data-driven performance analysis, with potential opportunities for further refinement and deeper exploration.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nThis project will be co-supervised with an A*STAR researcher. The student will\nbe allocated a workspace at A*STAR, and will need to travel to A*STAR regularly for meetings.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nDesign: Create a modular framework with adjustable simulation parameters.\nImplementation: Develop the simulation in Python (using Qiskit/Cirq); implement functions for systematic parameter variation and data logging.\nResearch: Review literature on surface codes and noise models; compare simulation outcomes with theoretical expectations.\nDevelopment: Build data visualization tools to analyze trends and thresholds.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0719",
    "title": "Algebraic Methods in Quantum Error Correction: Implementation and Analysis",
    "summary": "Quantum error correction (QEC) is essential for reliable quantum computing, and many effective QEC schemes are founded on algebraic principles. This project focuses on QEC codes that leverage algebraic structures�such as those used in Calderbank�Shor�Steane (CSS) codes or cyclic/BCH code-based constructions.\nYou will explore how algebraic parameters (such as field size and code distance) influence error-correcting performance and implement a simulation of one or two algebraic QEC codes in Python, optionally using SageMath for symbolic computations. The project will involve testing and comparing performance metrics, including logical error rates and resource overhead, across different parameter choices. Through systematic experimentation, you will evaluate the practical trade-offs of algebraic QEC codes and their suitability for fault-tolerant quantum computing.\n\nThis project is research-heavy and you will need to be self-motivated to score\na good FYP grade. Thus, please DO NOT blindly apply for the project. If you are\ninterested to learn more, send me an email at yongkiam.tan@ntu.edu.sg to\ndiscuss the project scope.\n\nThis project will be co-supervised with an A*STAR researcher. The student will\nbe allocated a workspace at A*STAR, and will need to travel to A*STAR regularly for meetings.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n\nDesign: Develop a conceptual model of algebraic QEC protocols with tunable algebraic parameters.\nImplementation: Code the simulation in Python, using SageMath for advanced algebraic operations as needed.\nResearch: Conduct an in-depth literature review on algebraic QEC codes and analyze how parameter variations affect performance.\nDevelopment: Build tools for systematic parameter studies and data visualization.",
    "supervisor": "Mr Tan Yong Kiam",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0720",
    "title": "Integrative Deep Learning To Predict Antibody-Antigen Binding Affinity",
    "summary": "Accurately predicting how strongly antibodies bind to antigens is crucial for advancing immunotherapies and vaccine development. Current computational methods rely either solely on sequence information or on structural data, limiting their predictive power. This project aims to overcome these limitations by developing a novel deep learning model that integrates both antibody-antigen sequences and their 3D structural information. State-of-the-art tools such as AlphaFold, ESM-2, and geometric deep learning architectures (e.g., graph neural networks and transformers) will be explored to achieve superior accuracy in binding affinity predictions.\n\nThe student will leverage Python and PyTorch libraries to design and implement integrative deep learning algorithms. Publicly available datasets like SAbDab and AlphaFold DB will be utilized for training and evaluating the models. This approach has the potential to significantly improve upon existing methods, enabling the design of more effective therapeutic antibodies.\n\nhttps://github.com/deepmind/alphafold\nhttps://github.com/facebookresearch/esm\nhttps://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on predicting antibody-antigen binding affinity, using deep learning methods\n\n(b) Development component\nThe student will leverage Python and PyTorch libraries to design and implement integrative deep learning algorithms.",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0721",
    "title": "Deep Learning Model Integrating Sequence And Structure For MHC-Peptide Binding Affinity Prediction",
    "summary": "MHC-peptide binding plays a critical role in triggering T-cell immune responses, making precise prediction of binding affinities vital for personalized immunotherapy and vaccine design. While many earlier deep learning methods predominantly utilized amino acid sequence data, recent state-of-the-art models have begun incorporating 3D structural context to enhance predictive accuracy. This project aims to further advance this integration by leveraging both sequence and predicted 3D structural information of peptide-MHC complexes.\n\nIn this project, we will design a novel deep learning architecture that effectively combines amino acid sequence embeddings from advanced protein language models (e.g., ESM-2) with predicted 3D structural data obtained via cutting-edge methods like AlphaFold or the PANDORA modelling pipeline. Geometric deep learning techniques, such as graph neural networks based on geometric vector perceptron (GVP) and equivariant transformer architectures, will be explored to robustly fuse these diverse data types. By harnessing this integrated sequence-structure framework, we aim to achieve superior binding affinity prediction accuracy compared to traditional sequence-only approaches.\n\nhttps://github.com/deepmind/alphafold\nhttps://github.com/facebookresearch/esm\nhttps://github.com/X-lab-3D/PANDORA\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on predicting MHC-peptide binding affinity with deep learning approaches\n\n(b) Development component\nThe student will develop necessary techniques and routines with Python and Pytorch libraries",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Computational Biology",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0722",
    "title": "SnapAssist (Arduino Xiao Sense) V",
    "summary": "As the title implies, this FYP project will be using the Arduino Platform with a Mobile Phone App \n\nBased on the existing applications developed, we will be looking at introducing more options in the application and includes additional sensors/actuators.  We will discuss details with the student once he/she has been allocated \n\nEventually, the system will be a portable application that can be carried around during a photography Session.\n\nSpecific details:\n1. Use of the Arduino\n2. Various Actuators/Sensors Modules (Buy In)",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0723",
    "title": "SnapAssist (Arduino Nano Sense2) IV",
    "summary": "As the title implies, this FYP project will be using the Arduino Platform with a Mobile Phone App \n\nBased on the existing applications developed, we will be looking at introducing more options in the application and includes additional sensors/actuators.  We will discuss details with the student once he/she has been allocated \n\nEventually, the system will be a portable application that can be carried around during a photography Session.\n\nSpecific details:\n1. Use of the Arduino\n2. Various Actuators/Sensors Modules (Buy In)",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0724",
    "title": "SnapAssist (Arduino Nano Sense2) V",
    "summary": "As the title implies, this FYP project will be using the Arduino Platform with a Mobile Phone App \n\nBased on the existing applications developed, we will be looking at introducing more options in the application and includes additional sensors/actuators.  We will discuss details with the student once he/she has been allocated \n\nEventually, the system will be a portable application that can be carried around during a photography Session.\n\nSpecific details:\n1. Use of the Arduino\n2. Various Actuators/Sensors Modules (Buy In)",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0725",
    "title": "Snap Buddy - Droplet Photography (RaspPi Version)",
    "summary": "As the title implies, this FYP project will be working on a 11 inch Montor with the Raspberry Pi ZeroW.  \n\nIt will bw used to display images captured on the DSLR and allow notes/edits to be recorded on the saved image.\n\nEventually, the system will be a application that can be used during a  photo shoot in the studio.\n\nSpecific details:\n1. Use of the ESP32/Arduino\n2. External PCB fabrication \n3. Various Actuators/Sensors",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Microprocessor-based Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0726",
    "title": "Art Buddy - V2.0",
    "summary": "As the title implies, this FYP project is mainly on software development for the Raspberry Pi 3/4 with HQ Camera Mount (with Zoom Lens). \n\nSoftware will be in 2 parts, one student will concentrate on the various apps that will use the images captured from the various camera . The other student will look at developing the master app that will control the simultanous capturing of all the Raspberry Pi with HQ cameras.\n\n  \n\nEventually, the system will be a portable application that can be carried around during a  Photography Session.\n\nSpecific details:\n1. Use of the Arduino\n2. Various Actuators/Sensors Modules (Buy In)",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0727",
    "title": "SnapAssist (Arduino Nano Sense2) III",
    "summary": "As the title implies, this FYP project will be using the Arduino Platform with a Mobile Phone App \n\nBased on the existing applications developed, we will be looking at introducing more options in the application and includes additional sensors/actuators.  We will discuss details with the student once he/she has been allocated \n\nEventually, the system will be a portable application that can be carried around during a photography Session.\n\nSpecific details:\n1. Use of the Arduino\n2. Various Actuators/Sensors Modules (Buy In)",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0728",
    "title": "SnapAssist (Arduino Nano Sense2) II",
    "summary": "As the title implies, this FYP project will be using the Arduino Platform with a Mobile Phone App \n\nBased on the existing applications developed, we will be looking at introducing more options in the application and includes additional sensors/actuators.  We will discuss details with the student once he/she has been allocated \n\nEventually, the system will be a portable application that can be carried around during a photography Session.\n\nSpecific details:\n1. Use of the Arduino\n2. Various Actuators/Sensors Modules (Buy In)",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0729",
    "title": "SnapAssist (Arduino Nano Sense2) I",
    "summary": "As the title implies, this FYP project will be using the Arduino Platform with a Mobile Phone App \n\nBased on the existing applications developed, we will be looking at introducing more options in the application and includes additional sensors/actuators.  We will discuss details with the student once he/she has been allocated \n\nEventually, the system will be a portable application that can be carried around during a photography Session.\n\nSpecific details:\n1. Use of the Arduino\n2. Various Actuators/Sensors Modules (Buy In)",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0730",
    "title": "Generative AI Art - Portrait Photography",
    "summary": "Generative AI Art is the new HOT item for 2023, various large corporations has started sharing their online beta/software/app. (Including Microsoft, Meta, Adobe,etc). We are interested to work with Image Submissions and maybe coupled with Text to work on the Generative AI Arts.   WE want to explore how much can be done/improve on for this new branch of AI Art.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0731",
    "title": "Generative AI Art - Portrait Photography",
    "summary": "Generative AI Art is the new HOT item for 2023, various large corporations has started sharing their online beta/software/app. (Including Microsoft, Meta, Adobe,etc). We are interested to work with Image Submissions and maybe coupled with Text to work on the Generative AI Arts.   WE want to explore how much can be done/improve on for this new branch of AI Art.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0732",
    "title": "Snap Assist (ESP32S3 with LCD Display) III",
    "summary": "As the title implies, this FYP project will be using the ESP32S3 to control photography applications and activate the attached DSLR/Flash System. \n\nThe current version is working with an Arduino Sense but we want to improve the speed of the system with a newer, more powderful microcontroller/microcomputer. \n\nThis project will concentrate  on porting a current application.\n\nSpecific details:\n1. Use of the ESP32S3\n2. Porting of existing Software Framework\n3. Porting of existing Applications",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Microprocessor-based Systems",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0733",
    "title": "Snap Assist (ESP32S3 with LCD Display) II",
    "summary": "As the title implies, this FYP project will be using the ESP32S3 to control photography applications and activate the attached DSLR/Flash System. \n\nThe current version is working with an Arduino Sense but we want to improve the speed of the system with a newer, more powderful microcontroller/microcomputer. \n\nThis project will concentrate  on porting a current application.\n\nSpecific details:\n1. Use of the ESP32S3\n2. Porting of existing Software Framework\n3. Porting of existing Applications",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Microprocessor-based Systems",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0734",
    "title": "Snap Assist (ESP32S3 with LCD Display) I",
    "summary": "As the title implies, this FYP project will be using the ESP32S3 to control photography applications and activate the attached DSLR/Flash System. \n\nThe current version is working with an Arduino Sense but we want to improve the speed of the system with a newer, more powderful microcontroller/microcomputer. \n\nThis project will concentrate  on porting a current application.\n\nSpecific details:\n1. Use of the ESP32S3\n2. Porting of existing Software Framework\n3. Porting of existing Applications",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Microprocessor-based Systems",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0735",
    "title": "Snap Buddy - Droplet Photography (RaspPi Version)",
    "summary": "As the title implies, this FYP project will be working on a 11 inch Montor with the Raspberry Pi ZeroW.  \n\nIt will bw used to display images captured on the DSLR and allow notes/edits to be recorded on the saved image.\n\nEventually, the system will be a application that can be used during a  photo shoot in the studio.\n\nSpecific details:\n1. Use of the ESP32/Arduino\n2. External PCB fabrication \n3. Various Actuators/Sensors",
    "supervisor": "A/P Chia Liang Tien",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Microprocessor-based Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0736",
    "title": "Robot car with robotic arm #2",
    "summary": "Explore and propose uses cases with a system consisting of a robot car equipped with robotic ARM, camera, microphone, speakers and/or IMU sensors. \n\nReference: https://category.yahboom.net/products/transbot-se\n\nControlling of the robotic ARM is via RPI. \nIMU sensors (if required) are available on separate sensor board with BLE/USB connection to RPI.\nCamera mounted on robot allows image recognition to be done.\nMicrophone and speakers available (if needed) for user interactions.\n\nStudents required to be independent and resourceful.  No guidance from Post Graduate Students.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Mr Oh Hong Lye",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Sensor Networks",
      "Web-based Applications",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0737",
    "title": "Constructing an Efficient Universal Graph Tokenizer",
    "summary": "Tokenization is a crucial step in processing graph data for large-scale graph foundation models (GFMs). This project aims to develop an efficient universal graph tokenizer that converts graphs into discrete tokens while preserving essential structural and semantic information. The proposed tokenizer will be designed to handle diverse graph structures, including social networks, citation networks, and molecular graphs. Students will explore different tokenization strategies, such as node clustering, spectral methods, and subgraph extraction, to generate compact yet informative representations. The tokenizer�s effectiveness will be evaluated by integrating it with existing GFMs and assessing performance on downstream tasks like node classification and graph generation. The goal is to develop a tokenizer that balances expressiveness and computational efficiency.\n\nSpecific details:\nSee project summary.\n\nSee project summary.",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0738",
    "title": "Identifying Task-Relevant Tokens in Graph Foundation Models",
    "summary": "Graph foundation models (GFMs) generate tokenized graph representations, but not all tokens contribute equally to downstream tasks. This project focuses on developing methods to identify important graph tokens that are most relevant to specific tasks such as link prediction, node classification, or anomaly detection. The approach will involve analyzing token importance using techniques like attention scores, gradient-based attribution methods, or perturbation-based saliency analysis. Students will experiment with different architectures (e.g., transformer-based GFMs) and evaluate the effectiveness of selected tokens by measuring their impact on model performance. The expected contribution is a framework for understanding and improving token selection in GFMs, leading to more interpretable and efficient graph representations.\n\nSpecific details:\nSee project summary.\n\nSee project summary.",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0739",
    "title": "Scalable Random Walk Kernel Computation for Large Graphs",
    "summary": "Random walk kernels are a powerful tool for measuring graph similarity, but their high computational complexity hinders scalability. This project aims to develop an efficient algorithm for computing random walk kernels on large graphs. Students will explore techniques such as truncated random walks, importance sampling, and precomputed transition matrices to accelerate kernel computation. The project will include theoretical analysis of computational trade-offs and empirical validation on real-world graph datasets. The final goal is to design an approach that retains the expressive power of random walk kernels while significantly improving computational efficiency.\n\nSpecific details:\nSee project summary.\n\nNeed relatively stronger research capabilities to design efficient algorithms.",
    "supervisor": "Ast/P Luo Siqiang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0740",
    "title": "Robust Retrieval Augmented Generation (II)",
    "summary": "Retrieval augmented generation has been widely adopted to perform knowledge inntensive tasks such as question answering. Along with the useful information being retrieved, it is also possible that the retrieval process introduces some noise that negatively affect the task. In this project, you will explore strategies that can enhance the robustness of retrieval to enhance the model performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nIdentify the limitation and motivation\n\n(b) Development component\nDevelop algorithms to improve performance",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0741",
    "title": "Robust Retrieval Augmented Generation (I)",
    "summary": "Retrieval augmented generation has been widely adopted to perform knowledge inntensive tasks such as question answering. Along with the useful information being retrieved, it is also possible that the retrieval process introduces some noise that negatively affect the task. In this project, you will explore strategies that can enhance the robustness of retrieval to enhance the model performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nIdentify the limitation and motivation\n\n(b) Development component\nDevelop algorithms to improve performance",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0742",
    "title": "Analyzing and Comparing LM architectures for text classification tasks.",
    "summary": "This project delves into the realm of Natural Language Processing (NLP), specifically focusing on Language Model (LM) architectures and their efficacy in text classification. This study aims to investigate different LM architectures, such as encoder-only (BERT), encoder-decoder (T5) and decoder-only (GPT) architectures, when being used for learning an effective text classifier. The evaluation will be centered on benchmark text classification datasets. To obtain better performances, you need to tailor the design of different LM architectures towards specific tasks, determine which configuration gives the best results. The outcome is a comprehensive analysis on how each LM architecture can better serve the task, and which gives the best performances.\n\nSpecific details:\n(a) Design component\nDesign each LM architecture tailored towards a specific text classification task.\n\n(b) Implementation component\nConduct model training and testing over benchmark datasets after completing the design for each LM architecture.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0743",
    "title": "Exemplar selection for In-Context Learning under complex scenarios",
    "summary": "In-context learning has been widely adopted in large language models to solve complex tasks without the need to update model parameters. This is achieved by providing a few input-output examples as demonstrations to be fed as the prompt into the LLMs. Existing studies have revealed that selecting similar examples to the target is an optimal strategy. However, how this translates to more complicated tasks remains unclear. This project aims to study how to measure similarity in complicated tasks, such as natural language inference, information extraction, etc., and whether similarity is the optimal criteria. You will conduct empirical experiments to explore this research question.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nExplore how to measure similarity under complex scenarios and test whether similarity is the optimal metric to select good exemplars as prompt.\n\n\n(b) Development component\nThink critically why the metric works and how to improve the selection.",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0744",
    "title": "Exemplar Selection for In-context learning under Out-Of-Domain Scenario",
    "summary": "In-context learning has been widely adopted in large language models to solve complex tasks without the need to update model parameters. This is achieved by providing a few input-output examples as demonstrations to be fed as the prompt into the LLMs. Existing studies have revealed that selecting similar examples to the target is an optimal strategy. However, how this translates to the out-of-domain (OOD) scenario remains unclear. When there is domain shift, it is not clear whether similarity is critical when selecting examples. This project aims to study how to measure similarity under the OOD setting and whether similarity is the optimal criteria. You will conduct empirical experiments to explore this research question.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nExplore what is the best metric under OOD setting.\n\n(b) Development component\nThink critically why certain metric is helpful.",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0745",
    "title": "Effective Fake News Detection",
    "summary": "Fake news has emerged in various online platforms which imposes non-negligible risks to online users. The ability to automatically detect fake news becomes critical to combat such risk. This project aims to design effective models for (multimodal) fake news detection. The models should be able to capture complex interactions or relations between units in the same and different modalities.\n\nSpecific details:\n(a) Design component\nThe student needs to design effective frameworks that could capture interactions among textual spans, image components, or units across two modalities.\n\n(b) Implementation component\nAfter model design, the student needs to implement the model and conduct experiments to verify the effectiveness.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0746",
    "title": "Multi-Agent Coordination for Intelligent Scheduling",
    "summary": "The objective for this project is to develop a system of specialized AI agents (e.g., Scheduling Agent, Calendar Agent, Priority Agent) that coordinate user schedules, resolve task conflicts, and optimize productivity.\n\nSpecific details:\n(a) Design component\n� Agent Architecture: Message-passing and shared memory via database.\n\n� Coordinated Scheduling Algorithm: Auto-updates in response to user task changes.\n\n� Performance Evaluation: Completion rate, conflict resolution time, satisfaction.\n\n(b) Implementation component\n� Store all agent logs, decisions, and task metadata in a relational + vector database (e.g., PostgreSQL + pgvector).\n\n� Use RAG to fetch historical context and similar past scheduling patterns for decision support.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0747",
    "title": "User Preference Modeling and Personalized Recommendation",
    "summary": "The objective for this project is to train ML models to learn personal workload preferences, goal tendencies, and behavioral habits to make intelligent recommendations based on past interaction records.\n\nSpecific details:\n(a) Design component\n� ML Pipeline: Preprocessing, model training, real-time inference.\n\n� Feedback Loop: Use database-stored user responses to refine models.\n\n� Evaluation Metrics: Satisfaction, recommendation accuracy.\n\n(b) Implementation component\n� Store preference vectors per user (e.g., tolerance to workload, preferred hours).\n\n� RAG-ready vector store for querying similar users� behavior or retrieving historical decisions to support explainability in recommendations.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0748",
    "title": "Future Outcome Prediction and Scenario Planning",
    "summary": "As AI is seamlessly integrated into human activities, it becomes increasingly crucial to design AI models that can contribute to our task planning and long-term outcome prediction. The objective for this project is to develop models that can forecast how today�s decisions impact long-term goals using time-series models, LLMs or RL-powered simulators.\n\nSpecific details:\n(a) Design component\n� Forecasting Model: Predict outcome probabilities over time.\n\n� Scenario Visualization: Graphs/tables to show projected goal progress.\n\n� Validation: Run on real/simulated user histories.\n\n(b) Implementation component\n� Time-series task logs stored in structured tables.\n\n� Longitudinal data indexed for RAG-enabled querying (e.g., �Show all paths where similar users reached goal X in Y weeks�).\n\n� Support agents that simulate alternate task sequences using stored historical behavior.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0749",
    "title": "Reinforcement Learning for Multi-Agent Task Allocation",
    "summary": "With a growing interest in multi-agent frameworks which collaborately accomplish complex tasks, how to effectively train these frameworks is underexplored and challenging. The objective of this project is to use reinforcement learning to train a team of agents to assign and schedule tasks optimally in dynamic environments.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n� RL Simulation Environment: Custom task simulator with time/resource constraints.\n\n� Policy Learning: Coordination through shared global reward signals.\n\n� Benchmarking: Against rule-based or greedy allocation.\n\n(b) Development component\n� Centralized task repository and agent state database to simulate real-world constraints.\n\n� Vector embeddings of task types and outcomes stored for similarity lookup in RAG-based training replay buffers or dynamic environment generation.\n\n� Logs used for post-hoc strategy comparison.",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0750",
    "title": "Privacy-Preserving Federated Learning and Domain Adaptation for Multi-Site fMRI Analysis",
    "summary": "Data has a �non-rivalrous� value, meaning multiple parties can use it simultaneously to generate insights. However, medical data sharing faces challenges due to privacy concerns, regulatory constraints, and institutional competition. Federated learning addresses these issues by enabling decentralized model training without data transfer. Another challenge is domain shift, as imaging data varies across institutions due to different scanners and protocols. Combining federated learning with domain adaptation techniques can enhance the reliability and generalizability of deep learning models in neuroimaging analysis for psychiatric disorders.\n\nWe address multi-site fMRI classification using a privacy-preserving federated learning approach. This method integrates a decentralized optimization algorithm with a randomization mechanism for model updates. To handle site-specific distribution shifts, we introduce two domain adaptation techniques. We aim for the results to demonstrate that federated learning improves neuroimage analysis while safeguarding data privacy, with potential for broader applications in medical data analysis.\n\nThe student will develop the necessary routines in Python with Pytorch libraries\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nStudent will research on deep learning approaches to synergistically learn fMRI data gathered over multiple sites\n\n(b) Development component\nThe student will develop the necessary routines in Python with Pytorch libraries",
    "supervisor": "Prof Jagath Chandana Rajapakse",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Biomedical Systems",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0751",
    "title": "Conversational AI Chatbot with task scheduling and recommendation",
    "summary": "Conversational AI chatbots have been widely developed to assist users in various tasks. However, when conversations involve task executions and scheduling such as booking a flight, how to parse task-related information to be connected with natural language interface is challenging. The objective of this project is to enable users to interact with the (multi-agent) system via conversational interface (e.g., �What should I do after lunch tomorrow?�).\n\nSpecific details:\n(a) Design component\n� NLP Pipeline: Parse scheduling or preference-related intents.\n\n� Dialogue Manager: Handle multi-turn clarification, confirmations.\n\n� End-to-End Integration: Connect parsed outputs to agent APIs and schedule changes.\n\n(b) Implementation component\n� Store parsed task intents and dialogue history for RAG retrieval (e.g., similar past conversations).\n\n� Use vector DB to power semantic search in user history and enable memory-augmented conversations (e.g., \"What did I say about my thesis two weeks ago?\").\n\n� Real-time updates reflected in the same agent-friendly task log schema used system-wide.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Wang Wenya",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0752",
    "title": "LLM-assisted Simulation Scenario Generation",
    "summary": "Realistic simulation scenarios can be contructed based on real-world observations. However, it may be challenging to collect sufficient real-world observations to reconstruct the simulation scenario. Large-Language Models (LLMs) excel at understanding and generating coherent, contextually relevant text. Research has also found that LLMs can provide a commonsense model of the world in addition to a policy that acts on it. This project seeks to construct simulation scenarios using commonsense knowledge generated from LLMs to fill in the gaps in the modelling details.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Design prompt to generate common sense knowledge from LLMs for scenario generation\n\n(b) Development component\n- Construct simulation scenarios using common sense knowledge from LLMs",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Animation/ Games",
      "Serious Games",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0753",
    "title": "Data Center Warning Detection",
    "summary": "A data center may contain a variety of servers, which hardware status cannot be monitored by external systems; they are only visible through the status lights on the physical server. A robot can be developed to patrol the data center and monitor the existing status lights on the servers for abnormalities. Then the robot can consolidate and send the warning message to the administrator.\n\nSpecific details:\n(a) Design component\n- Design CV techniques to recognize warning status lights\n\n(b) Implementation component\n- Implement warning light recognition\n- Integrate with autonomous robot\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Robotics",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0754",
    "title": "Office Space Occupancy Detection",
    "summary": "In an office setting, it is difficult to monitor occupancy without intrusive questions about workers' arrival or departure. A robot can be developed to patrol the office routinely to identify the occupancy of the seating space.\n\nSpecific details:\n(a) Design component\n- Design image recognition of a seating space\n- Design image detection of a human occupying a seat\n\n(b) Implementation component\n- Implement image detection on embedded system\n- Integrate with autonomous robot\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Robotics",
      "Real-Time / Embedded Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0755",
    "title": "Visual Visitor Management System",
    "summary": "It is difficult for an office setting to monitor the arrival of new visitors without human intervention. This project proposes an image recognition tool using the images from the security cameras to identify frequent visitors as regulars to the office, and infrequent visitors as newcomers. Hence, an alert can be raised for any newcomers to the office.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n- Personal image recognition\n- Image grouping for the same person\n\n(b) Development component\n- Develop an integrated system combining the personal image recognition with alert system.",
    "supervisor": "Dr Tan Wen Jun",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Image Analysis &amp; Processing",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0756",
    "title": "\"X\" Friend: \"X\" Application driven by data",
    "summary": "In this project, you will develop a mobile app (android or IOS) that uses the publicly available and accessible datasets on data.gov.sg to create an application that engages the public or help them in any possible front (environmental, healthcare, career, navigation). The \"X\" is your choice of area. You will look at the datasets available and you will have the freedom to discuss and decide what kind of application you want to develop.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Mining",
      "Software and Applications",
      "Mobile Applications",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0757",
    "title": "Attendance Management System -part 4",
    "summary": "This project aims to make the inventory management system attendance management system(mostly pen-paper based) to fully online paperless system.  The system need to scalable and efficient full stack development\n\nThis project already has a full stack developed. The current student need to work more on the attributes and fix the bugs and make it stream lined. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nDeliverable is a web application., where Medical Certificates from student's could be uploaded and verified if they are absent.\nThe new NTU pass should be used for the attendance capture\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "e-Commerce",
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0758",
    "title": "Enhancing Peer Evaluation in Group Projects",
    "summary": "Design a peer -evaluation tool with flexibility in metrics for evaluation. This should be in away where the best person in a team should get a higher score and the worst contributor should get the least. This study explores the weaknesses of existing peer evaluation methods and proposes improvements, such as structured rubrics, anonymous reviews, weighted scoring mechanisms, and feedback dashboard both of instructors and students . By refining peer evaluation systems, this research aims to promote fairness, transparency, and meaningful assessments in collaborative learning environments.\n\nNeed to do software development for the same. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0759",
    "title": "Academic emotion recognition using facial expressions",
    "summary": "Understanding students' emotions in the classroom is essential for enhancing learning experiences. This study focuses on recognizing key academic emotions�boredom, confusion, engagement, frustration, �from classroom videos using facial expression analysis. The DAiSEE dataset  is used for training the model, ensuring robust emotion classification. The trained model is then tested on real-time classroom videos to assess its effectiveness in recognizing student engagement levels. The insights gained can help educators adapt teaching strategies dynamically, fostering a more responsive and effective learning environment.\n\nThis study is in collaboration with NIE\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Bioinformatics",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0760",
    "title": "Consumer Electricity Flexibility-Aware Digital Twin (Smart City)",
    "summary": "The Consumer Electricity Flexibility-Aware Digital Twin framework combines clustering, statistical methods, and explainable AI to overcome stochastic customer behavior challenges. This framework enables precise Customer Baseline Load (CBL) estimation and quantifies electricity flexibility for informed-energy management. By providing transparent and data-driven insights, it supports informed decision-making and enhances customer participation in Demand Response (DR) programs, contributing to smart city objectives for optimized energy management.\n\nSpecific details:\n1.\tClustering customer behavior: Use clustering techniques to group customers based on their electricity consumption patterns, identifying similar behaviors.\n2.\tCBL estimation: Apply advance ML and statistical methods to accurately estimate the Customer Baseline Load (CBL) for each customer, accounting for variability in their consumption.\n3.\tFlexibility quantification: Measure and quantify the electricity flexibility of customers by analyzing their response to varying grid conditions or DR events.\n4.\tExplainable AI integration: Integrate explainable AI models to ensure transparency and interpretability, enabling informed decisions on customer participation in DR programs.\n5.\tData-driven insights for DR programs: Leverage insights from clustering and AI to optimize customer targeting for DR programs, improving participation rates and energy management.\n\nSkills required: \n1.\tMachine Learning (Clustering)\n2.\tTime-series\n3.\teXplainable AI (XAI)\n4.\tPython\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Arvind Easwaran",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0761",
    "title": "Optimized EV Fleet Charging Scheduling Using Machine Learning and Mathematical Optimization",
    "summary": "The proliferation of Electric Vehicles (EVs) in urban transportation presents challenges for managing their charging schedules, especially for fleet operators. This project aims to develop an optimized charging strategy for EV fleets using a combination of machine learning (ML) techniques and mathematical optimization. By using ML techniques on EV fleet charging dataset, the optimization problem understands the EV behaviour and accordingly seeks to minimize the overall charging costs while adhering to operational, grid-level, and service-level constraints. The project will also consider factors such as grid load, demand response signals, available charging sockets, and service requirements to ensure an optimal charging solution.\n\nSpecific details:\n\n\n1.\tPrepare the literature review on the latest state-of-the-art articles.\n2.\tCollect historical data related to EV fleet charging and grid-level data. Preprocess and clean the data for training ML models and feeding them into the optimization process.\n3.\tUse Exploratory Data Analysis (EDA) to understand the EV data and implement feature engineering. Develop ML models for predictions.\n4.\tOptimization problem formulation and implementation:\n\t� Define the optimization objective function: Minimize the total charging cost over a given scheduling horizon. Include constraints such as: Battery operational constraints (e.g., state of charge, battery health). Grid-level constraints (e.g., grid load, time-of-day pricing, demand response signals). Service-level constraints (e.g., charging socket availability, charging port type, charging rate, fleet service requirements).\n\nSkills required:\n1.\tMachine Learning\n2.\tEDA\n3.\tOptimization (Gurobi library)\n4.\tPython",
    "supervisor": "A/P Arvind Easwaran",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Discrete Math"
    ]
  },
  {
    "projectNo": "CCDS25-0762",
    "title": "Uncertainty quantification for machine learning methods via conformal prediction",
    "summary": "Conformal prediction is a novel approach to quantifying uncertainty of machine learning predictions, and producing statistically valid prediction regions only assuming exchangeability of the data. The goal of this project is to review some of the literature on conformal prediction, and then implement and evaluate such methods on several datasets. Comparisons will also be done with alternative uncertainty quantification approaches.\n\nReferences: \n[1] Conformal prediction: A gentle introduction by Angelopoulos and Bates\n[2] Conformalized quantile regression by Romano, Patterson, and Candes\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Daniel Paulin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Theory &amp; Algorithms",
      "Artificial Intelligence",
      "Data Structure and Algorithms",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0763",
    "title": "Learning with fewer labels: a review of active learning methods",
    "summary": "Obtaining labelled data is time consuming, and often expensive. Active learning is a machine learning approach where we are presented with a large set of unlabeled data, and the goal is to select the most informative ones for labelling, reducing the number of samples required for accurately predicting labels.\nIn this project, we will review the recent developments in active learning, and implement and compare various algorithms on several datasets. We will also consider combining active learning with contrastive learning, a powerful approach to data augmentation.\n\nReferences: \n[1] Ren, P. et al. \"A survey of deep active learning\". ACM computing surveys (CSUR), 54(9), 1-40, 2021\n[2] Gal, Yarin, Riashat Islam, and Zoubin Ghahramani. \"Deep bayesian active learning with image data.\" International conference on machine learning. PMLR, 2017.\n[3] Chen, Ting, et al. \"A simple framework for contrastive learning of visual representations.\" International conference on machine learning. PmLR, 2020.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Daniel Paulin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Structure and Algorithms",
      "Machine Learning",
      "Image Analysis &amp; Processing",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0764",
    "title": "Sampling from distributions via generative diffusion models",
    "summary": "Denoising diffusion probabilistic models have been widely used for image generation, and they already been implemented on smartphone image editing applications.\nThe main idea of such methods is that a probabilistic diffusion model transform the original samples into noise, and this process is then reversed in time to generate further samples.\n\nIn this project, we will review a recent approach using generative diffusion models for generating samples from general distributions where we can evaluate the density up to an unknown normalizing constant. We are going to implement the approach and compare it with alternative methods on a variety of target distributions. \nSome possible extensions will also be considered.\n\nReference:\n[1] Vargas, F., Grathwohl, W. S., &amp; Doucet, A. Denoising Diffusion Samplers. In The Eleventh International Conference on Learning Representations.\n[2] Noble, M., Grenioux, L., Gabri�, M., &amp; Durmus, A. O. Learned Reference-based Diffusion Sampler for multi-modal distributions. In The Thirteenth International Conference on Learning Representations.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Daniel Paulin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Theory &amp; Algorithms",
      "Machine Learning",
      "Data Structure and Algorithms",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0765",
    "title": "Generative data augmentation",
    "summary": "Generative models are capable of creating novel samples that are distinct from the input samples used for training them. Generative data augmentation aims to increase the performance of Machine Learning models by enriching the training data with additional examples created by generative models. In this project, we will review existing approaches to generative data augmentation, and evaluate them on a variety of datasets. We will also implement novel methods\n\nReferences: \n[1] Zheng, C., Wu, G., &amp; Li, C. (2023). Toward understanding generative data augmentation. Advances in neural information processing systems, 36, 54046-54060.\n[2] Chen, Y., Yan, Z., &amp; Zhu, Y. (2024). A comprehensive survey for generative data augmentation. Neurocomputing, 128167.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Daniel Paulin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Structure and Algorithms",
      "Data Analytics",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0766",
    "title": "LLM generated text detection",
    "summary": "In many settings, it is desirable to detect text that was generated by Large Language Models (LLM). In this project, we will review existing approaches to this problem.\nWe will implement several approaches including ones based on simple statistical methods, and evaluate their performance on a variety of datasets containing texts of different length. \n\nReferences: \n[1] Mitchell, E., Lee, Y., Khazatsky, A., Manning, C. D., &amp; Finn, C. (2023, July). Detectgpt: Zero-shot machine-generated text detection using probability curvature. In International Conference on Machine Learning (pp. 24950-24962). PMLR.\n\n[2] Wu, J., Yang, S., Zhan, R., Yuan, Y., Chao, L. S., &amp; Wong, D. F. (2025). A survey on LLM-generated text detection: Necessity, methods, and future directions. Computational Linguistics, 1-66.\n\n[3] Radvand, T., Abdolmaleki, M., Mostagir, M., &amp; Tewari, A. (2025). Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities. arXiv preprint arXiv:2501.02406.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Daniel Paulin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Structure and Algorithms",
      "Data Analytics",
      "Machine Learning",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0767",
    "title": "Predicting soccer match outcomes using machine learning methods",
    "summary": "In this project, we will review the literature on soccer outcome prediction, and implement several machine learning approaches for this task. The algorithms will be evaluated on Premier League datasets.\n\nReferences: \n[1] Bunker, R., &amp; Susnjak, T. (2022). The application of machine learning techniques for predicting match results in team sport: A review. Journal of Artificial Intelligence Research, 73, 1285-1322.\n\n[2] Dubitzky, W., Lopes, P., Davis, J., &amp; Berrar, D. (2019). The open international soccer database for machine learning. Machine learning, 108, 9-28.\n\n[3] Berrar, D., Lopes, P., &amp; Dubitzky, W. (2019). Incorporating domain knowledge in machine learning for soccer outcome prediction. Machine learning, 108, 97-126.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Daniel Paulin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Structure and Algorithms",
      "Data Analytics",
      "Machine Learning",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0768",
    "title": "Sequential Monte Carlo methods for sampling from Bayesian neural network posteriors",
    "summary": "In this project, we will study the use of Sequential Monte Carlo methods for sampling from Bayesian posterior distributions, in particular, those arising from neural network models. \nSuch posterior distributions are known to be highly multimodal, hence they are challenging to sample from, but Sequential Monte Carlo methods are known to perform well for multimodal distributions. \nThe samples obtained can be used for uncertainty quantification, and may also yield better predictive performance.\nThe project will involve implementation of the developed algorithms in PyTorch, and evaluation on a variety of datasets and neural network models.\n\nReferences:\n[1] Dai, C., Heng, J., Jacob, P. E., &amp; Whiteley, N. (2022). An invitation to sequential Monte Carlo samplers. Journal of the American Statistical Association, 117(539), 1587-1600.\n\n[2] Paulin, D., Whalley, P. A., Chada, N. K., &amp; Leimkuhler, B. (2024). Sampling from Bayesian neural network posteriors with symmetric minibatch splitting Langevin dynamics. arXiv preprint arXiv:2410.19780.\n\n[3] Paulin, D., Jasra, A., &amp; Thiery, A. (2019). Error bounds for sequential Monte Carlo samplers for multimodal distributions. Bernoulli, 25(1), 310-340.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Daniel Paulin",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Structure and Algorithms",
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0769",
    "title": "Computer vision enabled navigation",
    "summary": "The objective of the project is to adapt robotic exploration to incorporate intelligence.\n\nThe project will be an extension of multidisciplinary project. The student is expected to analyze the given hardware and change if needed to tune for the requirement. Additional intelligence need to be supported by the RPi module for intelligent exploration\nStudent need to complete MDP.\n\nNo Graduate student to help.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nThe objective of the project is to adapt robotic exploration to incorporate intelligence\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Design & Implementation",
    "keywords": [
      "Robotics",
      "Machine Learning",
      "Real-Time / Embedded Systems",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0770",
    "title": "Object Detection and Path planning with remote teleoperation of robotic car",
    "summary": "Using MDP robot and VR camera, achieve remote teleoperation of the robot and object detection. detected objects should be processed to plan the path\n\nThe student should have completed multi disciplinary project\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nTo design and implement semi automatic way for machine learning models on resource constrained computing platforms.\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Research & Development",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Robotics",
      "Machine Learning",
      "Hardware Acceleration"
    ]
  },
  {
    "projectNo": "CCDS25-0771",
    "title": "EEG-Driven Gaming: Translating Neural Intent into Action",
    "summary": "The project is do develop a control strategy where control signals are provided by the brain waves. A game interface needs to be controlled (via bluetooth) by raw EEG signals generated . The control has to be real time. Eye tracker can also be used an an input \n\nSpecific details:\n(a) Design component\nGUI need to be developed and interfaced with game\n\n\n(b) Implementation component\nConnecting the brain wave acquisition system and getting the control signals to control the game\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Computer Animation/ Games",
      "Virtual Reality",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0772",
    "title": "AI-Driven Serious Game Design",
    "summary": "The project includes  development of GUI and enhancing the same using Artificial intelligence . \n\nA good knowledge of C#, Unity 3D is required.\n\nPlease note that there are no PhD or Postdoc to guide you and you will be under my direct supervision\n\nSpecific details:\n(a) Design component\nStudents need to design a good game platform that can take EEG signals as a control input.\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Biomedical Systems",
      "Human Computer Interaction",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0773",
    "title": "Immersive Learning Through Augmented Reality Games",
    "summary": "To use augmented reality for learning applications. AR or VR can be used\n\nThere are no research staff to guide you and you will be directly under my guidance\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Gamification",
      "Smartphone Systems and Applications",
      "Virtual Reality"
    ]
  },
  {
    "projectNo": "CCDS25-0774",
    "title": "Gradient Estimation over Discrete Branches in Machine Learning Libraries",
    "summary": "Automatic differentiation (AD) [1] is a core feature of machine learning libraries like PyTorch [2], allowing efficient computation of gradients over complex computational graphs. However, although discrete branches (e.g., if-else constructs) are commonplace in real-world problems, gradients computed by standard AD techniques often do not reflect the effects of branches on the computed output. The recently proposed DiscoGrad Gradient Oracle (DGO) [3,4] combines AD and branch-level statistics to efficiently compute gradients over discrete branches. However, its implementation is currently limited to C++ programs.\n\nThis project aims to explore how DGO can be adapted and implemented within PyTorch or an equivalent machine learning library, enabling gradient estimation over discrete branches in computational graphs. The goal is to extend the gradient computation capabilities and provide a robust solution for handling discrete decisions during training by integrating DGO's AD and stateful estimation techniques into the library's gradient estimations.\n\n[1] Margossian, Charles C. \"A review of automatic differentiation and its efficient implementation.\" Wiley interdisciplinary reviews: data mining and knowledge discovery 9, no. 4 (2019): e1305.\n[2] Paszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen et al. \"Pytorch: An imperative style, high-performance deep learning library.\" Advances in neural information processing systems 32 (2019).\n[3] Kreikemeyer, Justin N., and Philipp Andelfinger. \"Smoothing methods for automatic differentiation across conditional branches.\" IEEE Access (2023).\n[4] Andelfinger, Philipp, and Justin N. Kreikemeyer. \"Automatic Gradient Estimation for Calibrating Crowd Models with Discrete Decision Making.\" In International Conference on Computational Science, pp. 227-241. Cham: Springer Nature Switzerland, 2024.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n  - Study the principles of automatic differentiation (AD) and DGO, and select a suitable machine learning library.\n   - Propose a design that integrates DGO into the library and justify the key design choices taken.\n   - Implement the proposed solution within the machine learning library, ensuring compatibility with its AD system, and evaluate its performance and fidelity.",
    "supervisor": "Prof Cai Wentong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0775",
    "title": "Self-Calibrating Generative Agents",
    "summary": "Generative agents have been proposed as \"believable simulacra of human behavior\" [1]. Relying on the recent advances in large language models (LLMs), generative agents can form opinions, communicate among each other, follow daily routines, form plans, and remember previous experiences. The capability of generative agents to exhibit \"common sense\" reasoning makes them attractive for building believable and explainable models of human decision-making. On the other hand, many practical uses of models involving simulated humans, e.g., for studying build evacuations, must be shown to be valid based on the adherence of the simulated behavior to real-world empirical data.\n\nThe goal of this Final Year Project is to bring the capabilities of generative agents to simulate human-like behavior together with the well-defined requirements of evacuation studies. In a self-calibration environment, agents will follow their own generated narrative, reasoning, and actions while interacting with simulated evacuation scenes formulated based on real-world experiments from the literature [2]. Automatic feedback from the simulated environment will allow for a gradual harmonization of the generated evacuations with physical constraints and the real-world observations without the need for user intervention.\n\n[1] Park, Joon Sung, Joseph O'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. \"Generative agents: Interactive simulacra of human behavior.\" In Proceedings of the 36th annual acm symposium on user interface software and technology, pp. 1-22. 2023.\n[2] Kobes, Margrethe, Ira Helsloot, Bauke de Vries, and Jos Post. \"Exit choice,(pre-) movement time and (pre-) evacuation behaviour in hotel fire evacuation�Behavioural analysis and validation of the use of serious gaming in experimental research.\" Procedia Engineering 3 (2010): 37-51.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n  - Construct simple representation of building evacuation scenario from the literature [2] in an existing crowd simulation framework.\n  - Formulate an interaction protocol between LLM and simulation.\n  - Prompt engineering and iterative refinement to realise self-calibration loop.",
    "supervisor": "Prof Cai Wentong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0776",
    "title": "Comparing Thread Interaction Models for Discrete-Event Simulation on Graphics Processing Units",
    "summary": "Graphics processing units (GPUs) have become indispensable accelerators in most areas of scientific computing. One important application area is discrete-event simulation (DES) [1]. In DES, the state of a simulated system (e.g., a computer network or a manufacturing plant) evolves over time through a series of events that signify instantaneous changes in the system�s state. It has been shown that GPUs can accelerate DES substantially [2], but careful design of the data structures is required to efficiently support the fine-grained thread interactions induced by this class of simulations [3].\n\nA recently proposed parallelized DES algorithm [4] targeting CPUs achieves high-efficiency thread interactions by fine-grained locking and shared memory accesses rather than the traditional message passing, thus significantly reducing the number of synchronization rounds and memory accesses. Due to the synchronous execution model and the substantial cost of memory accesses on GPUs, this approach holds significant promise for GPU-based DES.\n\nThe objective of this Final Year Project is to compare message-based and lock-based thread interaction on GPUs both in isolation and when applied as part of a DES implementation. The overall performance is evaluated using a simple simulation model from epidemiology.\n\nReferences are available on request.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nThe comparison of the thread interaction models will take two approaches: first, the fundamental performance characteristics will be determined using micro-benchmarks on the basis of metrics such as instructions and cache misses per thread interaction. In a second step, the message-based and locking-based interaction will be implemented to execute a simple epidemiological model and assessed when applied to overall simulations. By varying the model dynamics, the relative merits of the two approaches are evaluated under different workload conditions.",
    "supervisor": "Prof Cai Wentong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Parallel Computing",
      "Hardware Acceleration"
    ]
  },
  {
    "projectNo": "CCDS25-0777",
    "title": "Speculative Parallel Simulation of Event-Driven Molecular Dynamics",
    "summary": "Discrete molecular dynamics models form the basis for important models for simulating ideal gases, granular materials, or even star and planet formations. Classically, these models are simulated by advancing the simulation time in steps of fixed size. This approach comes with substantial overhead due to the sparsity of collisions. The method of event-driven molecular dynamics avoids unnecessary computational steps by iteratively advancing to the time of the next inter-particle collision [1]. While more efficient, this approach requires careful updating of projected collision times. While several implementations have been proposed [2-4] , event-driven molecular dynamics on modern parallel architectures is still considered to be challenging [4].\n\nThe goal of this Final Year Project is to assess the suitability of different classes of parallel simulation algorithms for accelerating event-driven molecular dynamics simulations, and to derive recommendations for implementors in order to achieve highest performance on modern hardware.\nThe focus is on contrasting asynchronous parallel simulation using the Time Warp algorithm [5] and synchronous parallel simulation using the recently proposed Window Racer algorithm [6].\n\nReferences are available on request.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nIn the first stage of the project, a literature review on existing work in parallel event-driven molecular dynamics is conducted in order to understand and categorize the algorithms proposed in the literature. In the second stage, a basic molecular dynamics model is implemented in two existing simulation frameworks that implement Time Warp and Window Racer, respectively. In the final stage, measurements are conducted to study the suitability of the algorithms under different model parametrizations and to identify potentials for further optimizations or specializations for this class of",
    "supervisor": "Prof Cai Wentong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Parallel Computing",
      "High-Performance Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0778",
    "title": "Simulation Modelling of AI Clusters",
    "summary": "The performance of AI clusters can be affected by various factors, such as model parameters, workload distribution, job scheduler logic, topology, and hardware specifications. Optimizing performance for a specific aspect of the AI cluster may only achieve localized improvements and not fully utilize the cluster's potential. To address this, a unified simulation framework is needed to accurately simulate AI workloads and model the performance of computing, memory, and networking components within large-scale AI training clusters. Such a framework will facilitate comprehensive design and optimization across different system levels and support data-driven decision-making in AI cluster design. In this project, the student will review existing research on simulating AI clusters, with a particular focus on AI workload modelling.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Cai Wentong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0779",
    "title": "Investigate Viral Spreading in Enclosed Environment Using Agent-based Modelling and Simulation",
    "summary": "This project aims to develop an agent-based simulation of viral transmission in an enclosed environment to provide a platform for analysis of the spread of virus and policy interventions in the enclosed space.  The student will first need to study the identified scenario and develop an agent-based model.  The traces generated from simulation will be then used for contact analysis for viral transmission.  \n\nReference:\nH. M. S. S. a. M. Ismail Husein, \"Modeling the Transmission of Infectious Disease in a Dynamic Network,\" 2019. [Online]. Available: https://iopscience.iop.org/article/10.1088/1742-6596/1255/1/012052. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Cai Wentong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0780",
    "title": "Application of Generative AI for Agent-based Modelling",
    "summary": "There has been a recent rise in the usage and popularity of Generative Artificial Intelligence (AI), such as ChatGPT especially with its ability to mimic human behaviour. This final year project explores the novel application of Generative AI in the domain of agent-based modelling, aiming to overcome the challenge of incorporating nuanced human behaviour in agent-based modelling.  By leveraging Chat GPT, this study seeks to enhance the cognitive realism of agents within an agent-based simulation.  In this approach, ChatGPT will be used to generate data required to train a behaviour model for agents.  Possible application domains include agent-based epidemic simulation and agent-based crowd simulation. \n\nReferences:\nJ.S. Park et al., \"Generative Agents: Interactive Simulacra of Human Behavior,\" arxiv2023, 2023\n[Online]. Available: https://arxiv.org/abs/2304.03442\n\nR. Williams, N. Hosseinichimeh, A. Majumdar, and N. Ghaffarzadegan, \"Epidemic Modeling with\nGenerative Agents,\" arxiv2023, 2023 [Online]. Available: https://arxiv.org/abs/2307.04986\n\nN. Ghaffarzadegan, A. Majumdar, R. Williams, and N. Hosseinichimeh, \"Generative Agent-Based\nModeling: Unveiling Social System Dynamics through Coupling Mechanistic Models with Generative\nArtificial Intelligence,\" arxiv2023, 2023 [Online]. Available:\nhttps://arxiv.org/ftp/arxiv/papers/2309/2309.11456.pdf\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Cai Wentong",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0781",
    "title": "EEG based emotion recognition",
    "summary": "Emotion recognition using electroencephalography (EEG) has gained significant attention in affective computing and neuroscience. EEG signals capture neural activity associated with emotional states, providing an objective approach to emotion detection. This study explores machine learning techniques to recognize emotions based on EEG data, leveraging features such as frequency bands, temporal patterns, and connectivity metrics. The findings have potential applications in mental health monitoring, human-computer interaction, and adaptive learning environments.\n\nThis work is in collaboration with Dr. Yuvaraj (NIE)\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nFACED EEG dataset https://www.nature.com/articles/s41597-023-02650-w\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Bioinformatics",
      "Machine Learning",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0782",
    "title": "Neuroadaptive Game Design for Cognitive Enhancement",
    "summary": "We are designing many cognitive games for elderly to practice their memory. This project is to design and develop a serious game for elderly to train their cognitive functions so as to slow down their function loss such as memory loss. The game development will be using Unity 3D with leap motion or VR  as one of options in the project.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Serious Games",
      "Human Computer Interaction",
      "Gamification"
    ]
  },
  {
    "projectNo": "CCDS25-0783",
    "title": "Music and the Relaxed Brain: An EEG Exploration",
    "summary": "This study aims to explore the real-time impact of various music types on relaxation levels , employing Electroencephalogram (EEG) analysis as a tool for comprehensive investigation.\n A good knowledge about machine learning and pattern recognition is expected.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nstudy the effect of same by introducing music varying in perceived valence and arousal. \n\n(a) Research component\nextract physiological signals . \n\n(b) Development component\ndataset available : Electroencephalography (EEG) dataset during naturalistic music listening comprising different genres with familiarity and enjoyment ratings\nDEEP",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Biomedical Systems",
      "Hardware Acceleration"
    ]
  },
  {
    "projectNo": "CCDS25-0784",
    "title": "Multiscale Attentional State Recognition in Game Play",
    "summary": "The project includes  development of GUI and enhancing the same using Artificial intelligence . A good knowledge of C#, Unity 3D is required.\nThe objective of the project is to do a real time control with a neurofeedback given to the user in the form of a visual display.\n\nIn this work a game needs to be designed which will be controlled by using the signals from Electroencephalogram (EEG).  In order to translate brain signal to an effective control signal, it is important to develop appropriate data acquisition techniques and feature extraction/classification algorithms. EEG-based BCIs is been employed for games to improve attention skills. \n\nSpecific details:\n(a) Design component\nStudents need to design a good game platform that can take EEG signals as a control input.\n\n(b) Implementation component\n\n(a) Research component\nMultiple levels of attention need to be recorded\n\n(b) Development component",
    "supervisor": "Dr Smitha K G",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Biomedical Systems",
      "Human Computer Interaction",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0785",
    "title": "Leveraging Large Language Models for Intelligent Project-Specific Query Understanding",
    "summary": "As projects grow in scale and complexity, developers and users frequently ask various project-related questions. While large language models (LLMs) can interpret queries, token limits and hallucinations hinder precise responses. Moreover, the absence of large-scale datasets and evaluation metrics makes it difficult to quantify LLMs� limitations and capabilities, while the lack of effective methods to improve their reliability in real-world scenarios. This project aims to construct datasets, define evaluation criteria, and develop methods to assess and improve LLMs' accuracy in answering project-level inquiries.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nExplore new methods in enhancing LLMs' capability in answering project-specific questions more reliably.\n\n(b) Development component\n\nCollect benchmark data and develop evaluation frameworks.",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Software and Applications",
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0786",
    "title": "Multi-source knowledge fusion for domain-specific knowledge graphs",
    "summary": "Knowledge graph is a powerful method for organizing and representing structured data, facilitating complex reasoning and enhanced decision-making. However, constructing, merging, and maintaining domain-specific knowledge graphs remains challenging due to data heterogeneity, dynamic evolution, and inconsistent representations across multiple sources. This project aims to develop a multi-source knowledge fusion framework that leverages LLMs and other AI techniques to integrate and harmonize diverse knowledge sources. The student is expected to work alongside with a team of researchers on topics centered around environmental issues.\n\nSpecific details:\n(a) Design component\nDesign the fusion framework\n\n(b) Implementation component\n\n(a) Research component\nKnowledge graph enhanced with LLMs\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0787",
    "title": "Creating domain-specific expert with fine-tuned LLMs and RAG",
    "summary": "LLMs have been utilized in many real-world applications to provide decision support. Nonetheless, without fine-tuning, most LLMs still fall short in tasks that require domain-specific knowledge. This project aims to elevate decision making by fine-tuning LLMs to produce more accurate and contextually relevant outputs. Additionally, the solution should integrate Retrieval-Augmented Generation (RAG) to incorporate domain-specific data into model responses. The student is expected to work alongside with a team of researchers on topics centered around environmental issues.\n\nSpecific details:\n(a) Design component\nIntegration with RAG for prompting\n\n(b) Implementation component\n\n(a) Research component\nEvaluation of fine-tuned models in decision making\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0788",
    "title": "Exploring the use of  LLM in encouraging students to engage in interdisciplinary learning",
    "summary": "This project aims to build an app to encourage users to engage in interdisciplinary learning by providing feedback on interdisciplinary natured essays. \n\nSpecific details:\n(a) Design component\n\nThe design of an app to encourage users to engage in interdisciplinary learning in CC0006\n\n(b) Implementation component\n\nThe implementation of an to encourage users to engage in interdisciplinary learning\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0789",
    "title": "An app for second language learning",
    "summary": "The project aims to build an app to assist users in learning the second language leveraging on the power of GenAI, e.g., GPT models. The app can focus on one or more aspects, e.g., reading, writing,  speaking, and listening. \n\nSpecific details:\n(a) Design component\n\nDesign an app to learn the second language\n(b) Implementation component\n\nImplementation of the app to learn the second language\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0790",
    "title": "Generation of false samples for skills improvement",
    "summary": "The project aims to build an app which will generate false samples for users to practice in order to improve users' skills and capabilities by practicing on properly generated false samples\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nThe generations of false samples using GenAI technologies\n\n(b) Development component\nThe implementation of an app which is built up with the functions of generating false sample.",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0791",
    "title": "A serious game to assist students in computer science modules post-learning",
    "summary": "This project aims to build a game to assist students in  reinforcing what they have learned in computer science modules to gain a deeper understanding. \n\nSpecific details:\n(a) Design component\nThe design of the game. \n\n(b) Implementation component\nThe implementation of the game. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Serious Games"
    ]
  },
  {
    "projectNo": "CCDS25-0793",
    "title": "Recommendations with Uncertainty",
    "summary": "The project aims to develop advanced recommendation systems considering the uncertainty inherent in these predictions. In the rapidly evolving landscape of recommendation systems, particularly in domains like e-commerce, streaming services, and personalized content delivery, understanding both the recommendation itself and the uncertainty in that recommendation is crucial for enhancing user trust and engagement. Focusing on the explainability of uncertainty,  the outcomes of this project are expected to contribute to the field of recommendation systems, particularly in contexts where understanding the uncertainty in recommendations is as important as the recommendations themselves.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0794",
    "title": "To make novel recommendations in recommender systems",
    "summary": "This project aims to develop approaches to making novel recommendations to users in recommender systems to reduce the appearance of similar recommendations. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearch on approaches to making novel recommendations\n\n(b) Development component\nImplementation of approaches to making novel recommendations",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0795",
    "title": "An app to encourage users to engage in interdisciplinary learning",
    "summary": "This project aims to build an app to encourage users to engage in interdisciplinary learning by providing feedback on interdisciplinary natured essays. \n\nSpecific details:\n(a) Design component\n\nThe design of an app to encourage users to engage in interdisciplinary learning for CC0002\n\n(b) Implementation component\n\nThe implementation of an to encourage users to engage in interdisciplinary learning\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0796",
    "title": "Environment Construction and AI Agent Training in Minecraft",
    "summary": "This project focuses on developing AI agents in Minecraft using MineDojo, an open-ended framework for embodied agent research. Once the environment is set up, the student will implement and train an AI agent within it using machine learning techniques. The agent�s performance will be evaluated and iteratively improved by fine-tuning training strategies and adjusting environmental parameters.\n\nSpecific details:\n(a) Design component\nSetup the Agent environment with MineDojo.\n\n(b) Implementation component\n\n(a) Research component\nAI based agent training and evaluation\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Serious Games"
    ]
  },
  {
    "projectNo": "CCDS25-0797",
    "title": "Prediction Correction with Uncertainty Estimation",
    "summary": "This project aims to develop a novel framework where machine learning models possess self-awareness and self-correction capabilities. This project explores techniques to enable models to monitor their own performance, identify errors in predictions, and autonomously correct them. By integrating feedback mechanisms, the models will dynamically adapt and refine their predictions, improving accuracy and reliability over time.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nUse RUE / IG-RUE to compute reconstruction error. Build a second model that takes in the original query x as well as the reconstruction error for prediction. \n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0798",
    "title": "FACE Explanation with Uncertainty Estimation",
    "summary": "Feature Attribution Computed Exactly (FACE) is a novel XAI method for feature attribution that enables direct computation of explanations. This project will explore FACE�s application across multiple datasets and investigate how uncertainty estimation can be integrated into its explanations. The outcome will be novel algorithms that provide \"uncertainty-aware explanations.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nimplement FACE on MLPs; add in uncertainty estimation; experiment on multiple datasets.\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0799",
    "title": "Uncertainty Quantification with Tree-based Prediction Models",
    "summary": "Uncertainty quantification is essential for establishing trust in machine learning models. This project investigates methods for achieving reliable uncertainty quantification using tree-based models. By examining the properties of decision trees, we aim to develop algorithms capable of capturing various types of uncertainty in predictions. The outcomes will include novel algorithms for both classification and regression tasks, supported by experimental evaluations on multiple datasets.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n: implement tree-based models, be able to extract paths, leaf nodes. Develop methods for computing uncertainty estimates from depths and node sizes. Also need to implement baseline algorithms for comparison.\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0800",
    "title": "CAREER Platform Development�AI-Powered Learning for Autistic Adults",
    "summary": "This project focuses on the end-to-end development of the CAREER educational platform, an AI-powered tool designed to enhance employment readiness for autistic adults. The student will architect and implement the platform�s core functionalities, including integration of adaptive learning modules, real-time AI-driven feedback systems, user-friendly interfaces, and robust backend infrastructure. The project involves software design, database management, AI integration, and usability testing, directly contributing to CAREER�s deployment readiness.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0801",
    "title": "Interactive Workplace Simulation for Employment Readiness",
    "summary": "This project aims to create an interactive, game-like workplace simulation designed to prepare autistic individuals for real-world employment scenarios. The student will design virtual job scenarios, implement interactive decision-making features, and provide real-time AI-driven feedback on user choices. The project includes user-interface design, usability testing, and performance evaluation based on real-world usability metrics. Outcomes from this project will directly contribute to CAREER�s job-simulation modules.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0802",
    "title": "Fisher Information for Precise Feature-Attribution",
    "summary": "Understanding uncertainty is crucial for ensuring the reliability of explainable artificial intelligence (XAI) methods. This project explores a new information-theoretic approach to feature attribution, considering the precision of features in predictive models. The student will develop methods to adjust feature attribution weights based on the available information, improving the robustness of explanations. Evaluating the developed approach(es) against existing state-of-the-art methods. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nComputes the Fisher Information Matrix w.r.t model params and takes the diagonal as a direct form of feature attribution. Alternatively, compute the Fisher Information Matrix w.r.t to model parameters and weigh existing feature attribution methods to ensure �precise� attributions are given more weight.\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0803",
    "title": "Conditional Time-series Data Generation and Explanations",
    "summary": "Synthetic data plays a crucial role in preserving data privacy, particularly in sensitive fields like healthcare and finance. However, generating realistic multivariate time-series data with privacy guarantees remains a challenge due to the limited number of existing approaches. In this project, the student will develop new methods for synthetic time-series data generation by extending existing techniques with time-based conditionals. The effectiveness of these methods will be evaluated against established approaches such as TimeVAE and TimeGAN. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nTake the Conditional TimeVAE implementation from FYP Max, extend the generation to sequences instead of single time points. Compare the generation with existing methods and evaluate e.g. Wasserstein distance, quality of data generation via prediction models &amp; similarity of explanations against the true data. \n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0804",
    "title": "Conversational AI System for Enhancing Ikigai and Mental Well-Being",
    "summary": "This project aims to design and develop an AI-powered conversational application that supports mental well-being by helping users explore and strengthen their sense of Ikigai�a Japanese concept that embodies one�s purpose in life and source of fulfillment. The proposed system will leverage Large Language Models (LLMs) to generate personalized and context-aware conversations that guide users through introspection, goal formulation, and sustained motivation. \n\nSpecific details:\n(a) Design component\nThe project will involve building a functional prototype. \n\n(b) Implementation component\n\n(a) Research component\nEvaluation on the impact on perceived well-being with the implementation of Ikigai model\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0805",
    "title": "Purposeful and explainable dimensionality reduction for financial data",
    "summary": "This project aims to develop a combined framework of contrastive learning and adversarial networks to disentangle spuriously correlated features in financial market data. By reducing high-dimensional information into a smaller and more interpretable set of factors, we expect to improve human-readability without compromising predictive performance.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0806",
    "title": "Multi-level Hierarchical Reinforcement Learning for Portfolio Management",
    "summary": "This project uses a hierarchical reinforcement learning (HRL) approach for portfolio management. A high-level agent decides overall risk constraints, while lower-level agents determine precise asset allocation subject to these constraints, with some degree of freedom. The objective is to manage risk effectively while preserving diversity in portfolio actions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0807",
    "title": "AI Augmented Mobile Application for Health Assessment and Intervention",
    "summary": "With the pervasiveness of smartphones, there are more and more health coach-themed mobile applications available on the market. Nonetheless, many of them focus on a very limited number of functionalities, such as only diet intake tracking for assessment or only medication reminders for intervention. In addition, many commercial mobile apps are not designed and developed together with doctors, as such, the efficacy of such apps may be questionable. \n\tIn this project, the student is expected to work with an experienced team of doctors, researchers and developers and contribute to part of the virtual health coach mobile application design and implementation. \n\nSpecific details:\nThe student should excel in Unity 3D development or at least master related programming languages such as C#, XML, etc. \n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0808",
    "title": "AI Mobile Health Coach for Health Assessment and Intervention",
    "summary": "With the pervasiveness of smartphones, there are more and more health coach-themed mobile applications available on the market. Nonetheless, many of them focus on a very limited number of functionalities, such as only diet intake tracking for assessment or only medication reminders for intervention. In addition, many commercial mobile apps are not designed and developed together with doctors, as such, the efficacy of such apps may be questionable. In this project, the student is expected to work with an experienced team of doctors, researchers and developers and contribute to part of the virtual health coach design and implementation. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nThe student should excel in Unity 3D development or at least master related programming languages such as C#, XML, etc.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Human Computer Interaction",
      "Mobile Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0809",
    "title": "Intelligent Conversational System for Pre-Consultation Symptom Collection",
    "summary": "In clinical practice, physicians typically begin consultations by collecting essential patient information, including demographics, chief complaints, and medical history. This manual intake process is often time-consuming and may reduce consultation efficiency, particularly in high-demand healthcare settings. This project proposes the design and development of an AI-powered conversational system to streamline pre-consultation symptom collection in a more efficient, scalable, and patient- and/or doctor-friendly manner.\nThe system will leverage Large Language Models (LLMs) and natural language processing (NLP) to conduct adaptive, context-aware dialogues with patients. The project will also explore multimodal input methods (e.g., text and voice) and apply user-centered UI/UX design principles to ensure accessibility and ease of use across diverse patient populations. In addition, it may investigate effective formats for presenting the collected data to physicians, with the goal of enhancing clinical efficiency.\n\nSpecific details:\n(a) Design component\nDesign and implement the conversation application\n\n(b) Implementation component\n\n(a) Research component\nLeverage LLMs and NLP for data collection and analysis\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0810",
    "title": "Entity resolution benchmarks - the next level",
    "summary": "Entity resolution (ER) identifies multiple representations of real-world entities, so-called matches, within or across data sources. Posed as a classification problem, machine learning (ML) models have become highly successful in accurately distinguishing matches from non-matches - at least on the benchmarks established for traditional ER methods not relying on ML years ago. Is the ER problem solved, then? Or have the benchmarks become too easy, and ER research is ready to push its frontier toward new challenges (e.g., sparse and heterogeneous data with minimal overlap, entities harder to distinguish due to high data overlap, etc.)?\n\nThis project explores different dimensions for creating the next generation of ER benchmarks that may allow us to identify shortcomings of / differences between state-of-the-art techniques. Developing a benchmark covering different dimensions and the quantitative evaluation of state-of-the-art approaches using the proposed benchmark will help determine what problems ER research may tackle next. \n\nSpecific details:\n\n\n(a) Research component\n\n-   Definition of a new benchmark for entity resolution based on systematic review and analysis. \n- Methods to produce new benchmark datasets to address the benchmark tasks. \n\n(b) Development component\n- Implementation of the benchmark and evaluation of several ER techniques using the benchmark.",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0811",
    "title": "Bias-assessment in data preparation pipelines (Part III)",
    "summary": "The media have reported numerous examples of systems relying on machine learning (ML) that exhibit bias and discrimination against different groups of people, e.g., based on race or gender. One reason for this unwanted behavior lies in the underlying data used for ML. Therefore, research on fair machine learning has proposed metrics and algorithms to assess and improve the data to foster fair outcomes. These approaches typically focus on one step of an analytics pipeline (e.g., training, sampling, discretization), resulting in local improvements along the pipeline. There is a research gap concerning the global effect along a pipeline targeting fair ML. \n\nAs a first step towards fair ML pipelines, the overarching goal of this project is to investigate methods to identify possible causes of bias in a data preparation pipeline.  In this part of the project, research will focus on bias assessment based on data quality profiles that record various characteristics (sparsity, value distributions, etc.) captured during data preparation execution.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n- Literature review on bias in ML and its mitigation, and data  profiling\n- Proposal of algorithms for bias-assessment throughout pipelines\n\n(b) Development component\n\n- Implementation of the proposed algorithms\n- Development of a small benchmark to be used for evaluation",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0812",
    "title": "Bias-assessment in data preparation pipelines (Part II)",
    "summary": "The media have reported numerous examples of systems relying on machine learning (ML) that exhibit bias and discrimination against different groups of people, e.g., based on race or gender. One reason for this unwanted behavior lies in the underlying data used for ML. Therefore, research on fair machine learning has proposed metrics and algorithms to assess and improve the data to foster fair outcomes. These approaches typically focus on one step of an analytics pipeline (e.g., training, sampling, discretization), resulting in local improvements along the pipeline. There is a research gap concerning the global effect along a pipeline targeting fair ML. \n\nAs a first step towards fair ML pipelines, the overarching goal of this project is to investigate methods to identify possible causes of bias in a data preparation pipeline.  In this part of the project, research will focus on bias assessment based on query-based explanations that identify operations that may contribute to certain data or data characteristics being absent or present in operation outputs. \n\nSpecific details:\n\n\n(a) Research component\n\n- Literature review on bias in ML and its mitigation, and query-based explanations.\n-  Proposal of algorithms for bias-assessment throughout pipelines\n\n(b) Development component\n\n- Implementation of the proposed algorithms\n- Development of a small benchmark to be used for evaluation",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0813",
    "title": "Bias-assessment in data preparation pipelines (Part I)",
    "summary": "The media have reported numerous examples of systems relying on machine learning (ML) that exhibit bias and discrimination against different groups of people, e.g., based on race or gender. One reason for this unwanted behavior lies in the underlying data used for ML. Therefore, research on fair machine learning has proposed metrics and algorithms to assess and improve the data to foster fair outcomes. These approaches typically focus on one step of an analytics pipeline (e.g., training, sampling, discretization), resulting in local improvements along the pipeline. There is a research gap concerning the global effect along a pipeline targeting fair ML. \n\nAs a first step towards fair ML pipelines, the overarching goal of this project is to investigate methods to identify possible causes of bias in a data preparation pipeline. In this part of the project, research will focus on bias assessment based on data provenance traces captured during data preparation execution.\n\nSpecific details:\n\n\n(a) Research component\n\n- Literature review on bias in ML and its mitigation, and data provenance\n- Proposal of algorithms for bias-assessment throughout pipelines\n\n(b) Development component\n\n- Implementation of the proposed algorithms\n- Development of a small benchmark to be used for evaluation",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0814",
    "title": "A comparative analysis of SQL debugging techniques",
    "summary": "Many applications rely on structured queries (e.g., SQL) to query data, e.g., for data analysis, creating business reports, retrieving personal records, etc. Due to their declarative nature, developers cannot debug these queries using the traditional step-by-step debugging techniques commonly used for declarative programming (e.g., in Java). Recently, researchers have proposed alternative methods to tackle the problem of SQL debugging. \n\nThis project aims to perform a qualitative and quantitative comparison of different methods to better understand in what settings which methods may be suitable (or not). \n\nSpecific details:\n\n\n(a) Research component\n\n- Survey the state of the art in SQL query debugging. \n- Define comparison criteria and benchmark requirements.\n- Perform a qualitative and quantitative evaluation.\n\n(b) Development component\n-  Develop and implement the benchmark and run experiments.",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0815",
    "title": "Approximate data provenance - models and use cases",
    "summary": "For structured queries (e.g., SQL), data provenance research has resulted in multiple alternative models that can faithfully track tuples throughout processing. Such provenance tracing yields annotations to result tuples. These annotations encode which data were combined in what way. This information is valuable in various settings, e.g., for debugging structured queries or explainability of processed data. However, a significant obstacle in using provenance in practical settings is the computational overhead incurred for tracing and storing the provenance. \n\nThis project studies how approximate provenance that introduces uncertainty in the traced data provenance may balance the utility-overhead trade-off for selected use cases.\n\nSpecific details:\n\n\n(a) Research component\n\n- Survey the state of the art in approximate data provenance.\n-  Build on this existing work to extend or propose an alternative approximate data provenance model specifically targeting the utility-overhead trade-off. \n\n(b) Development component\n\n- Develop and implement algorithms to realize your proposal\n- Develop a use-case showing how your solution may be beneficial in a practical scenario",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0816",
    "title": "An app to maintain/improve the senior citizen's cognitive abilities",
    "summary": "This project aims to build an app to help the senior citizen to maintain/improve cognitive abilities through practicing mathematics questions following the observations of \"magic numbers\". \n\nSpecific details:\n(a) Design component\nThe interface of an app\n\n(b) Implementation component\nThe implementation of an app\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0817",
    "title": "Explainable AI Toolkit for Disease Modelling with Medical Images and Vision-Language Models",
    "summary": "This project aims to develop an explainable AI toolkit that supports disease modelling and medical insight generation using medical images, such as X-rays, MRIs, or CT scans, enhanced with the emerging capabilities of vision-language models (VLMs). Medical image analysis is a critical area of healthcare AI, enabling early detection and understanding of complex conditions such as neurological disorders, cardiovascular diseases, and cancers. However, many current AI models lack transparency, limiting their adoption in clinical settings where interpretability and accountability are essential.\n\nStudents will build a prototype system that uses deep learning methods to extract features from medical images and generates human-interpretable outputs. The project will also explore the integration of VLMs�AI systems that can jointly process images and medical text�to produce more contextual and multimodal explanations for model predictions. For example, the system could explain why a region in a brain scan may suggest signs of atrophy, supported by relevant clinical language. The final toolkit will be designed to support disease modelling tasks in a user-friendly interface, offering clinicians and researchers insights into both diagnostic outcomes and the rationale behind AI decisions. This project provides students with hands-on experience in computer vision, multimodal AI, and human-AI interaction in a high-impact healthcare setting.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0818",
    "title": "Exploring the use of LLM on automatic scoring of multimodal essays.",
    "summary": "This project aims to explore the use of LLM on automatic scoring of multimodal essays, which goes beyond traditional text-based writing by incorporating various modes of communication, like images, videos, audio, and interactive elements.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0819",
    "title": "Providing explanations for recommendations made in recommender systems",
    "summary": "This project aims to provide explanations to users for recommendations made in recommender system to gain a better performance on recommendations made.  \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearch for XAI approaches in recommender systems\n\n(b) Development component\nImplementations of XAI approaches in recommender systems",
    "supervisor": "Dr Liu Siyuan",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0820",
    "title": "Human-algorithm-AI collaboration for data fusion",
    "summary": "Data integration refers to the task of combining multiple heterogeneous data sets to obtain a unified, homogeneous, and comprehensive data set. Data integration usually comprises multiple sub-tasks supported by algorithms. Human-in-the-loop approaches have been proposed for each sub-task, where a human user and algorithms jointly solve a task. With generative AI becoming a commodity, researchers have explored approaches that leverage such models for data integration. Yet, these approaches typically replace the ``classical'' algorithm with the model. \n  \nThis FYP focuses on proposing novel solutions to the specific data integration task of data fusion that jointly leverages complementary capabilities of human users, algorithms, and generative models.  Data fusion combines multiple different representations of a real-world entity into a single, unified representation. \n\nSpecific details:\n\n\n(a) Research component\n\n- Investigate possible interactions between human users, algorithmic components, and generative models.\n- Propose algorithms leveraging these interactions for improved data fusion performance.\n\n\n(b) Development component\n - Develop software that implements the proposed algorithms\n- Test the software by developing, implementing, and running use case scenarios",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Database Systems",
      "Distributed Computing Systems",
      "Machine Learning",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0821",
    "title": "Gamified AI Companion for Cognitive Health Monitoring in Seniors",
    "summary": "This project explores the intersection of AI, gamification, and preventive healthcare by developing a digital companion for seniors to monitor and improve their cognitive health over time. With the rising prevalence of age-related conditions such as Alzheimer�s Disease and mild cognitive impairment, there is a growing need for engaging, accessible, and low-cost solutions that support long-term health monitoring outside clinical settings. This project aims to design an interactive platform that digitizes validated screening tools into playful, game-like experiences that encourage frequent use and improve adherence to health routines.\nStudents will build a web or mobile application that incorporates gamified tasks reflecting cognitive domains such as memory, attention, and executive function. These tasks will be powered by simple AI modules that adapt difficulty levels and provide personalized feedback based on users� longitudinal performance. The system will also collect behavioral data that can be analyzed to identify early signs of cognitive decline. The project includes interface design, backend development, data modeling, and user experience testing with sample users. By combining AI with gamification, this project contributes to the creation of scalable and motivating tools for aging-in-place communities.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Gamification",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0822",
    "title": "Irregular Time Series Prediction with Markov Models",
    "summary": "This project studies how to do machine learning predictions on irregular time series. We will explore different approaches and developed new algorithms. We will situate the study in a healthcare context. This will be a continuation of an existing FYP project.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nRead around Markov models.\n\n\n(b) Development component\nPython Implementation",
    "supervisor": "Ast/P Fan Xiuyi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Biomedical Systems",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0823",
    "title": "Multi-Agent Medical Chatbot for Trustworthy Clinical Decision Support",
    "summary": "This project aims to build a trustworthy AI-powered medical chatbot system that simulates a team of specialized healthcare agents collaborating to support clinical decision-making. While large language models (LLMs) have shown great promise in medical applications, there remain challenges in reliability, transparency, and domain specificity. This project adopts a modular approach by combining a general-purpose LLM with a set of focused agents�each responsible for specific medical domains such as geriatrics, cardiology, or mental health. These agents will interact to provide more holistic and accurate responses to complex medical queries.\n\nStudents will explore open-source LLMs (e.g., LLaMA, GPT, QWEN) and implement a multi-agent system that supports structured medical reasoning, proactive question-asking, and multi-turn dialogues. The chatbot will be augmented with knowledge retrieved from trustworthy medical databases (e.g., PubMed, UMLS) to ground its responses in credible sources. The system will be evaluated through simulated clinical scenarios and assessed for trustworthiness, clarity, and relevance. This project provides an opportunity to explore cutting-edge topics in medical AI, retrieval-augment generation (RAG), and explainability, while contributing to safer and more effective AI use in healthcare environments.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Smartphone Systems and Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0824",
    "title": "Explainable Diabetes Diagnosis from OCTA Images",
    "summary": "This project focuses on diagnosing diabetes through OCTA (Optical Coherence Tomography Angiography) images and providing clinical explanations for the diagnosis. The objective is to create an interpretable model that not only classifies whether a patient has diabetic retinopathy but also explains the diagnosis using key clinical features. This is crucial for building trust in AI models used in healthcare by providing insights into the decision-making process. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nRead a bit on medical imaging.\n\n(b) Development component\n\nImplementation of image segmentation and feature extraction methods to obtain clinical features from OCTA images (the public dataset OCTA500 has provided segmentation labels). Building two models, analyzing the models' performance, and ensuring that the interpretability aligns with clinical understanding.",
    "supervisor": "Ast/P Fan Xiuyi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Bioinformatics",
      "Machine Learning",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0825",
    "title": "From OCTA to FFA: Image Generation with Diffusion Techniques",
    "summary": "The project involves generating Fundus Fluorescein Angiography (FFA) images from Optical Coherence Tomography Angiography (OCTA) scans. OCTA images typically have a smaller field of view (FOV) compared to FFA. The challenge is to bridge this gap by using machine learning models to enhance the field of view and generate high-quality FFA images based on OCTA input. The primary model for this task will be a diffusion model, a recent advancement in generative modeling. Students will be responsible for designing, training, and testing the diffusion model to ensure the generated FFA images are clinically accurate.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nRead a bit on image generation\n\n(b) Development component\n\nExplore creative solutions for generating synthetic paired data or work with available datasets of OCTA or FFA images separately and apply techniques to align them for training purposes.",
    "supervisor": "Ast/P Fan Xiuyi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Medical Informatics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0826",
    "title": "Class-Specific Distributional and Aleatoric Uncertainty Estimates",
    "summary": "Reconstruction Uncertainty Estimate (RUE) is a distributional uncertainty measure that quantifies the degree of data shift between an instance and the training set. This project extends RUE with class-specific normalization and measures the deviation of class instances from the mean. The outcome will be two novel, retraining-free uncertainty estimates�distributional and aleatoric�to improve calibrated trust in AI.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nRead a bit on uncertainty estimation.\n\n(b) Development component\nBuild the above on various models on several datasets (Especially, the blood cell dataset which comprise of some highly clean classes and some not clean (aleatoric uncertainty)). Compare performance.",
    "supervisor": "Ast/P Fan Xiuyi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Medical Informatics"
    ]
  },
  {
    "projectNo": "CCDS25-0827",
    "title": "AI Supported Mobile Application for Mental Health",
    "summary": "This final year project focuses on creating a comprehensive AI-supported mobile application designed to address some of the most pressing mental health challenges, including privacy, accessibility, and personalized support. By integrating cutting-edge machine learning algorithms and natural language processing techniques, the app aims to deliver real-time assistance and monitoring to individuals experiencing stress, anxiety, and other common mental health concerns. Users can anonymously track their moods, receive automated feedback, and explore evidence-based coping strategies, ensuring that personal data remains secure and confidential. Additionally, the application�s intuitive interface makes it simple for people from diverse backgrounds to access relevant resources, regardless of their location or financial constraints. The project will involve rigorous testing and user feedback sessions to ensure the platform�s reliability and effectiveness. Ultimately, this solution aspires to bridge the gap between traditional mental health services and the growing number of individuals seeking flexible, on-demand support. By harnessing the power of AI, the application seeks to make mental healthcare more accessible, private, and user-friendly for everyone.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nUnity3D\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0828",
    "title": "AI Supported Virtual Agent for Mental Health",
    "summary": "This final year project focuses on developing an AI-supported virtual agent that addresses common mental health challenges by providing easily accessible, confidential, and cost-effective support. One of the primary reasons for leveraging virtual agents in mental healthcare is the increasing need for on-demand, user-friendly interventions. Traditional therapy sessions can be expensive, time-consuming, and hindered by location constraints, while a virtual agent can offer immediate, personalized guidance at any time. Additionally, the anonymity provided by digital platforms can help users feel more comfortable sharing personal concerns, making it easier to discuss sensitive topics without fear of judgment or stigma.\n\nBuilt on cutting-edge machine learning algorithms and natural language processing, the virtual agent will analyze user inputs in real time and provide tailored suggestions based on recognized patterns in stress, anxiety, or other mental health indicators. The agent�s chatbot interface will present users with targeted exercises, coping strategies, and, when necessary, referrals to professional help. By combining accessibility, privacy, and real-time responsiveness, this project aims to empower individuals to proactively manage their mental well-being and seek support whenever they need it.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nUnity3D\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Smartphone Systems and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0829",
    "title": "AI Augmented Game for Adult Learning",
    "summary": "This final year project focuses on developing an AI-augmented game designed to revolutionize adult learning through a blend of engaging gameplay mechanics and adaptive, data-driven instruction. By harnessing cutting-edge machine learning techniques, the system analyzes user performance, identifies knowledge gaps, and adjusts the game�s difficulty and content in real time to ensure each learner�s unique needs are met. Furthermore, gamification strategies�such as points, achievements, and progress tracking�are employed to motivate users and enhance overall learning retention.\n\nIncorporating these techniques fosters a more immersive, personalized experience for adult learners compared to traditional, passive methods. Additionally, embedded analytics offer valuable feedback to instructors and administrators, enabling them to assess learner progress at a granular level. By integrating AI-driven insights, this project demonstrates how adult education can be revitalized with greater flexibility, interactivity, and user satisfaction. Ultimately, the AI-augmented game aims to serve as a proof of concept, illustrating how emerging technologies can empower adults to learn new skills, broaden their knowledge base, and adapt to an ever-evolving world.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\nUnity3D\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Prof Miao Chun Yan",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Computer Animation/ Games",
      "Gamification",
      "Serious Games"
    ]
  },
  {
    "projectNo": "CCDS25-0830",
    "title": "Visual content generation via deep generative models",
    "summary": "This project aims to develop new method for visual content generation via deep generative models, in particular diffusion models. The visual content can be images, 3D objects, or videos. We will study and analyse the limitations of existing methods, and propose techniques to either enhance the capacity or improve the efficiency of generative models. For example, one possible direction is to train a 3D consistency model based on an existing 3D diffusion model such as LN3Diff. This will significantly increase the speed of 3D object generation. This project is flexible and other directions under this topic is also possible.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDevelop a new method for visual content generation via deep generative models. It should enhance the capacity or improve the efficiency of generative models.\n\n(b) Development component\n\nImplement the proposed method and evaluate its performance.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0831",
    "title": "DirectDrag3D: Drag-based Manipulation on Direct 3D Diffusion Model",
    "summary": "Drag-based editing techniques have become a popular way to interactively manipulate visual content, offering users intuitive control over shape, pose, and other attributes. However, existing methods are limited in scope: they either rely on image-based diffusion priors or operate on category-specific 3D diffusion models that lack the flexibility and generality required for precise and generative 3D object editing. This project, DirectDrag3D, aims to overcome these limitations by introducing a drag-based manipulation framework specifically designed for a high-capacity, direct 3D diffusion model (e.g. LN3Diff or 3DShape2VecSet). Inspired by the success of DragGAN in 2D editing, DirectDrag3D will extend these concepts to 3D space, enabling precise control over user-specified points on 3D objects, without sacrificing the quality or realism of the output. The goal is to create an intuitive, user-driven tool that allows for real-time manipulation of complex 3D objects, improving both the editing experience and the diversity of modifications.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nThe drag-based manipulation algorithm will focus on two core elements: motion supervision and 3D point tracking. We will design a method for motion supervision that leverages the latent features of the 3D diffusion model, ensuring that user-directed deformations are accurately applied to the object while maintaining natural and realistic characteristics. To extend the 2D point tracking in DragGAN, we will develop a 3D point correspondence mechanism, allowing for precise manipulation of specific points in 3D space. \n\n(b) Development component\n\nTo achieve our goal, we will first reproduce the DragGAN method alongside a 3D diffusion model, either LN3Diff or 3DShape2VecSet, which are well-established approaches in 3D diffusion. Once these are in place, we will implement the 3D point-dragging algorithm within the diffusion model, integrating motion supervision and point tracking.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Computer Graphics"
    ]
  },
  {
    "projectNo": "CCDS25-0832",
    "title": "Latent Schr�dinger Bridge for fast Image-to-Image learning",
    "summary": "Diffusion models have shown remarkable ability in unconditional image synthesis by transforming noise into detailed images. Building on this idea, Image-to-Image Schr�dinger Bridge (I2SB) has been proposed to directly learn a diffusion process that converts one image distribution into another. While I2SB is a flexible and powerful framework capable of handling a wide range of image-to-image tasks, it operates in pixel space, which requires significant computational resources and time for training. \nTo overcome this limitation, we will propose Latent I2SB, which leverages the success of latent diffusion models (LDMs). LDMs accelerate image synthesis tasks by processing the images in a low-dimensional latent space, making training more efficient. By adapting I2SB to the latent space, Latent I2SB aims to combine the versatility of I2SB with the speed and resource efficiency of LDMs. The approach will enable rapid learning of image-to-image tasks while maintaining high-quality outputs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Develop a novel class of conditional image synthesis framework.\n2) Investigate an efficient denoising neural network architecture for latent I2SB.\n\n(b) Development component\n\n1) Implement and train latent I2SB on various image-to-image tasks, such as super-resolution and deblurring.\n2) Develop a user-friendly GUI for users to input images and view the model outputs",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0833",
    "title": "Rule-Based and NLP-Enhanced Question Generation for Online Doctor Consultations",
    "summary": "This project focuses on developing a system to automatically generate helpful follow-up questions during online doctor consultations, aiming to assist doctors in gathering important patient information. Instead of relying solely on complex deep learning models, this project will use a rule-based approach combined with basic Natural Language Processing (NLP) techniques to extract key symptoms or conditions from patient inputs and suggest relevant questions. The student will work with a provided dataset of doctor-patient text conversations and perform data cleaning, simple text analysis, and keyword extraction. \n\nSpecific details:\n(a) Design component\nDesign the system interfaces\n\n(b) Implementation component\n\n(a) Research component\nBy identifying common medical symptoms and contexts, the student will design templates and rules to generate questions based on conversation content. Optionally, basic pre-trained NLP models like BERT can be used for named entity recognition (NER) or keyword matching.\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0834",
    "title": "Assessing the Accuracy of AI Chatbots in Explaining Common Medical Terms",
    "summary": "This project investigates how well AI-powered chatbots, such as ChatGPT or other open-source Large Language Models (LLMs), can explain common medical terms to patients in simple and understandable language. The goal is to evaluate the usefulness and accuracy of these models in supporting patient education, especially for people with no medical background. Using a provided dataset of real-world doctor-patient consultations, the student will identify a list of frequently mentioned medical terms and compare how these are explained by the LLMs versus how doctors explain them. This project focuses on basic NLP interactions, prompt engineering, and evaluation, avoiding complex model training or deployment. The student will gain hands-on experience in working with LLMs, analyzing real medical data, and applying basic research methods in AI evaluation.\n\nSpecific details:\n(a) Design component\nDesign prompts for LLMs in medication\n\n(b) Implementation component\n\n(a) Research component\nEvaluation of LLMs in medication\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Human Computer Interaction"
    ]
  },
  {
    "projectNo": "CCDS25-0835",
    "title": "Dialogue-Based Recommendation System: Extracting Preferences from Customer Conversations",
    "summary": "This project aims to build a recommendation system that can understand what users like or need based on their conversations. Instead of asking users to rate products or fill out forms, the system will analyze chat-style dialogues to find clues about their preferences. For example, if a user says, \"I'm looking for a lightweight laptop for travel,\" the system should be able to understand the user's interest and suggest suitable products. The student will clean and analyze a dataset of customer conversations, use Natural Language Processing (NLP) techniques to find keywords, product mentions, and user preferences, and then use this information to recommend relevant items. Pre-trained language models like BERT can be used to help the system understand context and meaning. The student will also build a simple method to rank and display recommendations based on how well they match what the user is looking for. By the end of the project, the goal is to have a working prototype that shows how conversations can be used to make smarter and more personalized product suggestions.\n\nSpecific details:\n(a) Design component\nPrototype of the recommendation system\n\n(b) Implementation component\n\n(a) Research component\nRecommendation modeling and evaluation\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0836",
    "title": "Comparative evaluation of data preparation assistants",
    "summary": "In data science problems, data preparation is frequently a time consuming and error prone task. For this reason, different assistants have been proposed to simplify the definition of data preparation steps to be applied, for instance through recommendations of the next step, suggestion of sequences of steps, etc. \n\nThe goal of this project is to review existing approaches and to design a benchmark suited for comparative evaluation. State-of-the-art approaches are then installed or re-implemented for a comparative evaluation with respect to the defined benchmark.  \n\nSpecific details:\n(a) Design component\n\nBenchmark design\n\n(b) Implementation component\n\nImplementation and evaluation of approaches.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Melanie Herschel Weis",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0837",
    "title": "Adversarial Attacks for Regression Tasks",
    "summary": "Regression is a fundamental yet often underexplored machine learning problem that focuses on predicting continuous target values from input data. While adversarial attacks on classification models (e.g., distinguishing cats from dogs) have been extensively studied, the vulnerability of regression models to such attacks remains under-researched. However, regression tasks play a critical role in safety-sensitive applications, including predictive maintenance, autonomous vehicle control, and financial forecasting.\n\nThis project aims to analyze, implement, and benchmark state-of-the-art adversarial attacks and defense mechanisms designed for regression models. We aim to develop a comprehensive toolkit for evaluating adversarial robustness. The proposed framework should be generic and extensible, allowing researchers and practitioners to systematically study adversarial vulnerabilities and mitigation strategies for regression tasks.\n\nSpecific details:\n- Literature survey on adversarial attack for regression tasks, evaluating their trade-offs and limitations\n- Implement and benchmark at least two distinct adversarial attack techniques for regression models\n- Develop a modular toolkit supporting at least two distinct attack methods\n- Optimize the attack and defense strategies based on empirical performance metrics.\n\nSkills required\n\nProgramming: Python / C++ coding\nMachine learning foundations: notions of regression models &amp; tasks\nSoftware engineering: design easy-to-use interfaces with modular and reusable code\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Arvind Easwaran",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0838",
    "title": "Programmatic Autoencoders in Reinforcement Learning​",
    "summary": "Learning meaningful feature representations is essential for efficiently processing high-dimensional inputs, such as images, particularly in reinforcement learning (RL) settings. While traditional autoencoders extract representations tailored to specific objectives, these representations often lack explicit semantic interpretability, limiting their generalization capabilities across diverse contexts. To address this limitation, we propose replacing the standard neural decoder with a programmatic decoder that leverages structured outputs from the encoder to perform tasks that help align the learned representations with concrete concepts. This approach enforces the encoder to produce semantically meaningful representations that are compatible with programmatic decoding, ensuring greater interpretability. Building on prior work [1], we plan to investigate differentiable programmatic decoder, enabling gradient-based optimization and improving sample efficiency. Furthermore, we plan to explore the integration of programmatic autoencoders within RL frameworks to enhance representation learning, ultimately improving policy generalization across diverse environments.\n\n[1] Alaia et al., \"Data-Efficient Learning with Neural Programs,\" NeurIPS 2024.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\nTasks: \nUtilize the GitHub repository of [1] to execute benchmark experiments.​\nDevelop differentiable approximations of the programmatic decoder to facilitate gradient-based training.​\nIntegrate the developed model in RL and verify sample efficiency and generalizability.\n\nSkills Required: \nProficiency in PyTorch.​\nFamiliarity with autoencoders, including variational autoencoders.​\nComprehensive understanding of RL and policy gradient algorithms, such as REINFORCE.​\nSolid foundation in deep learning, machine learning, and convolutional neural networks (CNNs).",
    "supervisor": "A/P Arvind Easwaran",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Real-Time / Embedded Systems",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0839",
    "title": "Accelerating Diffusion Models with Sparse Consistency Model",
    "summary": "Diffusion models have demonstrated exceptional image generation capabilities, but their widespread adoption is limited by significant computational demands and prolonged inference times. There are two prominent strategies to address these limitations: 1) employing consistency models to reduce inference steps; 2) using sparse attention to reduce the computation cost of the attention operation. However, these techniques have not yet been effectively combined within a single cohesive model. This project aims to integrate a sparse attention mechanism into a pre-trained latent consistency diffusion model, thereby accelerating inference while maintaining high-quality generation outputs. To explore the trade-off between computational efficiency and output quality, we will systematically evaluate how varying sparse attention parameters impact the generation results. Additionally, we will develop an intuitive graphical user interface (GUI) enabling users to generate images from textual prompts and dynamically adjust sparse attention settings to optimize their preferred balance between quality and inference speed.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Implement an established sparse attention technique in a pre-trained latent consistency diffusion model.\n2. Investigate the influence of different sparse attention configurations on the quality of generated images through comprehensive experiments.\n\n(b) Development component\n\n1. Developing a GUI for users to generate images from text prompts  using the sparse consistency model\n2. Enable real-time adjustment of sparse attention parameters within the GUI to allow users to balance between generation quality and inference time.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0840",
    "title": "FreeMoving: Training-Free Method for Object Moving in Images",
    "summary": "Previous object movement tasks mostly relied on model fine-tuning or optimization-based approaches. The latest MMDiT text-to-image model, represented by FLUX, has demonstrated strong image synthesis quality and high-resolution generation capabilities. FLUX explicitly applies Rotary Position Encoding (RoPE) to the query and key of each self-attention layer, effectively providing both absolute and relative positional information. Therefore, exploring how to leverage this design, combined with the powerful priors of MMDiT, to achieve training-free object movement presents an interesting research direction.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n(1) Basic Goal: Design an effective attention-sharing mechanism to achieve object movement in synthesized images.  \n\n(2) Advanced Goal: Enable object movement in real images, potentially leveraging fine-tuning or efficient inversion algorithms.\n\n(b) Development component\n\n(1) Design a user interface that allows users to select an object and specify a movement direction vector, then outputs the corresponding result.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Image Analysis &amp; Processing",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0841",
    "title": "Inference-Time Scaling for Complex Semantics in Text-to-Image Diffusion",
    "summary": "Recent text-to-image (T2I) diffusion models demonstrate remarkable generative capabilities but still struggle with prompts involving rare or highly complex compositions (e.g., objects featuring unconventional attributes or scenes with intricate details). Meanwhile, studies in large language models (LLMs) have highlighted the potential of inference-time scaling - devoting additional compute at inference to refine outputs - beyond the conventional approach of increasing dataset size and model capacity during training.\nThis project aims at exploring inference-time scaling in diffusion-based T2I systems by employing a strong visual-language verifier to provide semantic feedback, guiding the model toward more faithful and detailed outputs. By adaptively allocating more compute during inference, the goal is to enhance the model�s ability to generate images that accurately capture novel, rare, or compositionally complex concepts.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Introduce a mechanism to iteratively refine intermediate latents, guided by a semantic verifier that provides feedback on the relevance of each candidate to the target prompt.\n2. Employ a vision-language component to provide feedback on whether generated images capture the desired rare or complex semantics.\n3. Establish a set of challenging prompts (rare attributes, composite scenes) and metrics to measure improvements compared to baseline diffusion sampling.\n\n(b) Development component\n\n1. Incorporate the search-driven inference pipeline into an existing T2I diffusion model, allowing for adjustable compute budgets and feedback loops during inference.\n2. Develop a basic interface to enable users to input complex prompts, control inference-time parameters (e.g., search depth, verifier thresholds), and visualize outputs.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0842",
    "title": "LLM-Assisted Video Summarization",
    "summary": "This project explores the integration of Large Language Models (LLMs) into the process of video summarization. While traditional video summarization methods primarily rely on visual cues or supervised learning, they often struggle to capture the deeper semantic meaning or narrative flow of a video. By leveraging the powerful reasoning and language understanding capabilities of LLMs, this project aims to generate concise, coherent, and human-like video summaries that better reflect the core content and intent of the original material.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\ni) Extract segments from video content, and use visual understanding models and other necessary tools (e.g., human face recognition, etc.) to acquire enough information from the video segments.\nii) Feed this information into an LLM to guide the selection of important video clips, which are subsequently assembled into a coherent, story-driven summary video along with a corresponding textual summary (can be converted into a voice track and played together with the video).\n\n(b) Development component\n\nDevelop a Web User Interface for users to input videos and texts, and view the generated video summarization results.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0843",
    "title": "Mesh Split: Mesh Segmentation in Complete Shapes",
    "summary": "With recent advancements in 3D segmentation methods, effective mesh segmentation techniques, such as Point-SAM and SAMPart3D, have been introduced. While recent studies have demonstrated editing capabilities using segmentation results, these approaches rely on well-segmented meshes. However, most meshes have empty interiors, meaning that directly splitting segmented regions often leads to missing faces at the overlapped part and ambiguous boundaries. To address this, an additional reconstruction process is required for accurate segmentation and separation. In this project, our goal is to segment 3D meshes in a way that allows each divided region to exist as a complete mesh. By doing so, users can effectively utilize each separated 3D mesh component for editing while ensuring a clear separation of segmented regions.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1) Explore on PartNet and PartObjaverse-Tiny dataset that could be used for segmented mesh generation. 2) Evaluate the segmentation networks (Point-SAM or SAMPart3D) to ensure accurate segmentation on the mesh. 3) Investigate existing methods for separate mesh generation (e.g., PartGen, ComboVerse) to refer to the pipeline 4) Investigate image inpainting works that could be leveraged in generation process.\n\n(b) Development component\n\n1) Implement the Point-SAM or SAMPart3D to perform segmentation for any part. 2) Building a dataset for training the network to complete segmented meshes 3) Train mesh generation network that could generate boundary part by using segmentation information. 4) Utilize rendering and image inpainting network to improve the performance of generation.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Image Analysis &amp; Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0844",
    "title": "Seamless Video Content Transfer via Hybrid Style and Morphing Techniques",
    "summary": "Video content transfer has been widely studied, focusing on transforming a video from one style (or content) to another. Meanwhile, image morphing techniques, such as DiffMorpher, enable smooth transitions between two images by gradually blending their structures and textures. This project aims to combine these two approaches to achieve a seamless video content transfer, where transformations happen smoothly over time, rather than abruptly switching from one style or content to another.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nDevelop an effective hybrid content transfer pipeline, where a video gradually transitions from one style/content to another in a temporally smooth manner.\n\n(b) Development component\n\n1. Content Transfer Module\nUtilize existing video style transfer models or editing models to apply content changes frame by frame.\nEnsure temporal consistency by leveraging optical flow-based warping.\n\n2. Morphing Module\nApply image morphing techniques (e.g., DiffMorpher) to interpolate gradual transitions between different content states.\n\n3. Integration &amp; Post-processing\nDynamically blend content transfer outputs with morphing results for a natural transition effect.\nUse motion compensation to prevent flickering or frame inconsistencies.\nDevelop a user interface for selecting transfer styles and defining transition points.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0845",
    "title": "SYNC3R : Generalizing 4D Reconstructions To In-The-Wild Unsynchronized Videos",
    "summary": "Recent years have seen rapid growth in 3D and 4D reconstruction research, based on the two explicit representations : 3D Gaussian Splatting and Neural Radiance Fields. Moreover, ever since the introduction of COLMAP, there have been multiple numerical and deep-learning solutions on estimating camera poses with Structure-from-Motion (SfM), most notable being the recent transformer-based architecture called Dust3r. Accurate camera extrinsics/intrinsics are a necessary step before doing high-quality 3D and 4D reconstruction of the scenes. However, one area of 4D reconstruction remains unexplored, which is aligning of unsynchronized videos from various cameras sources per timestep. The existing techniques require working with event-based signals or having the expensive hardware with strict camera specifications in special lab-like environments. With the introduction of Sync-NeRF and their time embeddings, we got one step closer to affordable 4D reconstruction on the unsynchronized videos.  Additionally, Dust3r's output includes per-camera point clouds accompanied by per-pixel confidence scores for synchronized camera view matching. This opens a promising avenue for exploring how Dust3r's confidence scores could be used for turning unsynchronized camera videos to the synchronized ones. This project is difficult and thus can only be finished by students with high academic ability.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nWe will research whether and how confidence scores from Dust3r and VGGT can be used to estimate frame timestep overlap between the different unsynchronized videos. \nWe will use currently existing panoptic datasets in lab-like and in-the-wild environments to see how good these confidence scores work over multiple environments and across how many timesteps. Research should include intentionally making time offsets in videos and seeing how well do Dust3r/VGGT confidence scores predict timestep overlaps between the camera views and what are the final 4DGS reconstructions.\n\n(b) Development component\n\nWe should develop a metric for timestep overlapping per-frame and per-view.\nWe should develop a way to upscale confidence scores for the direct dynamic point cloud predictions on unsynchronized videos.\nBackbone for 4D reconstruction will be some of the currently existing 4DGS methods.",
    "supervisor": "Ast/P Pan Xingang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Machine Learning",
      "Artificial Intelligence",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0846",
    "title": "Creating Agents using Large Language Models",
    "summary": "Large Language Models (LLMs) have demonstrated impressive reasoning and problem-solving capabilities, making them promising tools for creating intelligent agents. This project explores the use of LLMs to develop goal-oriented agents by leveraging agent models to structure decision-making processes. This approach involves decomposing complex objectives into manageable sub-goals that can be achieved by the agent. Additionally, this project explores the use of LLMs for automated code generation to enable agents to execute actions dynamically in pursuit of their goals. By integrating these approaches, this project aims to enhance the adaptability and efficiency of LLM-powered agents in real-world applications.\n\nSpecific details:\n(a) Design component\nDesign prompts for LLMs to generate agent code and actions\n\n(b) Implementation component\n\n(a) Research component\nAgent modeling with LLMs\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Knowledge Representation/ Ontology",
      "Programming Languages &amp; Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0847",
    "title": "Neurosymbolic AI for User Profiling",
    "summary": "This FYP is about applying neurosymbolic AI for user profiling on a topic of your choice. In particular, you will be using Sentic APIs, a suite of application programming interfaces that perform various sentiment analysis tasks in different languages. All the APIs are based on the sentic computing framework and, hence, leverage an ensemble of symbolic AI (SenticNet) and subsymbolic AI (deep learning). One of the goals of this FYP is also to test functionality, reliability, and performance of Sentic APIs. For more info, please visit https://sentic.net/api or contact Dr Rui Mao (rui.mao@ntu.edu.sg).\n\nSpecific details:\nThe successful completion of this FYP consists of the following steps:\n1. choose a popular topic, e.g., cryptocurrencies, metaverse, or climate change\n2. crawl and label data about such topic from X or Reddit in English or any other language\n3. process the collected data using the APIs\n4. report any encountered issues, e.g., mislabeled tweets\n5. deduce possible reasons of such issues, e.g, missing concept in SenticNet\n6. come up with possible solutions for the encountered issues\n7. visualize and discuss results in your FYP report",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0848",
    "title": "Neurosymbolic AI for Stress and Depression Detection",
    "summary": "This FYP is about applying neurosymbolic AI for stress and depression detection on a topic of your choice. In particular, you will be using Sentic APIs, a suite of application programming interfaces that perform various sentiment analysis tasks in different languages. All the APIs are based on the sentic computing framework and, hence, leverage an ensemble of symbolic AI (SenticNet) and subsymbolic AI (deep learning). One of the goals of this FYP is also to test functionality, reliability, and performance of Sentic APIs. For more info, please visit https://sentic.net/api or contact Dr Rui Mao (rui.mao@ntu.edu.sg).\n\nSpecific details:\nThe successful completion of this FYP consists of the following steps:\n1. choose a popular topic, e.g., cryptocurrencies, metaverse, or climate change\n2. crawl and label data about such topic from X or Reddit in English or any other language\n3. process the collected data using the API\n4. report any encountered issues, e.g., mislabeled tweets\n5. deduce possible reasons of such issues, e.g, missing concept in SenticNet\n6. come up with possible solutions for the encountered issues\n7. visualize and discuss results in your FYP report",
    "supervisor": "Prof Erik Cambria",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0849",
    "title": "Investigating the Use of Large Language Models for Time Series Applications",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing, but their potential applications extend beyond text-based tasks. This study explores the use of LLMs for time series applications, investigating their effectiveness in tasks such as forecasting, anomaly detection, and pattern recognition. Different model architectures and methods will be compared, such as prompt engineering versus fine-tuning, to assess their ability to capture temporal dependencies and generate accurate predictions. Additionally, comparisons between LLM-based approaches with traditional time series models to highlight their strengths and limitations. This project aims to determine the feasibility of leveraging LLMs for time series analysis and their potential impact on real-world applications.\n\nSpecific details:\n(a) Design component\nDesign the applications for time series problems and the testing environment\n\n(b) Implementation component\n\n(a) Research component\nCompare different models and methods of LLMs in time series applications\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0850",
    "title": "Exploring Deep Reinforcement Learning for Autonomous Driving",
    "summary": "Deep reinforcement learning (DRL) has emerged as a promising approach for autonomous driving, allowing vehicles to learn complex driving behaviors through interaction with their environment. This project investigates the application of DRL in autonomous driving by evaluating various training environments and reinforcement learning algorithms. Different simulation environments will be compared to assess their impact on learning efficiency and real-world applicability. The study will explore DRL algorithms such as Deep Q-Networks (DQN), Proximal Policy Optimization (PPO), and Soft Actor-Critic (SAC), analyzing their performance based on metrics such as safety, adaptability, and generalization.\n\nSpecific details:\n(a) Design component\nDesign experiment environment\n\n(b) Implementation component\n\n(a) Research component\nComparison amongst different simulation environments for DRL algorithms and their impact on learning efficiency and real-world applicability.\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0851",
    "title": "Enhancing Large Language Models with Database and Logic Programming for Repository-Level Code Understanding",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in code understanding and generation. However, they face limitations when dealing with large codebases due to context window constraints and the challenge of maintaining consistent reasoning across multiple files. This research explores a novel approach to enhance LLMs' repository-level code comprehension by leveraging the capabilities of logical programming and database systems.\nThe project investigates the synergy between LLMs and Datalog, a declarative logic programming language widely used in program analysis. The core idea is to leverage LLMs' natural language understanding while utilizing Datalog's efficient querying and logical inference capabilities. This combination aims to enable more precise and scalable code analysis than either approach alone.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\nExplore innovative methods to integrate LLMs with Datalog engines for better logical inference capabilities.\n\n(b) Development component\n\nCollect data and conduct experiments to evaluate the proposed methods.",
    "supervisor": "A/P Li Yi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Software and Applications",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0852",
    "title": "Disease Modelling with Medical Images",
    "summary": "Medical image analysis is a critical area of healthcare AI, enabling early detection and understanding of complex conditions such as neurological disorders, cardiovascular diseases, and cancers. However, many current AI models lack transparency, limiting their adoption in clinical settings where interpretability and accountability are essential. The project will explore the integration of VLMs�AI systems that can jointly process images and medical text�to produce more contextual and multimodal explanations for model predictions. \n\nSpecific details:\n(a) Design component\nDesign the experiment environment and prototype system\n\n(b) Implementation component\n\n(a) Research component\nPrediction based on medical images and texts with VLMs\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0853",
    "title": "AI Companion for Cognitive Health Monitoring",
    "summary": "Students will build a web or mobile application that incorporates gamified tasks reflecting cognitive domains such as memory, attention, and executive function. These tasks will be powered by simple AI modules that adapt difficulty levels and provide personalized feedback based on users� longitudinal performance. The system will also collect behavioral data that can be analyzed to identify early signs of cognitive decline. \n\nSpecific details:\n(a) Design component\nInterface design and companion design\n\n(b) Implementation component\n\n(a) Research component\nData collection, data analytics and early detection\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Gamification"
    ]
  },
  {
    "projectNo": "CCDS25-0854",
    "title": "Medical Chatbot",
    "summary": "This project aims to build an AI-powered medical chatbot system to provide clinical suggestions. While large language models (LLMs) have shown great promise in medical applications, there remain challenges in reliability, transparency, and domain specificity. This project combines a general-purpose LLM with a specially focused agent which is responsible for a specific medical domain. This chatbot will interact to provide more holistic and accurate responses to complex medical queries.\n\nSpecific details:\n(a) Design component\nDesign the chatbot and deploy it on a robot\n\n(b) Implementation component\n\n(a) Research component\nQ&amp;A chatbot in medical domain\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Human Computer Interaction",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0855",
    "title": "A game design with AI",
    "summary": "This Project aims to develop the AI component of a newly designed Game. An AI model is chosen as the core algorithm to develop a powerful AI that critically challenges the player. the student needs to design and implement such a algorithm, and its any variations adopted to be integrated into a game. \n\nSpecific details:\n(a) Design component\nA game with AI component\n\n(b) Implementation component\nGame and AI algorithms\n\n(a) Research component\nAI or LLMs in games\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Serious Games",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0856",
    "title": "Chatbot for Education",
    "summary": "The project aims to develop a chatbot with LLMs as a learning companion of a student. The chatbot should be able to receive questions from students and provide answers in chatting style. The Q&amp;A should support multimodal data input and output.\n\nSpecific details:\n(a) Design component\nChatbot design\n\n(b) Implementation component\nChatbot development\n\n(a) Research component\nAnswer generation and multimodal modeling\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Software and Applications",
      "Natural Language Processing/ Text Mining",
      "Video/Audio/Speech Processing"
    ]
  },
  {
    "projectNo": "CCDS25-0857",
    "title": "A teaching companion",
    "summary": "This project aims to design and develop a companion of a teacher. The companion should be able to analyze reports and provide suggestions for generating feedback. \n\nSpecific details:\n(a) Design component\nDesign the companion\n\n(b) Implementation component\nDevelop the companion\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Natural Language Processing/ Text Mining",
      "Data Analytics",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0858",
    "title": "Course assistant design and development",
    "summary": "The project aims to design and develop a tool for course assistant creation. The tool should be able to extract information from the existing course lecture notes and generate the assistant for course teaching.\n\nSpecific details:\n(a) Design component\nAssistant design, data analysis\n\n(b) Implementation component\nDevelop the tool with LLMs\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Shen Zhiqi",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Programming Languages &amp; Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0859",
    "title": "Real-Time Sleep Staging with Smart Phone Actigraphy",
    "summary": "This project aims to develop: 1. An interface between smartphones and human physiological signals, e.g., movement data through smartphone actigraphy, and 2. Downstream applications such as a real-time sleep staging algorithm. The project addresses the need for accessible sleep monitoring by leveraging devices people already own, starting with smartphones. Phone-collected data will be used in combination with various signal-processing algorithms and/or machine learning methods to identify sleep stages in real-time. The research also explores sleep staging using this smart device interface, aiming to improve sleep quality and enhance cognitive health. The system will be validated against existing state-of-the-art methods to establish accuracy benchmarks. Additionally, the project will explore the potential for collecting data using other smart devices such as smartwatches, as well as other downstream applications like open-loop slow wave stimulation.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nCompare smartphone sensor data with state-of-the-art phone-based actigraphy methods, develop machine learning algorithms optimized for smartphone sensor inputs, and benchmark sleep staging algorithms against state-of-the-art (SOTA) methods.\n\n(b) Development component\nSmartphone interface, real-time sleep staging algorithm, signal processing pipeline.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Web-based Applications",
      "Real-Time / Embedded Systems",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0860",
    "title": "Dream Reality: Interfacing with Dreamers during Rapid Eye Movement Sleep Stage",
    "summary": "To develop an application that provides feedback during Rapid Eye Movement (REM) stage during sleep. The machine learning (ML) model will detect the user�s sleep stage in real-time and the model could be developed to have high specificity in detecting REM stage. In general, the application runs while the user is asleep and provides real-time feedback depending on which stage the user is at. When the user is at the REM stage, the application will provide auditory cues to track the user�s responses and behaviours. Brain signals are picked up by the application, using an electroencephalogram (EEG) device, to determine if the response is relevant to the cue. For example, the application sends a melody to the user, and if the brain activity responds to the music, the application considers that the user can hear the music even when asleep. The application continues to conduct the turn-taking session to reach a stage where the user can provide a stronger response such as answering a complex question via a yes or no. This can also be verified by asking follow-up questions during wake states and tracking the coherence of the responses.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nReal-time question-and-answering (QnA) session during REM sleep stage. The goal of this project is to ensure that this model, can accurately predict the current sleeping stage of the user. It should send cues or instructions only when the user is in the REM stage.\n\n(b) Development component\nA website/mobile application that incorporates the insights of the research component to carry out the prediction and detection of the REM stage as well as a QnA session during REM sleep stage. The application must be able to detect, track, analyse, and determine the user�s brain activities well in response to the corresponding instructions.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Real-Time / Embedded Systems",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0861",
    "title": "Adaptive Task Mapping for Network-on-Chip",
    "summary": "In modern many-core systems, efficient task-to-core mapping is essential for maximizing performance. However, task graphs often lack explicit annotations of dependencies or weights, making it difficult to determine whether computation or communication impacts performance more. This project explores a task mapping method for a given task graph that analyzes the impact of computation versus communication based on Network-on-Chip (NoC) behavior and extracted system statistics. The goal is to automatically classify whether an application is computation-dominated or communication-dominated, and then apply an appropriate mapping strategy: computation-aware task mapping or communication-aware task mapping for the latter to make the system dynamically adapts the mapping approach to maximize efficiency. Reference: Hui Chen, Zihao Zhang, Peng Chen, Xiangzhong Luo, Shiqing Li, and Weichen Liu. 2021. MARCO: A High-performance Task Mapping and Routing Co-optimization Framework for Point-to-Point NoC-based Heterogeneous Computing Systems. ACM Trans. Embed. Comput. Syst. 20, 5s, Article 54 (October 2021), 21 pages.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. NoC feature extraction from simulated execution (e.g., latency, cycles, hop count)\n2. Task mapping impact classification: computation vs. communication dominance\n3. Design of adaptive strategy selection for task mapping\n4. Baseline selection and comparative evaluation methodology\n\n(b) Development component\n\n1. Task graph generation\n2. Extraction of NoC-level metrics (latency, hops) \n3. Development of impact-aware task mapping logic\n4. Performance evaluation and result visualization",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Computer Architecture",
      "System on-Chip"
    ]
  },
  {
    "projectNo": "CCDS25-0862",
    "title": "Energy-Efficient Task Mapping for Dynamic NoC-based MPSoCs",
    "summary": "With the increasing complexity of NoC-based MPSoCs, efficient task mapping is crucial for minimizing energy and communication costs. A major challenge lies in handling dynamic workloads, where task arrival times and core availability are unpredictable. This project proposes an energy-aware mapping approach that combines design-time optimization with runtime remapping to adapt to resource changes. By reducing unnecessary communication and balancing energy across cores, the strategy aims to improve system efficiency and scalability for next-generation embedded and multicore platforms.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Hybrid static-dynamic mapping framework design\n2. Energy-aware objective formulation for mapping\n3. Runtime resource monitoring and adaptation\n4. Exploration of mapping-energy-latency trade-offs\n5. Comparative evaluation with baseline mapping models\n\n(b) Development component\n\n1. MPSoC NoC architecture simulation using gem5 or a similar platform\n2. Mapping scenario generation and workload deployment\n3. Integration of dynamic runtime remapping logic\n4. Evaluation and tuning of mapping engine",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Low-power Computing",
      "Computer Architecture",
      "System on-Chip"
    ]
  },
  {
    "projectNo": "CCDS25-0863",
    "title": "Rethinking Buffer Usage in NoC: Toward Coherence-Efficient Routing (1)",
    "summary": "In Networks-on-Chip (NoCs), buffers exist in both routers and cache coherence protocols, influencing congestion and coherence delays. However, their combined impact on system performance is often overlooked. This project investigates how buffer behavior affects coherence and communication efficiency. We aim to design a buffer-aware routing strategy that dynamically adapts to buffer occupancy and coherence traffic, improving latency and throughput in many-core systems. If successful, this approach could enhance NoC scalability and energy-efficiency under heavy traffic and coherence load. \nReference: Zixuan Liu and Yaoyao Ye. 2025. A Buffer Reservation Scheduling Strategy for Enhancing Performance of NoC Router Bypassing. In Proceedings of the 30th Asia and South Pacific Design Automation Conference (ASPDAC '25). Association for Computing Machinery, New York, NY, USA, 575�580.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Buffer-coherence interaction modeling\n2. Analysis of buffer pressure on performance\n3. Design of buffer reservation and routing coordination\n4. Comparative evaluation against existing flow control schemes\n\n(b) Development component\n\n1. Integration of buffer-aware routing in full system simulation\n2. Extension of gem5 with buffer reservation support\n3. Synthetic and real workload deployment\n4. Full-system performance measurement and visualization",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "System on-Chip",
      "Computer Architecture"
    ]
  },
  {
    "projectNo": "CCDS25-0864",
    "title": "Rethinking Buffer Usage in NoC: Toward Coherence-Efficient Routing (2)",
    "summary": "In Networks-on-Chip (NoCs), buffers exist in both routers and cache coherence protocols, influencing congestion and coherence delays. However, their combined impact on system performance is often overlooked. This project investigates how buffer behavior affects coherence and communication efficiency. We aim to design a buffer-aware routing strategy that dynamically adapts to buffer occupancy and coherence traffic, improving latency and throughput in many-core systems. If successful, this approach could enhance NoC scalability and energy-efficiency under heavy traffic and coherence load. \nReference: Zixuan Liu and Yaoyao Ye. 2025. A Buffer Reservation Scheduling Strategy for Enhancing Performance of NoC Router Bypassing. In Proceedings of the 30th Asia and South Pacific Design Automation Conference (ASPDAC '25). Association for Computing Machinery, New York, NY, USA, 575�580.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Buffer-coherence interaction modeling\n2. Analysis of buffer pressure on performance\n3. Design of buffer reservation and routing coordination\n4. Comparative evaluation against existing flow control schemes\n\n(b) Development component\n\n1. Integration of buffer-aware routing in full system simulation\n2. Extension of gem5 with buffer reservation support\n3. Synthetic and real workload deployment\n4. Full-system performance measurement and visualization",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "System on-Chip",
      "Computer Architecture"
    ]
  },
  {
    "projectNo": "CCDS25-0865",
    "title": "Efficient and Accurate Robot Manipulation Based on Generative Models (1)",
    "summary": "Robot manipulation is a key component of automation, with applications spanning industrial assembly, healthcare, and service industries. Advances in AI and deep learning have enabled the use of generative models to enhance robot control and adaptability. This project aims to develop a generative model-based deep learning framework for robot manipulation, utilizing natural language inputs to generate precise low-level instructions. By optimizing model architecture and configurations, the system seeks to balance accuracy and efficiency. Successfully implementing this approach will enhance robots' ability to perform complex tasks, improving both industrial productivity and everyday applications. (With limited hardware availability, the experiments should be done at software level.)\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Model architecture design\n2. Low-level motion control\n3. Training-aware optimization for efficiency\n\n(b) Development component\n\n1. Model implementation\n2. Training pipeline\n3. Post-optimization and deployment\n4. Performance evaluation",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Real-Time / Embedded Systems",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0866",
    "title": "Comparing Branching Heuristics for SAT Solvers",
    "summary": "SAT solving is a fundamental problem in computer science, with wide-ranging applications in areas such as artificial intelligence, formal verification, and combinatorial optimization.\n\nThis project aims to compare the effectiveness of different branching heuristics used in modern Boolean satisfiability (SAT) solvers. You will evaluate and compare several prominent heuristics (e.g., Variable State Independent Decaying Sum, random choice, ...), on a diverse set of benchmark instances, with an aim to understand what heuristics work well on which problem sets. The performance of each heuristic will be assessed based on metrics like the number of decisions made, the number of conflicts encountered, and the total solving time. \n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Timothy van Bremen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Theory &amp; Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0867",
    "title": "Energy-Efficient System Design for Large Language Models Using Model Compression and Mixture of Experts (1)",
    "summary": "The rapid advancement of large language models (LLMs) has led to significant breakthroughs in AI, yet these models have become increasingly energy-intensive, requiring vast computational resources for both training and inference. This raises concerns about environmental impact and operational costs. To address these challenges, this project seeks to develop an energy-efficient system for LLMs by integrating model compression techniques and a mixture of experts (MoE) approach. The objective is to reduce computational resource consumption while maintaining high model performance, ensuring the sustainable deployment of AI in large-scale applications. By exploring efficient methods to balance energy savings with model accuracy, this system aims to make LLMs more accessible and feasible for resource-constrained environments, promoting the long-term sustainability of AI technologies.\n\nSpecific details:\n(a) Design component\n\n1. Develop the conversion process from dense LLMs to MoE-based LLMs (Mixture of Experts).\n2. Design a fine-tuning approach for the MoE conversion.\n3. Design the conversion from full-precision models to quantized models.\n4. Create a Quantization-Aware Training (QAT) workflow to maintain performance in quantized models.\n\n(b) Implementation component\n\n1. Implement MoE experts tailored for specific LLMs.\n2. Develop a quantization algorithm for various model components.\n3. Apply Quantization-Aware Training (QAT) and Parameter Efficient Fine-Tuning (PEFT) to preserve accuracy.\n4. Implement the optimization workflow, testing both performance and energy efficiency.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Low-power Computing",
      "Artificial Intelligence",
      "Real-Time / Embedded Systems",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0868",
    "title": "Efficient Spatio-Temporal Information Extraction for Enhanced Robot Manipulation",
    "summary": "In robot manipulation, Vision-Language Models (VLMs) are essential for enabling robots to process visual information and natural language instructions, reason about their environment, and plan complex tasks. However, current VLMs exhibit inefficiencies when applied to manipulation tasks, particularly in the integration of spatial and temporal information. This project seeks to address these challenges by developing a deep model with advanced methods for the efficient extraction of spatio-temporal information to enhance robot manipulation. Through specialized design techniques, this approach aims to improve the model's ability to respond more accurately in dynamic 3D environments. The successful outcome will enable more stable and reliable robot actions in real-world scenarios.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Design of parameterized model\n2. Design of feature extractors for spatial information\n3. Design of feature extractors for temporal information\n4. Aggregation of language and spatio-temporal features\n5. Generation of low-level instructions\n\n(b) Development component\n\n1. Model implementation\n2. Development of training pipeline\n3. Performance evaluation",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Robotics",
      "Real-Time / Embedded Systems",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0869",
    "title": "KV Cache Sharing for Multi-LLM serving (1)",
    "summary": "Deploying multiple large language models (LLMs) concurrently for diverse tasks presents significant challenges in memory consumption, latency, and energy efficiency. A substantial contributor to these overheads is the redundant storage and computation within individual KV caches maintained independently by each model. To address this inefficiency, this research proposes an innovative KV cache sharing strategy among multiple concurrently served LLMs. We aim to investigate methods for intelligently identifying commonalities in intermediate representations, effectively sharing KV caches, and optimizing access patterns. We will explore adaptive policies for cache merging, quantization, and compression techniques to enhance inference efficiency. The proposed approach will be validated on representative workloads in realistic multi-tenant scenarios. Our goal is to significantly reduce memory usage and inference latency, enabling efficient scaling of LLM serving infrastructures. By achieving effective KV cache sharing, this work seeks to lay foundations for sustainable, scalable, and cost-efficient multi-LLM deployment in cloud and edge computing environments.\n\nSpecific details:\n(a) Design component\n\n1. Selective KV cache sharing strategy between two concurrently served LLMs, emphasizing efficient similarity detection and dynamic cache allocation.\n2. Optimized KV cache sharing methodology tailored for teacher-student LLM pairs from knowledge distillation, leveraging representation alignment and hierarchical cache reuse techniques.\n\n(b) Implementation component\n\n1. Implementation of a generalized KV cache sharing mechanism applicable to multiple LLM architectures exhibiting structural similarities.\n2. Targeted implementation and performance analysis of KV cache sharing with the LLaMA series or Deepseek series LLMs, emphasizing accuracy, latency, and resource utilization metrics.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Low-power Computing",
      "Natural Language Processing/ Text Mining",
      "Computer Architecture"
    ]
  },
  {
    "projectNo": "CCDS25-0870",
    "title": "KV Cache Sharing for Multi-LLM serving (2)",
    "summary": "Deploying multiple large language models (LLMs) concurrently for diverse tasks presents significant challenges in memory consumption, latency, and energy efficiency. A substantial contributor to these overheads is the redundant storage and computation within individual KV caches maintained independently by each model. To address this inefficiency, this research proposes an innovative KV cache sharing strategy among multiple concurrently served LLMs. We aim to investigate methods for intelligently identifying commonalities in intermediate representations, effectively sharing KV caches, and optimizing access patterns. We will explore adaptive policies for cache merging, quantization, and compression techniques to enhance inference efficiency. The proposed approach will be validated on representative workloads in realistic multi-tenant scenarios. Our goal is to significantly reduce memory usage and inference latency, enabling efficient scaling of LLM serving infrastructures. By achieving effective KV cache sharing, this work seeks to lay foundations for sustainable, scalable, and cost-efficient multi-LLM deployment in cloud and edge computing environments.\n\nSpecific details:\n(a) Design component\n\n1. Selective KV cache sharing strategy between two concurrently served LLMs, emphasizing efficient similarity detection and dynamic cache allocation.\n2. Optimized KV cache sharing methodology tailored for teacher-student LLM pairs from knowledge distillation, leveraging representation alignment and hierarchical cache reuse techniques.\n\n(b) Implementation component\n\n1. Implementation of a generalized KV cache sharing mechanism applicable to multiple LLM architectures exhibiting structural similarities.\n2. Targeted implementation and performance analysis of KV cache sharing with the LLaMA series or Deepseek series LLMs, emphasizing accuracy, latency, and resource utilization metrics.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Low-power Computing",
      "Natural Language Processing/ Text Mining",
      "Computer Architecture"
    ]
  },
  {
    "projectNo": "CCDS25-0871",
    "title": "Energy-Efficient System Design for Large Language Models Using Model Compression and Mixture of Experts (2)",
    "summary": "The rapid advancement of large language models (LLMs) has led to significant breakthroughs in AI, yet these models have become increasingly energy-intensive, requiring vast computational resources for both training and inference. This raises concerns about environmental impact and operational costs. To address these challenges, this project seeks to develop an energy-efficient system for LLMs by integrating model compression techniques and a mixture of experts (MoE) approach. The objective is to reduce computational resource consumption while maintaining high model performance, ensuring the sustainable deployment of AI in large-scale applications. By exploring efficient methods to balance energy savings with model accuracy, this system aims to make LLMs more accessible and feasible for resource-constrained environments, promoting the long-term sustainability of AI technologies.\n\nSpecific details:\n(a) Design component\n\n1. Develop the conversion process from dense LLMs to MoE-based LLMs (Mixture of Experts).\n2. Design a fine-tuning approach for the MoE conversion.\n3. Design the conversion from full-precision models to quantized models.\n4. Create a Quantization-Aware Training (QAT) workflow to maintain performance in quantized models.\n\n(b) Implementation component\n\n1. Implement MoE experts tailored for specific LLMs.\n2. Develop a quantization algorithm for various model components.\n3. Apply Quantization-Aware Training (QAT) and Parameter Efficient Fine-Tuning (PEFT) to preserve accuracy.\n4. Implement the optimization workflow, testing both performance and energy efficiency.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Low-power Computing",
      "Artificial Intelligence",
      "Real-Time / Embedded Systems",
      "Natural Language Processing/ Text Mining"
    ]
  },
  {
    "projectNo": "CCDS25-0872",
    "title": "Efficient and Accurate Robot Manipulation Based on Generative Models (2)",
    "summary": "Robot manipulation is a key component of automation, with applications spanning industrial assembly, healthcare, and service industries. Advances in AI and deep learning have enabled the use of generative models to enhance robot control and adaptability. This project aims to develop a generative model-based deep learning framework for robot manipulation, utilizing natural language inputs to generate precise low-level instructions. By optimizing model architecture and configurations, the system seeks to balance accuracy and efficiency. Successfully implementing this approach will enhance robots' ability to perform complex tasks, improving both industrial productivity and everyday applications. (With limited hardware availability, the experiments should be done at software level.)\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Model architecture design\n2. Low-level motion control\n3. Training-aware optimization for efficiency\n\n(b) Development component\n\n1. Model implementation\n2. Training pipeline\n3. Post-optimization and deployment\n4. Performance evaluation",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Natural Language Processing/ Text Mining",
      "Real-Time / Embedded Systems",
      "Robotics"
    ]
  },
  {
    "projectNo": "CCDS25-0873",
    "title": "Rethinking Buffer Usage in NoC: Toward Coherence-Efficient Routing (3)",
    "summary": "In Networks-on-Chip (NoCs), buffers exist in both routers and cache coherence protocols, influencing congestion and coherence delays. However, their combined impact on system performance is often overlooked. This project investigates how buffer behavior affects coherence and communication efficiency. We aim to design a buffer-aware routing strategy that dynamically adapts to buffer occupancy and coherence traffic, improving latency and throughput in many-core systems. If successful, this approach could enhance NoC scalability and energy-efficiency under heavy traffic and coherence load. \nReference: Zixuan Liu and Yaoyao Ye. 2025. A Buffer Reservation Scheduling Strategy for Enhancing Performance of NoC Router Bypassing. In Proceedings of the 30th Asia and South Pacific Design Automation Conference (ASPDAC '25). Association for Computing Machinery, New York, NY, USA, 575�580.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n1. Buffer-coherence interaction modeling\n2. Analysis of buffer pressure on performance\n3. Design of buffer reservation and routing coordination\n4. Comparative evaluation against existing flow control schemes\n\n(b) Development component\n\n1. Integration of buffer-aware routing in full system simulation\n2. Extension of gem5 with buffer reservation support\n3. Synthetic and real workload deployment\n4. Full-system performance measurement and visualization",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "System on-Chip",
      "Computer Architecture"
    ]
  },
  {
    "projectNo": "CCDS25-0876",
    "title": "KV Cache Sharing for Multi-LLM serving (3)",
    "summary": "Deploying multiple large language models (LLMs) concurrently for diverse tasks presents significant challenges in memory consumption, latency, and energy efficiency. A substantial contributor to these overheads is the redundant storage and computation within individual KV caches maintained independently by each model. To address this inefficiency, this research proposes an innovative KV cache sharing strategy among multiple concurrently served LLMs. We aim to investigate methods for intelligently identifying commonalities in intermediate representations, effectively sharing KV caches, and optimizing access patterns. We will explore adaptive policies for cache merging, quantization, and compression techniques to enhance inference efficiency. The proposed approach will be validated on representative workloads in realistic multi-tenant scenarios. Our goal is to significantly reduce memory usage and inference latency, enabling efficient scaling of LLM serving infrastructures. By achieving effective KV cache sharing, this work seeks to lay foundations for sustainable, scalable, and cost-efficient multi-LLM deployment in cloud and edge computing environments.\n\nSpecific details:\n(a) Design component\n\n1. Selective KV cache sharing strategy between two concurrently served LLMs, emphasizing efficient similarity detection and dynamic cache allocation.\n2. Optimized KV cache sharing methodology tailored for teacher-student LLM pairs from knowledge distillation, leveraging representation alignment and hierarchical cache reuse techniques.\n\n(b) Implementation component\n\n1. Implementation of a generalized KV cache sharing mechanism applicable to multiple LLM architectures exhibiting structural similarities.\n2. Targeted implementation and performance analysis of KV cache sharing with the LLaMA series or Deepseek series LLMs, emphasizing accuracy, latency, and resource utilization metrics.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "A/P Liu Weichen",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Low-power Computing",
      "Natural Language Processing/ Text Mining",
      "Computer Architecture"
    ]
  },
  {
    "projectNo": "CCDS25-0877",
    "title": "Investigating the Impact of Problem Structure on SAT Solving in Practice",
    "summary": "SAT solving is a fundamental problem in computer science with wide-ranging applications in areas such as artificial intelligence, formal verification, and combinatorial optimization.\n\nThis project seeks to understand how the structure of Boolean satisfiability (SAT) problem instances influences the performance of SAT solvers in practice. The goal is to analyze various structural properties of SAT formulas, such as treewidth, pathwidth, and others, and empirically correlate them with key performance metrics like overall solving time and number of conflicts. By examining these relationships across a number of benchmarks, we aim to identify which structural characteristics make problems easier or harder for current SAT solving techniques in practice. The findings will contribute to a better understanding of solver limitations, and potentially inspire the development of more structure-aware algorithms.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Timothy van Bremen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Theory &amp; Algorithms",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0878",
    "title": "Investigating the Use of Inductive Logic Programming for Knowledge Graph Completion",
    "summary": "This project explores the application of Inductive Logic Programming (ILP) to the task of Knowledge Graph Completion. It aims to investigate how ILP techniques can learn logical rules from existing triples within a knowledge graph. These learned rules will then be used to infer missing relationships and predict new triples, effectively expanding the knowledge graph. The project will involve implementing and evaluating different ILP approaches on benchmark knowledge graphs to assess their accuracy and efficiency in completing missing information. This ultimate goal is to demonstrate the potential of logic-based machine learning for enhancing the completeness of knowledge graphs.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Timothy van Bremen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Knowledge Representation/ Ontology"
    ]
  },
  {
    "projectNo": "CCDS25-0879",
    "title": "Exploring the Use of Machine Learning to Guide SAT Solver Heuristics",
    "summary": "Boolean satisfiability (SAT) solving is a fundamental problem in computer science with wide-ranging applications in areas such as artificial intelligence, formal verification, and combinatorial optimization.\n\nThis project investigates the potential of machine learning to enhance the performance of SAT solvers. We will explore how machine learning models can be trained to predict effective branching variables or optimal parameter settings for SAT solvers based on the characteristics of input formulas. By analyzing features of SAT instances, the trained models will aim to guide the solver's search process, ideally leading to faster solving times. The project will involve implementing and evaluating different machine learning approaches to dynamically adapt SAT solver behaviour, ultimately contributing to the development of more intelligent and robust solvers. Note that this idea has precedent: MapleSAT (https://maplesat.github.io/), an existing state-of-the-art SAT solver, uses machine learning heuristics for improved performance.\n\nDepending on the progress of the project and time constraints, a similar study may be done for Boolean model counters (#SAT).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Ast/P Timothy van Bremen",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Logic and Formal Methods",
      "Data Structure and Algorithms"
    ]
  },
  {
    "projectNo": "CCDS25-0880",
    "title": "Real-Time Sleep Staging with Smartwatch",
    "summary": "This project aims to develop a real-time sleep staging algorithm that uses smartwatch data (e.g., movement, heart-rate, and electrodermal activity data from Google Pixel Watch 3). Sleep staging normally classifies when the user is in the awake, light sleep (N1), sleep (N2), deep sleep (N3) or rapid-eye movement (REM) stage. By detecting these stages in real-time, the smartwatch could administer sleep interventions at various stages (e.g., playing audio at N3 stage improve sleep quality or at REM stage to induce lucid dreaming). Existing commercial sleep-tracking algorithms on smartwatches (e.g. Fitbit, Apple Watch) or smart rings (e.g., Oura) only provide post-hoc/ post-wake analysis and do not track sleep stages in real-time. The project addresses the need for accessible sleep monitoring by leveraging devices people already own such as smartwatches. The project will explore collecting data using smartwatches and gold-standard sleep-trackers (for ground-truth labelling) while users are taking a nap (&lt;30min) or during overnight sleep. The collected data will be used in combination with various signal-processing algorithms, AI and/or machine learning methods to identify sleep stages in real-time. The system will be validated against existing state-of-the-art methods to establish accuracy benchmarks. The project might explore embedded ML and implementing the algorithm to work in real-time on the smartwatch itself (e.g., TFLite models).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nCompare smartwatch sensor data with state-of-the-art smartwatch-based actigraphy methods, develop machine learning algorithms optimized for smartwatch sensor inputs, and benchmark sleep staging algorithms against state-of-the-art (SOTA) methods.\n\n(b) Development component\nSmartwatch interface, real-time sleep staging algorithm, signal processing pipeline.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Ubiquitous/ Pervasive Computing",
      "Real-Time / Embedded Systems",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0881",
    "title": "Real-Time Sleep Staging with Smart Speakers for Sleep Interventions",
    "summary": "This project aims to develop a real-time sleep staging algorithm that uses audio or reflected ultra-sound/inaudible sounds and other sensors from commercial smart speakers (e.g., Google Home, Apple HomePod). Sleep staging normally classifies when the user is in the awake, light sleep (N1), sleep (N2), deep sleep (N3) or rapid-eye movement (REM) stage. By detecting these stages in real-time, the smart speaker could administer sleep interventions at various stages (e.g., playing audio at N3 stage improve sleep quality or at REM stage to induce lucid dreaming). Existing commercial sleep-tracking algorithms on smart speakers only provide post-hoc/ post-wake analysis and do not track sleep stages in real-time. The project addresses the need for accessible sleep monitoring by leveraging devices people might already own such as smart speakers. The project will explore collecting data using smart speakers and gold-standard wearable sleep-trackers (for ground-truth labelling) while users are taking a nap (&lt;30min) or during overnight sleep. The collected data will be used in combination with various signal-processing algorithms and AI (deep learning, machine learning) methods to identify sleep stages in real-time. The system will be validated against existing state-of-the-art methods to establish accuracy benchmarks. The project might explore embedded ML and implementing the algorithm to work in real-time on the smart speaker itself (e.g., TFLite models).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nCompare smart speaker sensor data with state-of-the-art smart speaker-based sleep staging methods, develop deep/machine learning algorithms optimized for smart speaker sensor inputs, and benchmark sleep staging algorithms against state-of-the-art (SOTA) methods.\n\n(b) Development component\nSmart speaker interface, real-time sleep staging algorithm, signal processing pipeline.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Ubiquitous/ Pervasive Computing",
      "Real-Time / Embedded Systems",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0882",
    "title": "Pillow Interfaces for Real-Time Sleep Staging and Sleep Interventions",
    "summary": "This project aims to develop 1) a device that clips onto pillows or is embedded into pillow cases and 2) a real-time sleep staging algorithm that uses the device�s sensor data like movement data. Sleep staging normally classifies when the user is in the awake, light sleep (N1), sleep (N2), deep sleep (N3) or rapid-eye movement (REM) stage. By detecting these stages in real-time, the device could administer sleep interventions at various stages (e.g., playing audio at N3 stage improve sleep quality or at REM stage to induce lucid dreaming). There is a lack of existing devices on pillows for real-time sleep tracking and existing commercial sleep-tracking algorithms on devices like smartphones and smartwatches mainly provide post-hoc/ post-wake analysis and do not track sleep stages in real-time. The project will explore building the device using powerful and tiny micro-controller boards like the Seeed XIAO nRF52840 Sense Plus and programming it using Arduino (C++) or MicroPython, Then, collecting data with the device and gold-standard wearable sleep-trackers (for ground-truth labelling) while users are taking a nap (&lt;30min) or during overnight sleep. The collected data will be used in combination with various signal-processing algorithms and AI (deep learning, machine learning) methods to identify sleep stages in real-time. The system will be validated against any existing state-of-the-art methods to establish accuracy benchmarks. The project might explore embedded ML and implementing the algorithm to work in real-time on the device itself (e.g., TFLite models).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nData collection, compare device sensor data with state-of-the-art sleep staging methods, develop deep/machine learning algorithms optimized for the device sensor inputs, and benchmark sleep staging algorithms against state-of-the-art (SOTA) methods.\n\n(b) Development component\nMicro-controller programming, on-pillow interface development , real-time sleep staging algorithm, signal processing pipeline.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Ubiquitous/ Pervasive Computing",
      "Real-Time / Embedded Systems",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0883",
    "title": "Sleep Mask for Real-Time Sleep Staging and Sleep Interventions",
    "summary": "This project aims to develop 1) a sleep mask device with movement sensors and possibility infra-red eye movement sensors and electroencephalogram (EEG) brain-activity sensors and 2) potentially a real-time sleep staging algorithm that uses the mask�s sensor data. Sleep staging normally classifies when the user is in the awake, light sleep (N1), sleep (N2), deep sleep (N3) or rapid-eye movement (REM) stage. By detecting these stages in real-time, the device could administer sleep interventions at various stages (e.g., playing audio at N3 stage improve sleep quality or at REM stage to induce lucid dreaming). There is a lack of existing devices on sleep masks for real-time sleep tracking and existing commercial sleep-tracking algorithms on devices like smartphones and smartwatches mainly provide post-hoc/ post-wake analysis and do not track sleep stages in real-time. The project will explore building the sleep mask device and will require hardware implementation skills (micro-controller programming, circuits design and electrical engineering). The project may also explore collecting data with the mask and gold-standard wearable sleep-trackers (for ground-truth labelling) while users are taking a nap (&lt;30min) or during overnight sleep. The collected data will be used in combination with various signal-processing algorithms and AI (deep learning, machine learning) methods to identify sleep stages in real-time. The system will be validated against any existing state-of-the-art methods to establish accuracy benchmarks. The project might explore embedded ML and implementing the algorithm to work in real-time on the device itself (e.g., TFLite models).\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nData collection, compare device sensor data with state-of-the-art sleep staging methods, develop deep/machine learning algorithms optimized for the device sensor inputs, and benchmark sleep staging algorithms against state-of-the-art (SOTA) methods.\n\n(b) Development component\nSleep mask device development, micro-controller programming, real-time sleep staging algorithm, signal processing pipeline.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Ubiquitous/ Pervasive Computing",
      "Real-Time / Embedded Systems",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0884",
    "title": "Alleviating Insomnia using LLM-based Voice Interfaces and Chatbots",
    "summary": "Singapore is the third-most sleep deprived cities in the world (according to a 2023 survey) and majority of the sleep troubles in the world are due to �sleep-onset insomnia� where people have trouble falling asleep when they are ready to sleep. This project aims to develop large language model (LLM) based voice interfaces that could help people fall asleep faster; increase people�s sleep onset. The project will explore the development of web applications deployed on laptops/smartphones/etc that could keep users from distracting or anxious thoughts by implementing neuroscience/sleep research based methods that potentially enable faster sleep onset. For example, it could get you to engage in (quite mindless) counting in a turn-taking format where the voice interface will start with �1� and you will say �2�, then the interface will say �3� and so on. Variations could be made such as counting backwards from 100 or counting forward in increments of 7. Other methods could be explored such as listening the LLM interface tell an extremely boring story. The project might also explore testing out this interface with users to get feedback on user experience and measure whether it could potentially improve sleep onset.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearching past neuroscience and sleep science literature to understand best methods to implement. Conducting user studies to test the interface and study effects on sleep onset and user experience.\n\n(b) Development component\nWeb-based voice interfaces using LLMs, potential fine-tuning and additional algorithm development.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Web-based Applications",
      "Video/Audio/Speech Processing",
      "Artificial Intelligence",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0885",
    "title": "Deeper Sleep using LLM-based Hypnosis and Voice Interfaces",
    "summary": "Singapore is the third-most sleep deprived cities in the world (according to a 2023 survey) and there is a growing need worldwide to achieve higher sleep quality. This project aims to develop large language model (LLM) based voice interfaces that could help people enhance their sleep quality and have deeper sleep. The project will explore the development of web applications deployed on laptops/smartphones/etc that implements hypnosis and audio interventions before sleep. Some of these interventions have been shown in neuroscience/sleep research to enable better sleep outcomes and the use of LLMs and voice interfaces for such applications remains unexplored. The envisioned system could provide hypnotic suggestions such as guiding you imagine going deeper into the sea and deeper into sleep. The deployed web app LLM could provide variations of hypnotic or voice suggestions. The project might also explore testing out this interface with users to get feedback on user experience and measure whether it could potentially improve sleep quality, deep sleep duration and other sleep outcomes.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearching past neuroscience and sleep science literature to understand best methods to implement. Conducting user studies to test the interface and study effects on sleep quality, sleep outcomes and user experience.\n\n(b) Development component\nWeb-based voice interfaces using LLMs, potential fine-tuning and additional algorithm development.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Web-based Applications",
      "Artificial Intelligence",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0886",
    "title": "Improving Memory via Web Apps on Desktop/Phone -- Memory Reactivation During Sleep",
    "summary": "In this project, we are trying to create and test web apps that can help improve memory by \"reactivating memories\" during sleep. \nUsers first \"tag memories\" on a web app or browser add-on, which will start playing music or audio patterns, while you are learning something like watching a lecture or video etc. \nWhen you sleep at night, the web app could approximate or time when you are in deep sleep and plays the same music audio patterns which can help your brain to \"reactivate\" and strengthen these tagged memories. This could help boost our everyday cognitive performance and memory. The deployed system could be integrated with �pomodoro� like web apps, Spotify or Youtube apps, or as an internet browser add-on. It could provide variations of audio or music either based on user selection or automated recommendations. There is potential to explore generative AI, AI agents and recommendation systems. The project might also explore testing out this interface with users to get feedback on user experience and measure whether it could improve memory through a lecture or documentary video (for the user study) and quizzes designed to test recall of the video contents.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearching past neuroscience and sleep science literature to understand targeted memory reactivation methods to implement. Conducting user studies to test the interface and study effects on memory and user experience.\n\n(b) Development component\nWeb-based interface for targeted memory reactivation, potential fine-tuning and additional algorithm development.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Web-based Applications",
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0887",
    "title": "Enhancing cognitive ability through olfactory (scent) interfaces in sleep and educational settings",
    "summary": "In this project, we are trying to test how olfactory interfaces (interfaces that release scents like portable diffusers) can help improve cognitive abilities in people (such as memory) by \"reactivating memories\" and providing �olfactory enrichment� during sleep. \nUsers first \"tag memories\" by having the interface present scents while you are learning something like watching a lecture or video etc. We aim to test this in real-time educational settings such as classrooms, life-long learning centres etc.\nWhen you sleep at night, the interface would present the same scent which can help your brain to \"reactivate\" and strengthen these tagged memories. Prolonged olfactory exposure during sleep over a days and weeks have been shown to boost people�s everyday cognitive performance. \nThe project will test out the interfaces with users in their own learning environments and at home when they sleep overnight. The user study will compare three experimental conditions: 1. One night with the same scent presented as the one used during learning, 2. One night with a different scent (active control), 3. One night with no scent (control condition). The study will get feedback on user experience and measure whether it could improve memory through quizzes designed to test recall of the learning/video contents and other cognitive abilities. The technical component of the project involves data analysis of data collected from the questionnaires, quizzes and electroencephalogram (EEG) brain-activity sensors and other biosensing technologies.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearching past neuroscience and sleep science literature to understand targeted memory reactivation and olfactory enrichment methods to implement. Conducting user studies to test the interface and study effects on cognitive abilities and user experience.\n\n(b) Development component\nData analysis scripts for data collected from questionnaires, quizzes and electroencephalogram (EEG) brain-activity sensors and other biosensing technologies.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Ubiquitous/ Pervasive Computing",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0889",
    "title": "Techno-Psychedelics: Inducing Altered States of Consciousness through Digital Interfaces",
    "summary": "Previous works have explored using virtual reality (VR) and multi-modal interfaces (e.g. audio-visual) to induce altered states of consciousness, some of which enable experiences comparable to psychedelics like increased sense of connectedness, openness and transcendence (https://dl.acm.org/doi/10.1145/3313831.3376649). The project aims to design similar experiences in VR, mixed reality and/or digital interfaces and testing if they could alter creativity, critical thinking and mood or mental states in people (https://www.nature.com/articles/s41598-023-31361-w). This project is exploratory in nature; it could be implemented as immersive virtual reality environments, graphics shaders, using generative AI or even audio-induced hypnagogic (while falling into sleep) experiences. The project might also test the interfaces with users to get feedback on user experiences and effects on cognitive abilities and mental states. The project would be suitable for students who are interested in the intersection of human-computer interactions and neuroscience/cognitive science fields.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearching past human-computer interactions, neuroscience, cognitive science literature to understand methods to implement. Conducting user studies to test the interface and study effects on user states of consciousness and user experience.\n\n(b) Development component\nTechno-psychedelic Interface development, possible 2D/3D generative AI, shaders and mixed reality implementation.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Virtual Reality",
      "Mixed Reality",
      "Multimedia Systems",
      "Visual Computing"
    ]
  },
  {
    "projectNo": "CCDS25-0890",
    "title": "Self-Voice Interfaces and Agents to Alter Creative Performance",
    "summary": "Previous works have shown that interfaces that use self-voices (the user�s own voice) can have positive psychological and behavioral effects on people (https://arxiv.org/pdf/2409.11531) including nudging people towards their ideal selves with self-voice messages or improved task completion with self-voice reminders. In this project, the aim is to 1. Develop a web app that implements a voice-cloning model or calls a voice-cloning API and uses the user�s self-voice to support creative performance through LLM-based interfaces. The possible scenarios to support could be drawing, story writing, or ideation sessions. 2. Test the web app to study the effects on the users� creative performance via a series of tasks such as the Creative Storytelling Task, Alternative Uses Task and Verb Generation Task. One group of users will be asked to use the self-voice web app for about 10-15 minutes, one group will the web app with a default random voice, and a final group will not be interacting with the web app.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearching past human-computer interactions, neuroscience literature to understand methods to implement. Conducting user studies to test the interface and study effects on creativity and user experience.\n\n(b) Development component\nWeb app interface development, deploying voice-cloning AI models or APIs, fine-tuning and developing LLM voice interface.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Software)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Web-based Applications",
      "Video/Audio/Speech Processing",
      "Artificial Intelligence",
      "Multimedia Systems"
    ]
  },
  {
    "projectNo": "CCDS25-0891",
    "title": "Promoting Brain Health through Subliminal Gamma Frequency 40 Hz Light and Sensory Stimulation Device",
    "summary": "Researchers have shown that we can improve brain health by using light, audio and vibration sensory stimulation to stimulate 40 Hz gamma frequency rhythms in the brain (https://news.mit.edu/2025/evidence-40hz-gamma-stimulation-promotes-brain-health-expanding-0314). These could help treat Alzheimer�s disease, improve memory recall and other cognitive outcomes in people. However, having light, audio or vibration stimulation near 40Hz can be uncomfortable to experience; imagine that 40 Hz light flashes would be seen as strobe lighting. In this project, the aim is to develop devices that could produce such 40 Hz light but in micro/nano-second bursts that humans cannot consciously perceive, in what we can call �subliminal� stimulation. To test if the device could work in stimulating 40 Hz brain rhythms, we would record the user�s brain activity using a wearable electroencephalogram (EEG) headset while exposed to the subliminal stimulation through the device and study if there are neurological responses to the stimuli. We would also perform further analysis on whether we see higher activity of 40 Hz gamma rhythms in the brain. This project is suitable for students with experience in circuit design, electrical engineering, computer engineering, and interested in the intersection of human-computer interactions and neuroscience.\n\nSpecific details:\n(a) Design component\n\n\n(b) Implementation component\n\n(a) Research component\nResearching past human-computer interactions, neuroscience and computer/electrical engineering literature to understand methods to implement. Conducting user studies to test the device and study effects brain activity.\n\n(b) Development component\nDevice for providing subliminal sensory stimulation through circuit and hardware design.",
    "supervisor": "Ast/P Chan Wei Ting, Samantha",
    "isJointOrURECA": "No",
    "category": "Hardware & Software (Mostly Hardware)",
    "type": "Research & Development",
    "keywords": [
      "Human Computer Interaction",
      "Digital Systems",
      "Field Programmable Gate Arrays (FPGA)"
    ]
  },
  {
    "projectNo": "CCDS25-0892",
    "title": "Stock Trading Strategy Based on Financial Report Dates, 52-Week Extremes, and Volatility Measures",
    "summary": "This project aims to develop an algorithmic stock trading strategy that leverages three core financial indicators:\n�\tFinancial Report Dates: These serve as event markers that may cause significant price adjustments due to earnings announcements or other key disclosures.\n�\t52-Week Low and High: These metrics help gauge potential support and resistance levels, providing insights into when a stock might be undervalued (near 52-week low) or overvalued (near 52-week high).\n�\tVolatility Measures: Quantitative assessments of price fluctuations over time (using metrics like historical volatility or the Average True Range) enable the strategy to manage risk and optimize entry/exit points.\n\nSpecific details:\nBy integrating these components, the proposed trading strategy seeks to identify attractive trading opportunities and systematically manage risk through dynamic position sizing and stop-loss rules.\n\nExpected Outcomes\n�\tTrading Algorithm: A fully implemented trading strategy that systematically uses financial report events, 52-week extremes, and volatility measures to generate trading signals.\n�\tPerformance Analysis: A detailed report comparing the strategy�s backtested performance against common benchmarks (e.g., buy-and-hold strategy), including risk-adjusted metrics.\n�\tRisk Management Insights: Enhanced understanding of how volatility-driven risk management can protect portfolio returns.\n�\tFuture Directions: Recommendations for real-time deployment and further research into the integration of additional indicators or machine learning techniques to refine signal generation.",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics"
    ]
  },
  {
    "projectNo": "CCDS25-0893",
    "title": "Machine Learning-Based Stock Trading Strategy Using Historical Data",
    "summary": "This project aims to design and implement an algorithmic stock trading strategy by leveraging historical market data and machine learning techniques. The goal is to predict stock price movements and generate trading signals that can be backtested for performance.\n\nSpecific details:\nExpected Outcomes\n�\tA fully implemented trading algorithm that utilizes machine learning to predict stock price movements.\n�\tA comprehensive performance analysis based on historical backtesting.\n�\tA set of insights on the effectiveness of machine learning techniques in financial forecasting.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Data Analytics",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0894",
    "title": "Online Secure Payment for Membership System",
    "summary": "In today's digital era, online membership systems play a crucial role in providing exclusive resources and services to members. However, ensuring secure and seamless payment processes is essential for the success and trustworthiness of these systems. This project focuses on implementing state-of-the-art secure online payment methods within a membership system.\n\n\nThis project requires proficiency in both English and Mandarin to effectively access diverse sources and engage with a broad range of stakeholders.\n\nSpecific details:\n�\tDesign and implement various access levels distinguishing between members and non-members.\n�\tDevelop a secure payment mechanism allowing members to pay their annual membership fees.\n�\tImplement multiple state-of-the-art online payment methods for seamless transactions.\n�\tIntegrate access control features for members to access exclusive resources and purchase items.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "e-Commerce"
    ]
  },
  {
    "projectNo": "CCDS25-0895",
    "title": "Online Life-Long Learning App with Personalized Recommendation",
    "summary": "In the era of continuous technological advancements, the need for life-long learning has become paramount. This project aims to develop an innovative Online Life-Long Learning App that not only provides a diverse range of courses but also utilizes personalized recommendation systems to enhance the learning experience.\n\nThis project requires proficiency in both English and Mandarin to effectively access diverse sources and engage with a broad range of stakeholders.\n\nSpecific details:\n�\tCreate a user-friendly mobile application accessible across various devices.\n�\tDevelop a comprehensive database of courses covering a wide array of subjects.\n�\tImplement a robust recommendation algorithm for personalized learning paths.\n�\tIntegrate features for interactive assessments, quizzes, and progress tracking.\n�\tEstablish a community platform for learners to connect, share experiences, and collaborate.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0896",
    "title": "Online Life-Long Learning App with Personalized Recommendation part 2",
    "summary": "In the era of continuous technological advancements, the need for life-long learning has become paramount. This project aims to develop an innovative Online Life-Long Learning App that not only provides a diverse range of courses but also utilizes personalized recommendation systems to enhance the learning experience.\n\nThis project requires proficiency in both English and Mandarin to effectively access diverse sources and engage with a broad range of stakeholders.\n\nSpecific details:\n�\tCreate a user-friendly mobile application accessible across various devices.\n�\tDevelop a comprehensive database of courses covering a wide array of subjects.\n�\tImplement a robust recommendation algorithm for personalized learning paths.\n�\tIntegrate features for interactive assessments, quizzes, and progress tracking.\n�\tEstablish a community platform for learners to connect, share experiences, and collaborate.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Mobile Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0897",
    "title": "Title: Investigating Patterns of Attention in Students During Lectures: An EEG and Deep Learning Approach",
    "summary": "In the dynamic landscape of educational methodologies, understanding the patterns of attention exhibited by students during lectures is crucial for optimizing learning environments. Traditional methods of assessing attention rely on subjective measures, often limited by self-reporting or external observations. This research proposes to utilize Electroencephalography (EEG) coupled with advanced deep learning techniques to objectively measure and analyze patterns of attention in students during lectures.\n\nSpecific details:\nThe primary objectives of this research are:\na. To employ EEG technology to capture real-time brainwave data during student lectures.\nb. To develop a robust deep learning model capable of analyzing EEG data to identify patterns associated with attention levels.\nc. To investigate the correlation between attention patterns and academic performance.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "projectNo": "CCDS25-0898",
    "title": "Beyond Web Builders: Exploring Limitations and Opportunities in Web Development",
    "summary": "Web builders have significantly simplified the website creation process, enabling users to design and deploy websites without extensive coding knowledge. However, these tools inherently come with limitations. This project aims to investigate and analyze the boundaries of web builders, identifying areas where they fall short and exploring opportunities for improvement in web development.\n\nThis project requires proficiency in both English and Mandarin to effectively access diverse sources and engage with a broad range of stakeholders.\n\nSpecific details:\n�\tIdentify and analyze the limitations of popular web builders.\n�\tInvestigate common challenges faced by users when working with web builders.\n�\tExplore advanced web development functionalities that are typically not supported by web builders.\n�\tPropose solutions or alternatives to address identified limitations.\n�\tDevelop a prototype or proof-of-concept demonstrating the implementation of advanced features.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Software and Applications",
      "Web-based Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0899",
    "title": "Development of an AI-Powered Exchange Platform part 3",
    "summary": "The continuous evolution of financial markets demands advanced tools for investors to make informed decisions. This project aims to actively engage students in the development of an AI-powered exchange platform. This platform will empower investors by providing intelligent insights, facilitating investment decisions, and managing their portfolios effectively.\n\nSpecific details:\n�\tParticipate in the design and development of an AI-driven exchange platform.\n�\tImplement machine learning algorithms for market analysis and prediction.\n�\tIntegrate features for portfolio management and investment recommendations.\n�\tEnsure a user-friendly interface for seamless investor interaction.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0900",
    "title": "Development of an AI-Powered Exchange Platform part 2",
    "summary": "The continuous evolution of financial markets demands advanced tools for investors to make informed decisions. This project aims to actively engage students in the development of an AI-powered exchange platform. This platform will empower investors by providing intelligent insights, facilitating investment decisions, and managing their portfolios effectively.\n\nSpecific details:\n�\tParticipate in the design and development of an AI-driven exchange platform.\n�\tImplement machine learning algorithms for market analysis and prediction.\n�\tIntegrate features for portfolio management and investment recommendations.\n�\tEnsure a user-friendly interface for seamless investor interaction.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0901",
    "title": "Development of an AI-Powered Exchange Platform part 1",
    "summary": "The continuous evolution of financial markets demands advanced tools for investors to make informed decisions. This project aims to actively engage students in the development of an AI-powered exchange platform. This platform will empower investors by providing intelligent insights, facilitating investment decisions, and managing their portfolios effectively.\n\nSpecific details:\n�\tParticipate in the design and development of an AI-driven exchange platform.\n�\tImplement machine learning algorithms for market analysis and prediction.\n�\tIntegrate features for portfolio management and investment recommendations.\n�\tEnsure a user-friendly interface for seamless investor interaction.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Web-based Applications",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0902",
    "title": "Exploring the Limitations of Claude: An Empirical Study of Boundaries in Anthropic�s Language Model",
    "summary": "This project aims to systematically investigate the limitations of Claude, a state-of-the-art language model developed by Anthropic. Despite its impressive capabilities in natural language understanding and generation, Claude exhibits specific shortcomings when it comes to complex reasoning, context retention, ethical judgment, and domain-specific tasks. Through controlled experiments and benchmark tests, this study will identify and analyze these limitations. The findings will contribute to a deeper understanding of current AI constraints and offer recommendations for the future development of more robust, transparent, and ethically aligned language models.\n\nSpecific details:\nThe primary objectives of the project are:\n�\tBenchmarking Performance: Design and implement tests across various tasks (e.g., complex reasoning, long-context understanding, ethical decision-making) to identify where Claude's performance degrades.\n�\tError Analysis: Categorize and analyze error types, such as hallucinations, inability to perform multi-step reasoning, or context drop-offs.\n�\tRoot Cause Investigation: Examine the architectural and training-related factors that might contribute to these limitations.\n�\tRecommendations: Propose potential improvements and future research directions to address the identified shortcomings.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Artificial Intelligence"
    ]
  },
  {
    "projectNo": "CCDS25-0903",
    "title": "Enhancing Game Design and Development in Unity Using Generative AI: Opportunities and Shortcomings",
    "summary": "This project aims to investigate the potential of generative AI in transforming game design and development within the Unity ecosystem. By integrating AI-driven asset generation, procedural content creation, and automated design suggestions into Unity, the study will assess both the opportunities and limitations of these techniques. Through a combination of literature review, prototype development, and empirical testing, the project seeks to provide actionable insights for game developers, highlighting how generative AI can streamline development processes while also addressing its inherent challenges.\n\nSpecific details:\nUnity is one of the most widely used game engines, enabling developers to create interactive and immersive experiences. Recently, generative AI has emerged as a promising tool in various creative fields, including game development. Techniques such as neural network-based image synthesis, natural language processing, and procedural generation are being employed to create assets, design levels, and even script in-game narratives. However, while these approaches offer significant benefits in terms of speed and creativity, they also introduce challenges such as inconsistent quality, integration complexity, and ethical considerations.\nThis proposal outlines a project to explore:\n�\tHow generative AI can be effectively integrated into Unity for game design and development.\n�\tThe strengths and opportunities provided by these AI tools.\n�\tThe shortcomings and limitations that need to be addressed to ensure a balanced and practical adoption in professional workflows.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0904",
    "title": "Enhancing Game Design and Development in Unity Using Generative AI: Opportunities and Shortcomings part 2",
    "summary": "This project aims to investigate the potential of generative AI in transforming game design and development within the Unity ecosystem. By integrating AI-driven asset generation, procedural content creation, and automated design suggestions into Unity, the study will assess both the opportunities and limitations of these techniques. Through a combination of literature review, prototype development, and empirical testing, the project seeks to provide actionable insights for game developers, highlighting how generative AI can streamline development processes while also addressing its inherent challenges.\n\nSpecific details:\nUnity is one of the most widely used game engines, enabling developers to create interactive and immersive experiences. Recently, generative AI has emerged as a promising tool in various creative fields, including game development. Techniques such as neural network-based image synthesis, natural language processing, and procedural generation are being employed to create assets, design levels, and even script in-game narratives. However, while these approaches offer significant benefits in terms of speed and creativity, they also introduce challenges such as inconsistent quality, integration complexity, and ethical considerations.\nThis proposal outlines a project to explore:\n�\tHow generative AI can be effectively integrated into Unity for game design and development.\n�\tThe strengths and opportunities provided by these AI tools.\n�\tThe shortcomings and limitations that need to be addressed to ensure a balanced and practical adoption in professional workflows.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0905",
    "title": "Leveraging Generative AI for Game Design and Development in Unreal Engine: Opportunities and Limitations",
    "summary": "This project aims to investigate how generative AI can be integrated into the Unreal Engine workflow to enhance game design and development. The study will focus on AI-driven asset creation, procedural level generation, and dynamic narrative design, assessing both the potential benefits and the technical, creative, and ethical shortcomings of these approaches. By developing a prototype and conducting empirical evaluations, the project seeks to offer actionable insights for game developers looking to harness AI technology in a professional Unreal Engine environment.\n\nSpecific details:\nUnreal Engine is a powerful game development platform renowned for its high-fidelity graphics, robust toolset, and versatile programming environment. With the advent of generative AI, new possibilities have emerged to accelerate creative processes, automate asset production, and generate innovative game mechanics. This proposal outlines a project designed to explore:\n�\tHow generative AI can be effectively integrated into the Unreal Engine environment.\n�\tThe tangible benefits of AI in speeding up content creation and enriching game design.\n�\tThe limitations, including quality control issues, integration complexities, and ethical concerns that developers may face.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0906",
    "title": "Integrated Project Allocation and Examiner Assignment System for Final Year Projects part 1",
    "summary": "The final year project allocation and examiner assignment process in universities often involves manual efforts and can be prone to inefficiencies. This project aims to develop an integrated system that automates and streamlines the allocation of final year projects to students and the assignment of examiners. The system will enhance transparency, fairness, and efficiency in the entire process.\n\nSpecific details:\n�\tDevelop a user-friendly web-based application for final year project allocation.\n�\tImplement an automated system for assigning project topics to students based on their preferences.\n�\tCreate a module for examiner assignment that considers expertise, workload, and preferences.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Human Computer Interaction",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0907",
    "title": "Integrated Project Allocation and Examiner Assignment System for Final Year Projects part 2",
    "summary": "The final year project allocation and examiner assignment process in universities often involves manual efforts and can be prone to inefficiencies. This project aims to develop an integrated system that automates and streamlines the allocation of final year projects to students and the assignment of examiners. The system will enhance transparency, fairness, and efficiency in the entire process.\n\nSpecific details:\n�\tDevelop a user-friendly web-based application for final year project allocation.\n�\tImplement an automated system for assigning project topics to students based on their preferences.\n�\tCreate a module for examiner assignment that considers expertise, workload, and preferences.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Human Computer Interaction",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0908",
    "title": "Integrated Project Allocation and Examiner Assignment System for Final Year Projects part 3",
    "summary": "The final year project allocation and examiner assignment process in universities often involves manual efforts and can be prone to inefficiencies. This project aims to develop an integrated system that automates and streamlines the allocation of final year projects to students and the assignment of examiners. The system will enhance transparency, fairness, and efficiency in the entire process.\n\nSpecific details:\n�\tDevelop a user-friendly web-based application for final year project allocation.\n�\tImplement an automated system for assigning project topics to students based on their preferences.\n�\tCreate a module for examiner assignment that considers expertise, workload, and preferences.\n\n(a) Research component\n\n\n(b) Development component",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Design & Implementation",
    "keywords": [
      "Database Systems",
      "Human Computer Interaction",
      "Software and Applications"
    ]
  },
  {
    "projectNo": "CCDS25-0909",
    "title": "Investigating Pedagogical Approaches for Integrating Generative AI to Enhance Student Problem-Solving Skills",
    "summary": "This project aims to explore the best pedagogical strategies for using generative AI as an educational tool to cultivate true problem solvers. The focus is on identifying and analyzing teaching methodologies that integrate AI-driven techniques with traditional educational knowledge. Through extensive literature review, qualitative research, and case study analysis, the project will develop a framework for educators to effectively incorporate generative AI into their teaching practices, thereby enhancing students� critical thinking and problem-solving abilities.\n\nSpecific details:\n\n\nThe rapid advancement of generative AI has opened new opportunities in education, particularly in fostering innovative and analytical thinking. While numerous tools exist to support learning, there is a growing need to understand how these technologies can be best integrated into the classroom to support problem-solving skills. This project examines how educators can combine generative AI capabilities with established pedagogical principles to help students tackle complex problems, encouraging independent learning and critical analysis.",
    "supervisor": "Dr Li Fang",
    "isJointOrURECA": "No",
    "category": "Software Only",
    "type": "Research & Development",
    "keywords": [
      "Artificial Intelligence",
      "Knowledge Representation/ Ontology"
    ]
  }
]